{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aknip/Streamlit-Gradio/blob/main/myGPTlab.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# myGPTlab\n",
        "\n",
        "This app helps to process texts (longform content) with ChatGPT via API.\n",
        "\n",
        "## Start:\n",
        "**Run all cells - that's it.**\n",
        "- The notebooks checks automatically, if an initial setup (with PIP etc.) is necessary. The setup status is saved in the file 'installation.done'\n",
        "- You can force the setup by deleting this file or by going to Seciton \"Setup and Configuration\" and checking \"inital_setup_mode\". Afterwards uncheck \"Setup and Configuration\".\n",
        "\n",
        "## Working with myGPTlab\n",
        "\n",
        "## FAQ\n",
        "### Was tun, wenn kryptische Fehlermeldungen erscheinen, wie z. B. \"error: invalid group reference 11 at position 1\"?\n",
        "Den Input-Text neu anlegen bzw. konvertieren (z. b. per pandoc). Die Ursache kann Encoding sein.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "Ht3Wkxk7Rpn_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here we go"
      ],
      "metadata": {
        "id": "v1Tk6QX28RZN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# @title\n",
        "import os\n",
        "import requests\n",
        "# os.environ.pop('CREDS') # delete environment variable for debugging\n",
        "if not os.getenv('CREDS'):\n",
        "  #popup('Enter API Keys as JSON:')\n",
        "  fname = 'aknip-colab-setup'\n",
        "  url = 'https://bit.ly/' + fname\n",
        "  r = requests.get(url)\n",
        "  open(fname, 'wb').write(r.content)\n",
        "  %run aknip-colab-setup\n",
        "else:\n",
        "  print(\"API Keys available in env 'CREDS'\")\n",
        "\n",
        "!pip install ipywidgets -q"
      ],
      "metadata": {
        "cellView": "form",
        "id": "VDc8hEXF1Zra",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2f55f54e-bd51-4f4e-a485-8fc309adc51e"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Secrets (JSON string): ··········\n",
            "Credentials stored in env 'CREDS'. Get values via: \n",
            "creds = json.loads(os.getenv('CREDS')) \n",
            "key = creds['OpenAI']['v1']['credential']\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m10.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title\n",
        "import ipywidgets\n",
        "from ipywidgets import Layout, Button, Box, VBox, HTML, Output\n",
        "\n",
        "# Info flex proportionally to the weight\n",
        "info_1 = HTML(value='<div style=\"background-color: red; text-align: center\"><b>Please wait for initial setup...</b></div>', layout=Layout(flex='1 1 auto', width='auto'))\n",
        "items_info = [info_1]\n",
        "\n",
        "# Header flex proportionally to the weight\n",
        "header_1 = HTML(value='<div style=\"background-color: #ccc; text-align: center\">Hello <b>World</b></div>', layout=Layout(flex='1 1 auto', width='auto'))\n",
        "items_header = [header_1]\n",
        "\n",
        "# Text flex proportionally to the weight\n",
        "text_1 = HTML(value='Infotext', layout=Layout(flex='1 1 auto', width='25%'))\n",
        "text_2 = HTML(value='Infotext jdskl fjkdslf jsdklfjslf', layout=Layout(flex='1 1 auto', width='25%'))\n",
        "text_3 = HTML(value='Infotext jdskl fjkdslf jsdklfjslf', layout=Layout(flex='1 1 auto', width='25%'))\n",
        "text_4 = HTML(value='Infotext jdskl fjkdslf jsdklfjslf', layout=Layout(flex='1 1 auto', width='25%'))\n",
        "items_texts = [text_1, text_2, text_3, text_4]\n",
        "\n",
        "# Buttons flex proportionally to the weight\n",
        "button_1 = Button(description='Install', layout=Layout(flex='1 1 0%', width='auto'), button_style='success')\n",
        "button_2 = Button(description='Save Text', layout=Layout(flex='1 1 0%', width='auto'), button_style='success')\n",
        "button_3 = Button(description='Split Text', layout=Layout(flex='1 1 0%', width='auto'), button_style='success')\n",
        "button_4 = Button(description='Chat', layout=Layout(flex='1 1 0%', width='auto'), button_style='success')\n",
        "items_buttons = [button_1, button_2, button_3, button_4]\n",
        "\n",
        "# Output flex proportionally to the weight\n",
        "output_1 = Output(layout=Layout(flex='1 1 auto', width='auto'))\n",
        "items_output = [output_1]\n",
        "\n",
        "box_layout = Layout(display='flex',\n",
        "                    flex_flow='row',\n",
        "                    align_items='stretch',\n",
        "                    width='90%')\n",
        "\n",
        "box_info = Box(children=items_info, layout=box_layout)\n",
        "box_header = Box(children=items_header, layout=box_layout)\n",
        "box_texts = Box(children=items_texts, layout=box_layout)\n",
        "box_buttons = Box(children=items_buttons, layout=box_layout)\n",
        "box_output = Box(children=items_output, layout=box_layout)\n",
        "\n",
        "def on_button_1_clicked(b):\n",
        "    with output_1:\n",
        "        print('Printed using output widget') # + my_input_text.value)\n",
        "        my_test()\n",
        "button_1.on_click(on_button_1_clicked)\n",
        "\n",
        "def on_button_2_clicked(b):\n",
        "    output_1.clear_output()\n",
        "\n",
        "button_2.on_click(on_button_2_clicked)\n",
        "\n",
        "button_1.layout.visibility = \"hidden\"\n",
        "button_2.layout.visibility = \"hidden\"\n",
        "button_3.layout.visibility = \"hidden\"\n",
        "button_4.layout.visibility = \"hidden\"\n",
        "\n",
        "VBox([box_info, box_header, box_texts, box_buttons, box_output])\n"
      ],
      "metadata": {
        "cellView": "form",
        "id": "IwvcO7XF5j5f",
        "outputId": "fe67cdd7-fa19-4b66-c0a0-6c372463fc9b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 113,
          "referenced_widgets": [
            "e0d1791da2ad4cc68ab08c12bb4429bc",
            "127bd2a95b554e86b33774b5417f5424",
            "28259723b582419ca057b52bba9b74e7",
            "abfedcbcab1144ad91eea8de578567f1",
            "23d1d32e0702475c9eb575797c56db00",
            "548b7826d8f74664b0af3068ff684632",
            "2bdac73c245d4e988b834058e50afd3f",
            "3c8072c6a1d24cbe8a9a9f5e3f80c11a",
            "c037f0e8b2654d309ea090c0eb1e18bc",
            "baf295ccea144243b20510b7eda0934e",
            "46033148e5c64d49a5e9860d101b82f4",
            "2e6ba526696f4d318d7e1c1f5ba6c750",
            "bac54a37a0484d21a190cda886e01c3c",
            "6d9a3defe3354dd499a322779b3ac7ea",
            "edc59731919f4414b31c3fe8af367193",
            "0961343291444357b5285721dc5365e2",
            "27413f6e7cf0498a991fc06d0abf39b8",
            "b8bad9dd76fc453eb3a1e193a0fefd69",
            "719fcbc5263c4a44a1782694aa6cf6ed",
            "d064827f45544bbb908fb3784fefad76",
            "aa21165055ff407e99ffd5f2c9314888",
            "f1daa1c0f5d242148e4f7be62b68104c",
            "32b5427d93164f539a8d422b66b5b199",
            "c853d0bdf89f4ba3bb49fe6821b9cf33",
            "31eb55c9aa8b45c4a887851b4102f300",
            "fb82952e40104a52bef15c090b89c157",
            "7657f29b25654df7b9c869242b8c7753",
            "0dc354d2b8174cd78583dd1befb82f35",
            "665642f42f35461e922e849ffc1fe6c9",
            "edcd256d704c4aae88e5e4e8206a8bbf",
            "8238d9a69ab7499a81fbad89d4363e7f",
            "4dcb1742bb5946b7b45c9a4fe6008b50",
            "97569c137b1540d186df3e6a03061c9b",
            "ad3b2c076e454e21b732aa310517b1db",
            "da2d9c76889745a4b37a5ef8aff816bd",
            "3c2318d4d12842c2af4b3fe5ab2ef6f1",
            "8dcf46a0934f4211a9186058fa426fb9",
            "447bb76f04e24893af4e8d5b4439635f",
            "bbabbf1347e24cdba0253a399fae5fa9",
            "10d382213150488ba702757d915662a1"
          ]
        }
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "VBox(children=(Box(children=(HTML(value='<div style=\"background-color: red; text-align: center\"><b>Please wait…"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e0d1791da2ad4cc68ab08c12bb4429bc"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Install"
      ],
      "metadata": {
        "id": "vcKyPYho08Y2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Settings\n",
        "\n",
        "# @markdown Default model\n",
        "default_model = 'GPT-3.5' # @param [\"GPT-3.5\", \"GPT-4\"]\n",
        "\n",
        "# @markdown Start Gradio webapp.\n",
        "start_gradio_webapp = False # @param {type:\"boolean\"}\n",
        "\n",
        "# @markdown Initial Setup Mode for pip install, fetch credentials etc.\n",
        "initial_setup_mode = False # @param {type:\"boolean\"}\n",
        "\n",
        "# @markdown Debug Mode for extensive logging.\n",
        "debug_mode = True # @param {type:\"boolean\"}\n",
        "\n",
        "# @markdown iOS Mode to develop helper functions, no Gradio.\n",
        "# @markdown Useful for development on iOS, eg. with Carnets App\n",
        "ios_mode = False # @param {type:\"boolean\"}"
      ],
      "metadata": {
        "cellView": "form",
        "id": "9NyekTkaGU3Z"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "folders = {\n",
        "    'audio': 'audio',\n",
        "    'audio-chunks': 'audio/chunks',\n",
        "    'transcript':'audio-transcript',\n",
        "    'transcript-chunks': 'audio-transcript/chunks',\n",
        "    'text-input': 'text-input',\n",
        "    'text-input-backup': 'text-input-backup',\n",
        "    'text-output': 'text-output',\n",
        "    'text-output-logs': 'text-output-logs'\n",
        "}"
      ],
      "metadata": {
        "id": "FBJns82oduIg"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from ipywidgets import widgets\n",
        "from IPython.display import Javascript, display, clear_output\n",
        "notify_output = widgets.Output()\n",
        "display(notify_output)\n",
        "@notify_output.capture()\n",
        "def popup(text):\n",
        "    clear_output()\n",
        "    display(Javascript(\"alert('{}')\".format(text)))\n",
        "#popup('Hello World!')"
      ],
      "metadata": {
        "id": "Z-9rgUetGeu0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17,
          "referenced_widgets": [
            "837d4a9832454a8e864d8e3f0b14ab78",
            "f4ac03a220974d4f9c71dd344f3478a1"
          ]
        },
        "outputId": "a46fb9ef-2211-4af5-f654-9c38583545ab"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Output()"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "837d4a9832454a8e864d8e3f0b14ab78"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "if initial_setup_mode != True:\n",
        "  if os.path.exists('installation.done'):\n",
        "      initial_setup_mode = False\n",
        "      print('No initial setup - forced by existing file \"installation.done\"')\n",
        "  else:\n",
        "    initial_setup_mode = True\n",
        "    print('Starting automatic setup - forced by missing file \"installation.done\".\\n\\nEnter API Keys as JSON (in next notebook cell).')\n",
        "    #popup('Starting automatic setup. Enter API Keys as JSON (in next notebook cell).')\n",
        "else:\n",
        "  print('Starting setup.\\n\\nEnter API Keys as JSON (in next notebook cell).')\n",
        "  #popup('Starting setup. Enter API Keys as JSON (in next notebook cell).')"
      ],
      "metadata": {
        "id": "4cDDPr809eC4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8cccd099-a94b-497f-c933-367076728366"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting automatic setup - forced by missing file \"installation.done\".\n",
            "\n",
            "Enter API Keys as JSON (in next notebook cell).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#if initial_setup_mode == True:\n",
        "  #popup('Enter API Keys as JSON:')\n",
        "  #!wget -q bit.ly/aknip-colab-setup\n",
        "  #%run aknip-colab-setup\n",
        "#else:\n",
        "  #print('No initial setup.')"
      ],
      "metadata": {
        "id": "eepWvnFN-yvj"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "creds = json.loads(os.getenv('CREDS'))\n",
        "# openAI_key = creds['OpenAI']['v2']['credential']\n",
        "# print(openAI_key)"
      ],
      "metadata": {
        "id": "iEwJ4-ShAt0v"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if ios_mode == False:\n",
        "  print('Mac')\n",
        "else:\n",
        "  print('iOS')"
      ],
      "metadata": {
        "id": "DRWVZHV1MOij",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4c1d5bf1-c8d6-4635-c0a5-19cb5371fbc1"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mac\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "Wtw0CARBQhTQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2cd68513-60e1-4f83-a8e5-d9e95bf6145c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m72.0/72.0 kB\u001b[0m \u001b[31m1.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.0/3.0 MB\u001b[0m \u001b[31m30.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m41.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m232.6/232.6 kB\u001b[0m \u001b[31m18.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.1/14.1 MB\u001b[0m \u001b[31m79.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m193.6/193.6 kB\u001b[0m \u001b[31m17.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m66.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m129.9/129.9 kB\u001b[0m \u001b[31m12.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.7/2.7 MB\u001b[0m \u001b[31m84.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m90.0/90.0 kB\u001b[0m \u001b[31m9.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m84.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.4/49.4 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for pickle-mixin (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ],
      "source": [
        "if initial_setup_mode == True:\n",
        "  !pip install openai==0.27.7 yt-dlp==2023.7.6 librosa==0.10.0.post2 pickle-mixin==1.0.2 langchain==0.0.225 PyPDF2==3.0.1 PyMuPDF==1.22.5 pypandoc -q\n",
        "else:\n",
        "  print('No initial setup.')\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "if (initial_setup_mode == True) and (ios_mode == False) :\n",
        "  !pip install gradio -q\n",
        "else:\n",
        "  print('No initial setup / iOS.')"
      ],
      "metadata": {
        "id": "-TpG9Zr0IUU0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6a24ef34-e31c-43ea-c788-841943589478"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m20.0/20.0 MB\u001b[0m \u001b[31m62.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m65.7/65.7 kB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m297.4/297.4 kB\u001b[0m \u001b[31m24.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.4/75.4 kB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m268.8/268.8 kB\u001b[0m \u001b[31m22.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.5/50.5 kB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m140.3/140.3 kB\u001b[0m \u001b[31m12.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.7/45.7 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m59.5/59.5 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.4/50.4 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.5/46.5 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.7/43.7 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.0/41.0 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.0/41.0 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m87.5/87.5 kB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.5/84.5 kB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.0/67.0 kB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m74.5/74.5 kB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for ffmpy (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "if (initial_setup_mode == True) and (ios_mode == False) :\n",
        "  %load_ext gradio\n",
        "else:\n",
        "  print('No initial setup / iOS.')"
      ],
      "metadata": {
        "id": "EyhkzcJ_Ob45"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if initial_setup_mode == True:\n",
        "  f= open('installation.done','w+')\n",
        "  f.close()\n",
        "  print('Initial setup done. Application starting.')\n",
        "  # popup('Initial setup done. Application starting.')\n",
        "else:\n",
        "  print('No initial setup.')"
      ],
      "metadata": {
        "id": "l0Lx1eHL9Nik",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cba03163-3290-4629-ec97-18903bfaf226"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Initial setup done. Application starting.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Promptlib"
      ],
      "metadata": {
        "id": "lKcS3L5pXA06"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# myprompt = \"The given text is delimited by triple backticks. Summarize the current text to succint and clear bullet points of its contents.\n",
        "#          The length of the summary must be 200 words maximum.\"\n",
        "# myprompt = \"The given text is delimited by triple backticks.\n",
        "#           Summarize the current text to a maximum of 15 succint and clear bullet points of its contents.\"\n",
        "# myprompt = myprompt + \"The maximum number of words should be 300 words in total. \"\n",
        "# myprompt = myprompt + \"Write everything in German language. \" # this is optional !\n",
        "# myprompt = myprompt + \"```\" + input_text + \"```\"\n",
        "\n",
        "\n",
        "# Promptlib\n",
        "# Todo: promptlib not as global,\n",
        "\n",
        "promptlib_global = {\n",
        "    'summary-shortened': {\n",
        "      'description': '',\n",
        "      'category': 'summarize',\n",
        "      '1': {\n",
        "          'note': 'Gleichzeitiges Einfügen/Formatieren von Headlines funktioniert nicht, lässt GPT alles umformulieren\\\n",
        "           (\"Format headings and subheadings in markdown syntax.\").\\\n",
        "           Test S4/HANA Kap. 4: Input 12.300 Wörter, GPT-3.5 Output: 4.500 Wörter (36%), GPT-4 Output: 3.400 Wörter (27%)',\n",
        "          \"prompt\": \"Paraphrase the following text and shorten each paragraph of the paraphrased text to maxiumum the half of its original length by focussing\\\n",
        "            on the key aspects. Write in the style and tone of a professional business analyst and use passive form. Be detailed and precise\\\n",
        "            and use every content detail of the text. Note that there may be typographical or grammatical errors in the passages due to the\\\n",
        "            text being fetched from a transcript of a talk or a speech.\\\n",
        "            {language_text} {length_text} Text:```{input_text}``` {toc_text}\",\n",
        "          \"lang-de\": \"Write everything in German language.\",\n",
        "          \"lang-en\": \"Write everything in English language.\",\n",
        "          \"lang-same\": \"If the following text in triple backticks is in German language write your text in German language, too.\",\n",
        "          'gpt-3.5-turbo': {\n",
        "              \"input-text-max\": 1200,\n",
        "              \"length-max-fix\": \"The length of the full text must be 1200 words maximum.\",\n",
        "              \"length-max-dyn\": \"The length of the full text must be {{length_calc(\\\"{input_text}\\\", {max_len})}} words maximum.\"\n",
        "          },\n",
        "          'gpt-4': {\n",
        "              \"input-text-max\": 2400,\n",
        "              \"length-max-fix\": \"The length of the full text must be 2400 words maximum.\",\n",
        "              \"length-max-dyn\": \"The length of the full text must be {{length_calc(\\\"{input_text}\\\", {max_len})}} words maximum.\"\n",
        "          },\n",
        "          'default-model': {\n",
        "              \"input-text-max\": 500,\n",
        "              \"length-max-fix\": \"The length of the full text must be 500 words maximum.\",\n",
        "              \"length-max-dyn\": \"The length of the full text must be {{length_calc(\\\"{input_text}\\\", {max_len})}} words maximum.\"\n",
        "          }\n",
        "      }\n",
        "    },\n",
        "    'summary-multiple-articles': {\n",
        "      'description': '',\n",
        "      'category': 'summarize',\n",
        "      '1': {\n",
        "          'note': 'summarize each headline / paragraph',\n",
        "          \"prompt\": \"The given text is delimited by triple backticks. It is a newspaper text with several articles.\\\n",
        "            Summarize each article with its headline and succint and clear bullet points of its contents.\\\n",
        "            Format everything in markdown syntax. {language_text} {length_text} Text:```{input_text}``` {toc_text}\",\n",
        "          \"lang-de\": \"Write everything in German language.\",\n",
        "          \"lang-en\": \"Write everything in English language.\",\n",
        "          \"lang-same\": \"If the following text in triple backticks is in German language write your text in German language, too.\",\n",
        "          'gpt-3.5-turbo': {\n",
        "              \"input-text-max\": 1200,\n",
        "              \"length-max-fix\": \"The length of the full text must be 1200 words maximum.\",\n",
        "              \"length-max-dyn\": \"The length of the full text must be {{length_calc(\\\"{input_text}\\\", {max_len})}} words maximum.\"\n",
        "          },\n",
        "          'gpt-4': {\n",
        "              \"input-text-max\": 2400,\n",
        "              \"length-max-fix\": \"The length of the full text must be 2400 words maximum.\",\n",
        "              \"length-max-dyn\": \"The length of the full text must be {{length_calc(\\\"{input_text}\\\", {max_len})}} words maximum.\"\n",
        "          },\n",
        "          'default-model': {\n",
        "              \"input-text-max\": 500,\n",
        "              \"length-max-fix\": \"The length of the full text must be 500 words maximum.\",\n",
        "              \"length-max-dyn\": \"The length of the full text must be {{length_calc(\\\"{input_text}\\\", {max_len})}} words maximum.\"\n",
        "          }\n",
        "      }\n",
        "    },\n",
        "    'summary-bullets': {\n",
        "      'description': 'Max word length: 1100 for EN, 900 for DE. approx. 1 min processing time Example: Full book: 113 parts á 1000 words takes 15 min.',\n",
        "      'category': 'summarize',\n",
        "      '1': {\n",
        "          'note': 'summarize to bullets v1',\n",
        "          \"prompt\": 'The given text is delimited by triple backticks. Summarize the current text to succint and clear bullet points\\\n",
        "            of its contents. {language_text} {length_text} Text:```{input_text}``` {toc_text}',\n",
        "          \"lang-de\": \"Write everything in German language.\",\n",
        "          \"lang-en\": \"Write everything in English language.\",\n",
        "          \"lang-same\": \"If the following text in triple backticks is in German language write your text in German language, too.\",\n",
        "          'gpt-3.5-turbo': {\n",
        "              \"input-text-max\": 1200,\n",
        "              \"length-max-fix\": \"The length of the summary must be 300 words maximum.\",\n",
        "              \"length-max-dyn\": \"The length of the summary must be {{length_calc(\\\"{input_text}\\\", {max_len})}} words maximum.\"\n",
        "          },\n",
        "          'gpt-4': {\n",
        "              \"input-text-max\": 2400,\n",
        "              \"length-max-fix\": \"The length of the summary must be 300 words maximum.\",\n",
        "              \"length-max-dyn\": \"The length of the summary must be {{length_calc(\\\"{input_text}\\\", {max_len})}} words maximum.\"\n",
        "          },\n",
        "          'default-model': {\n",
        "              \"input-text-max\": 500,\n",
        "              \"length-max-fix\": \"The length of the summary must be 300 words maximum.\",\n",
        "              \"length-max-dyn\": \"The length of the summary must be {{length_calc(\\\"{input_text}\\\", {max_len})}} words maximum.\"\n",
        "          }\n",
        "      },\n",
        "      '2': {\n",
        "          'note': 'summarize to bullets v2',\n",
        "          \"prompt\": 'The given text is delimited by triple backticks. Summarize the current text to a maximum of 15 succint\\\n",
        "            and clear bullet points of its contents. {language_text} {length_text} Text:```{input_text}``` {toc_text}',\n",
        "          \"lang-de\": \"Write everything in German language.\",\n",
        "          \"lang-en\": \"Write everything in English language.\",\n",
        "          \"lang-same\": \"If the following text in triple backticks is in German language write your text in German language, too.\",\n",
        "          'gpt-3.5-turbo': {\n",
        "              \"input-text-max\": 1200,\n",
        "              \"length-max-fix\": \"The length of the summary must be 300 words maximum.\",\n",
        "              \"length-max-dyn\": \"The length of the summary must be {{length_calc(\\\"{input_text}\\\", {max_len})}} words maximum.\"\n",
        "          },\n",
        "          'gpt-4': {\n",
        "              \"input-text-max\": 2400,\n",
        "              \"length-max-fix\": \"The length of the summary must be 300 words maximum.\",\n",
        "              \"length-max-dyn\": \"The length of the summary must be {{length_calc(\\\"{input_text}\\\", {max_len})}} words maximum.\"\n",
        "          },\n",
        "          'default-model': {\n",
        "              \"input-text-max\": 500,\n",
        "              \"length-max-fix\": \"The length of the summary must be 300 words maximum.\",\n",
        "              \"length-max-dyn\": \"The length of the summary must be {{length_calc(\\\"{input_text}\\\", {max_len})}} words maximum.\"\n",
        "          }\n",
        "      }\n",
        "    },\n",
        "    'create-subheadlines': {\n",
        "      'description': '',\n",
        "      'category': 'structure',\n",
        "      '1': {\n",
        "          'note': 'create subheadlien, keep text the same',\n",
        "          \"prompt\": \"The given text is delimited by triple backticks. Divide the text into 3 paragraphs of approximately\\\n",
        "           equal length according to the meaning of the content and insert subheadings for the paragraphs.\\\n",
        "           Please respond with the full original text including the inserted subheadings.\\\n",
        "           Format the subheadings in markdown syntax. {language_text} {length_text} Text:```{input_text}``` {toc_text}\",\n",
        "          \"lang-de\": \"Write everything in German language.\",\n",
        "          \"lang-en\": \"Write everything in English language.\",\n",
        "          \"lang-same\": \"Write in the language of the original text.\",\n",
        "          'gpt-3.5-turbo': {\n",
        "              \"input-text-max\": 1200,\n",
        "              \"length-max-fix\": \"The length of the full text must be 1200 words maximum.\",\n",
        "              \"length-max-dyn\": \"The length of the full text must be {{length_calc(\\\"{input_text}\\\", {max_len})}} words maximum.\"\n",
        "          },\n",
        "          'gpt-4': {\n",
        "              \"input-text-max\": 2400,\n",
        "              \"length-max-fix\": \"The length of the full text must be 2400 words maximum.\",\n",
        "              \"length-max-dyn\": \"The length of the full text must be {{length_calc(\\\"{input_text}\\\", {max_len})}} words maximum.\"\n",
        "          },\n",
        "          'default-model': {\n",
        "              \"input-text-max\": 500,\n",
        "              \"length-max-fix\": \"The length of the full text must be 500 words maximum.\",\n",
        "              \"length-max-dyn\": \"The length of the full text must be {{length_calc(\\\"{input_text}\\\", {max_len})}} words maximum.\"\n",
        "          }\n",
        "      }\n",
        "    },\n",
        "    'summary-3-sentences': {\n",
        "      'description': '',\n",
        "      'category': 'summarize',\n",
        "      '1': {\n",
        "          'note': 'create subheadlien, keep text the same',\n",
        "          \"prompt\": \"The given text is delimited by triple backticks. Summarize the text into three\\\n",
        "           sentences. {language_text} {length_text} Text:```{input_text}``` {toc_text}\",\n",
        "          \"lang-de\": \"Write everything in German language.\",\n",
        "          \"lang-en\": \"Write everything in English language.\",\n",
        "          \"lang-same\": \"Write in the language of the original text.\",\n",
        "          'gpt-3.5-turbo': {\n",
        "              \"input-text-max\": 1200,\n",
        "              \"length-max-fix\": \"The length of the full text must be 300 words maximum.\",\n",
        "              \"length-max-dyn\": \"The length of the full text must be {{length_calc(\\\"{input_text}\\\", {max_len})}} words maximum.\"\n",
        "          },\n",
        "          'gpt-4': {\n",
        "              \"input-text-max\": 2400,\n",
        "              \"length-max-fix\": \"The length of the full text must be 300 words maximum.\",\n",
        "              \"length-max-dyn\": \"The length of the full text must be {{length_calc(\\\"{input_text}\\\", {max_len})}} words maximum.\"\n",
        "          },\n",
        "          'default-model': {\n",
        "              \"input-text-max\": 500,\n",
        "              \"length-max-fix\": \"The length of the full text must be 300 words maximum.\",\n",
        "              \"length-max-dyn\": \"The length of the full text must be {{length_calc(\\\"{input_text}\\\", {max_len})}} words maximum.\"\n",
        "          }\n",
        "      }\n",
        "    }\n",
        "  }"
      ],
      "metadata": {
        "id": "YeJ8c1TVTDSb"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Code"
      ],
      "metadata": {
        "id": "iTR550hbTvzd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Helper Functions\n",
        "\n",
        "- **create_file_directory**: Creates a new directory - if it not exists yet. The always_delete flag forces a deletion even if it exists.\n",
        "- find_files\n",
        "- merge_textfiles\n",
        "- save_and_backup\n",
        "- zip_full_archive\n",
        "- unzip_full_archive\n",
        "- remove_all_double_whitespace\n",
        "- remove_double_spaces_keep_paragraphs\n",
        "- remove_special_chars\n",
        "- text_stats\n",
        "- wordcount\n",
        "- split_text_by_separator"
      ],
      "metadata": {
        "id": "zO7UxoRjSWUy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# v4 - 13.08.2023\n",
        "import shutil\n",
        "import os\n",
        "import textwrap\n",
        "import re\n",
        "import time\n",
        "from datetime import datetime\n",
        "import pypandoc\n",
        "import os\n",
        "import zipfile\n",
        "import random\n",
        "\n",
        "def create_file_directory(directory, always_delete=False):\n",
        "  # Creates a new directory - if it not exists yet. The always_delete flag forces a deletion even if it exists.\n",
        "  # Examples:\n",
        "  # - create_file_directory('texts', False) => creates a new directory only if it not exists yet\n",
        "  # - create_file_directory('texts', True) => always deletes existing directory and creates a new one\n",
        "  if os.path.exists(directory):\n",
        "    if always_delete:\n",
        "      # delete the diectory recursively\n",
        "      shutil.rmtree(directory)\n",
        "  # create directory\n",
        "  if not os.path.exists(directory):\n",
        "    os.mkdir(directory)\n",
        "\n",
        "\n",
        "def find_files(path, extensions=[\".txt\"], recursive=False):\n",
        "    # Recursively (optional) find all files with extension in path\n",
        "    my_files = []\n",
        "    for root, dirs, files in os.walk(path):\n",
        "        for f in files:\n",
        "            if extensions == []:\n",
        "                my_files.append(os.path.join(root, f))\n",
        "            else:\n",
        "                for ext in extensions:\n",
        "                    if f.endswith(ext):\n",
        "                        my_files.append(os.path.join(root, f))\n",
        "        # no recursion / don't look inside any subdirectory\n",
        "        if recursive == False:\n",
        "            break\n",
        "    return my_files\n",
        "\n",
        "\n",
        "def merge_textfiles(path, extensions=[\".txt\"], recursive=False, new_filename='merged.txt'):\n",
        "    # Recursively (optional) find all files with extension in path\n",
        "    my_files = find_files(path, extensions, recursive)\n",
        "    merged_text = ''\n",
        "    for filename in my_files:\n",
        "      # print(filename)\n",
        "      f= open(filename,'r')\n",
        "      if f.mode == 'r':\n",
        "            contents =f.read()\n",
        "      f.close()\n",
        "      merged_text = merged_text + contents + '\\n\\n\\n'\n",
        "\n",
        "    f= open(new_filename,'w+')\n",
        "    f.write(merged_text)\n",
        "    f.close()\n",
        "\n",
        "\n",
        "def save_and_backup(filepath, filename, content, convert_to_docx=False):\n",
        "  dot_pos = filename.rfind('.')\n",
        "  docx_filename = filename[:dot_pos] + '.docx'\n",
        "  if os.path.exists(filepath + '/' + filename):\n",
        "    # file exists, do backup\n",
        "    current_date_time = datetime.now().strftime(\"%Y-%m-%d %H-%M-%S\")\n",
        "    backuppath = filepath + '/backup ' + current_date_time\n",
        "    os.mkdir(backuppath)\n",
        "    shutil.copyfile(filepath + '/' + filename, backuppath + '/' + filename)\n",
        "    # copy corresponding .docx if necessary\n",
        "    if (convert_to_docx == True) and (os.path.exists(filepath + '/' + docx_filename)):\n",
        "      shutil.copyfile(filepath + '/' + docx_filename, backuppath + '/' + docx_filename)\n",
        "  # save\n",
        "  f= open(filepath + '/' + filename,'w+')\n",
        "  f.write(content)\n",
        "  f.close()\n",
        "  if convert_to_docx == True:\n",
        "    docx_file = pypandoc.convert_file(\n",
        "    filepath + '/' + filename,\n",
        "    'docx',\n",
        "    outputfile=filepath + '/' + docx_filename)\n",
        "\n",
        "\n",
        "def zip_full_archive():\n",
        "  # zips all project folders (except \"sample_data\" and config files)\n",
        "  #os.remove('zipfile.zip')\n",
        "  directory = \"./\"\n",
        "  with zipfile.ZipFile(\"zipfile.zip\", \"w\") as zip:\n",
        "      for subdir, dirs, files in os.walk(directory):\n",
        "          for file in files:\n",
        "              srcpath = os.path.join(subdir, file)\n",
        "              if (subdir != './') and (subdir.startswith('./.config') == False) and (subdir != './sample_data'):\n",
        "                #print(subdir)\n",
        "                dstpath_in_zip = os.path.relpath(srcpath, start=directory)\n",
        "                with open(srcpath, 'rb') as infile:\n",
        "                    print(srcpath)\n",
        "                    zip.writestr(dstpath_in_zip, infile.read())\n",
        "\n",
        "def unzip_full_archive():\n",
        "  with zipfile.ZipFile('zipfile.zip', 'r') as zip:\n",
        "      zip.printdir()\n",
        "      zip.extractall('./')\n",
        "\n",
        "\n",
        "def remove_all_double_whitespace (input_text):\n",
        "    # replaces ALL whitespace to a single SPACE, no paragraphs left\n",
        "    clean_text = \" \".join(re.split(\"[\\s ]+\", input_text, flags=re.UNICODE))\n",
        "    # clean_text = input_text.translate(str.maketrans('', '', ' \\n\\t\\r'))\n",
        "    return clean_text.strip()\n",
        "\n",
        "def remove_double_spaces_keep_paragraphs (input_text):\n",
        "    # removes double spaces and double paragraphs, keeps paragraph structure\n",
        "    clean_text = \"\"\n",
        "    for line in input_text.split('\\n'):\n",
        "        line_trimmed = line.strip()\n",
        "        if line_trimmed != '':\n",
        "            clean_text = clean_text + (re.sub('[\\t ]+',' ', line_trimmed)) + '\\n'\n",
        "    return clean_text[:-1] # remove last \\n\n",
        "\n",
        "\n",
        "def remove_special_chars(input_text, strength_level):\n",
        "  # removes\n",
        "  cleaned_text = input_text.replace('»', '\"')\n",
        "  cleaned_text = cleaned_text.replace('«', '\"')\n",
        "  cleaned_text = cleaned_text.replace('„', '\"')\n",
        "  cleaned_text = cleaned_text.replace('“', '\"')\n",
        "  cleaned_text = re.sub('(?sm)[\\\\\\/\"\\'`´\\^\\*{}\\[\\]<>\\+\\&]', '', cleaned_text)\n",
        "  return cleaned_text\n",
        "\n",
        "\n",
        "def text_stats(input_text):\n",
        "    nr_paragraphs = len(input_text.split(\"\\n\"))\n",
        "    nr_words = wordcount(input_text)\n",
        "    array_segments = input_text.split(\"§§§\")\n",
        "    nr_segments = len(array_segments)\n",
        "    stat_txt = f'Number of words / paragraphs / §§§ segements: {nr_words} / {nr_paragraphs} / {nr_segments}'\n",
        "    if nr_segments > 1:\n",
        "        seg_stats = []\n",
        "        seg_stats_text = ''\n",
        "        for seg in array_segments:\n",
        "            seg_stats.append(wordcount(seg))\n",
        "            seg_stats_text = seg_stats_text + str(wordcount(seg)) + ' / '\n",
        "        stat_txt = stat_txt + '\\n\\nMax words in §§§ segment: ' + str(max(seg_stats)) + ' (' + seg_stats_text[:-3] + ')'\n",
        "    return stat_txt\n",
        "\n",
        "def wordcount(input_text):\n",
        "    # returns number of words of given input_text\n",
        "    return len(input_text.split())\n",
        "\n",
        "\n",
        "def split_text_by_separator (text, separator, joiner, fixer, min_words=1000, max_words=0):\n",
        "    # Split text into an array of texts with a maximum word count\n",
        "    # optionally use random word counts between min_words and max_words (if max_words is set)\n",
        "    # example 1: Split by paragraphs\n",
        "    #   split_text_by_separator(input_text, '\\n', '\\n', 'fix-nothing', 2000)\n",
        "    # example 2: Split by sentences '. ' and fix\n",
        "    #   split_text_by_separator(input_text, '. ', ' ', 'fix-end', 2000)\n",
        "    # example 3: Split by markdown headlines '\\n#' and fix\n",
        "    #   split_text_by_separator(input_text, '\\n#', '\\n\\n', 'fix-start', 2000)\n",
        "    paragraphs = []\n",
        "    sections = []\n",
        "    section = ''\n",
        "    if max_words == 0:\n",
        "      max_words = min_words\n",
        "    # Split text, separated by separator\n",
        "    paragraphs_stripped = text.split(separator)\n",
        "    # fix paragraphs (if wanted) by re-adding the separator at end or start\n",
        "    if fixer == 'fix-nothing':\n",
        "        paragraphs = paragraphs_stripped\n",
        "    if fixer == 'fix-end':\n",
        "        for index, paragraph in enumerate(paragraphs_stripped):\n",
        "            if (index+1) == len(paragraphs_stripped):\n",
        "                paragraphs.append(paragraph)\n",
        "            else:\n",
        "                paragraphs.append(paragraph + separator)\n",
        "    if fixer == 'fix-start':\n",
        "        for index, paragraph in enumerate(paragraphs_stripped):\n",
        "            if index == 0:\n",
        "                paragraphs.append(paragraph)\n",
        "            else:\n",
        "                paragraphs.append(separator + paragraph)\n",
        "    # Loop through paragraphs and aggregate up to maximum word count\n",
        "    for index, paragraph in enumerate(paragraphs):\n",
        "        if min_words == max_words:\n",
        "            max_random = min_words\n",
        "        else:\n",
        "            max_random = random.randrange(min_words, max_words)\n",
        "        test_section = section + paragraph + joiner\n",
        "        if wordcount(test_section) > max_random:\n",
        "            sections.append(section.strip())\n",
        "            section = paragraph\n",
        "            if min_words == max_words:\n",
        "                max_random = min_words\n",
        "            else:\n",
        "                max_random = random.randrange(min_words, max_words)\n",
        "        else:\n",
        "            section = section + paragraph + joiner\n",
        "            # if last paragraph, append to array\n",
        "            if (index+1) == len(paragraphs):\n",
        "              sections.append(section)\n",
        "    return sections\n"
      ],
      "metadata": {
        "id": "dydmkY6_SZeG"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import pickle\n",
        "\n",
        "\n",
        "\n",
        "def write_prompt_to_lib(promptlib, prompt):\n",
        "    # adds or updates prompt to library\n",
        "    #\n",
        "    # TODO: Add model sections \"gpt-4\", ... etc.\n",
        "    #\n",
        "    id = prompt['id']\n",
        "    version = prompt['version']\n",
        "    if id not in promptlib:\n",
        "        # new id\n",
        "        promptlib[id] = {}\n",
        "        promptlib[id][version] = {}\n",
        "    else:\n",
        "        # id already existing, checking for version\n",
        "        if version not in promptlib[id]:\n",
        "            promptlib[id][version] = {}\n",
        "    promptlib[id]['description'] = prompt['description']\n",
        "    promptlib[id]['category'] = prompt['category']\n",
        "    promptlib[id][version]['note'] = prompt['note']\n",
        "    promptlib[id][version]['prompt'] = prompt['prompt']\n",
        "\n",
        "\n",
        "def get_prompt_from_lib(promptlib, id, model='default-model', version=None ):\n",
        "    # searches for prompt with given id\n",
        "    # looks for highest available version, if no version is given\n",
        "    if id==None:\n",
        "        prompt_found = None\n",
        "    else:\n",
        "        prompt = promptlib[id]\n",
        "        if version != None:\n",
        "            # version given\n",
        "            version_highest = int(version)\n",
        "        else:\n",
        "            # look for highest available version\n",
        "            version_highest = 0\n",
        "            for key, val in prompt.items():\n",
        "                try:\n",
        "                    version = int(key)\n",
        "                except ValueError:\n",
        "                    version = 0\n",
        "                if version > version_highest:\n",
        "                    version_highest = version\n",
        "        prompt_version = prompt[str(version_highest)]\n",
        "        # return dict\n",
        "        prompt_found = {}\n",
        "        prompt_found['id'] = id\n",
        "        prompt_found['description'] = prompt['description']\n",
        "        prompt_found['category'] = prompt['category']\n",
        "        prompt_found['version'] = str(version_highest)\n",
        "        prompt_found['note'] = prompt_version['note']\n",
        "        prompt_found['prompt'] = prompt_version['prompt']\n",
        "        prompt_found['lang-de'] = prompt_version['lang-de']\n",
        "        prompt_found['lang-en'] = prompt_version['lang-en']\n",
        "        prompt_found['lang-same'] = prompt_version['lang-same']\n",
        "        if model in prompt_version:\n",
        "          prompt_found['input-text-max'] = prompt_version[model]['input-text-max']\n",
        "          prompt_found['length-max-fix'] = prompt_version[model]['length-max-fix']\n",
        "          prompt_found['length-max-dyn'] = prompt_version[model]['length-max-dyn']\n",
        "        else:\n",
        "          prompt_found['input-text-max'] = prompt_version['default-model']['input-text-max']\n",
        "          prompt_found['length-max-fix'] = prompt_version['default-model']['length-max-fix']\n",
        "          prompt_found['length-max-dyn'] = prompt_version['default-model']['length-max-dyn']\n",
        "    return prompt_found\n",
        "\n",
        "def build_prompt_from_template(input_txt, prompt_obj, lang, length_type, length_max, toc_text):\n",
        "  prompt_text =  prompt_obj['prompt']\n",
        "  language_text = prompt_obj[lang]\n",
        "  # calculate max. output lengt dynamically\n",
        "  if length_type != '':\n",
        "    length_template = prompt_obj[length_type]\n",
        "    input_txt2 = re.sub('(?sm)[\\\\\\/\"\\'„“]', '', input_txt)\n",
        "    input_txt2 = re.sub('(?sm)[\\n]', ' ', input_txt2)\n",
        "    length_template2 = length_template.format(input_text = input_txt2, max_len=length_max)\n",
        "    length_text = eval(f\"f'{length_template2}'\")\n",
        "  else:\n",
        "    length_text = ''\n",
        "  # Create the final prompt, fill the variables\n",
        "  # Example: \"Summarize the following text. {language_text} {length_text} Text:```{input_text}``` TOC:```{toc_text}```\"\n",
        "  final_prompt = prompt_text.format(language_text=language_text, length_text=length_text, input_text=input_txt, toc_text=toc_text)\n",
        "  return final_prompt\n",
        "\n",
        "def length_calc(my_text, maxWords):\n",
        "  # maxWords 0.0 - 1.0 (percentage)\n",
        "    return int(wordcount(my_text) * maxWords)\n",
        "\n",
        "def save_promptlib(promptlib):\n",
        "  # saves promptlib to disk\n",
        "  with open('promptlib.dictionary', 'wb') as dict_file:\n",
        "      pickle.dump(promptlib, dict_file)\n",
        "\n",
        "def load_promptlib():\n",
        "  # load promptlib from disk\n",
        "  with open('promptlib.dictionary', 'rb') as dict_file:\n",
        "      promptlib = pickle.load(dict_file)\n",
        "  return promptlib\n",
        "\n"
      ],
      "metadata": {
        "id": "VD9mE55Zkl--"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title\n",
        "test_text1 = 'Die Photosynthese ist ein physiologischer Prozess zur Erzeugung energiereicher Biomoleküle aus energieärmeren Stoffen mit Hilfe\\\n",
        "  von Lichtenergie. Sie wird von Pflanzen, Algen und manchen Bakterien betrieben. Bei diesem biochemischen Vorgang wird Lichtenergie mit Hilfe\\\n",
        "  von lichtabsorbierenden Farbstoffen wie Chlorophyll in chemische Energie umgewandelt. Diese wird dann genutzt, um aus energiearmen\\\n",
        "  anorganischen Stoffen (vor allem Kohlenstoffdioxid (CO2) und Wasser (H2O)) energiereiche organische Verbindungen (vor allem Kohlenhydrate)\\\n",
        "  aufzubauen. Der genutzte Anteil der eingestrahlten Energie, nämlich der zum Aufbau der Assimilate verwendete Anteil, wird photosynthetische\\\n",
        "  Effizienz genannt. Soweit die energiereichen organischen Stoffe zu Bestandteilen des Lebewesens werden, bezeichnet man deren Synthese als\\\n",
        "  Assimilation. Man unterscheidet zwischen oxygener und anoxygener Photosynthese. Bei der oxygenen Photosynthese wird molekularer\\\n",
        "  Sauerstoff (O2) freigesetzt. Bei der anoxygenen Photosynthese, die nur von Bakterien betrieben wird, entstehen statt Sauerstoff andere\\\n",
        "  anorganische Stoffe, beispielsweise elementarer Schwefel (S). Die Photosynthese ist der einzige biochemische Prozess, bei dem\\\n",
        "  Lichtenergie, meistens Sonnenlicht, in chemisch gebundene Energie umgewandelt wird (Phototrophie). Indirekt sind auch fast alle\\\n",
        "  heterotrophen (nicht zur Photosynthese fähigen) Lebewesen von ihr abhängig, da sie der Photosynthese letztlich ihre Nahrung und auch\\\n",
        "  den zur Energiegewinnung mittels aerober Atmung benötigten Sauerstoff verdanken. Aus dem Sauerstoff entsteht außerdem die schützende\\\n",
        "  Ozonschicht der Erdatmosphäre.'\n",
        "test_text2 = f'''\n",
        "# The Potential of AI in Education\n",
        "\n",
        "So, anyone who's been paying attention for the last few months has been seeing headlines like this, especially in education. The thesis has been students are going to be using chat GPT and other forms of AI to cheat, do their assignments, they're not going to learn, and it's going to completely undermine education as we know it.\n",
        "\n",
        "Now what I'm going to argue today is not only are there ways to mitigate all of that, if we put the right guardrails, we do the right things, we can mitigate it, but I think we're at the cusp of using AI for probably the biggest positive transformation that education has ever seen. And the way we're going to do that is by giving every student on the planet an artificially intelligent but amazing personal tutor, and we're going to give every teacher on the planet an amazing, artificially intelligent teaching assistant.  And just to appreciate how big of a deal it would be to give everyone a personal tutor, I show you this clip from Benjamin Bloom's 1984 two-sigma study, or he called it the two-sigma problem.\n",
        "\n",
        "The two-sigma comes from two standard deviations, sigma the symbol for standard deviation, and he had good data that showed that, look, a normal distribution, that's the one that you see in the traditional bell curve right in the middle, that's how the world kind of sorts itself out, that if you were to give personal one-to-one tutoring for students, that you could actually get a distribution that looks like that right, it says tutorial one-to-one with the asterisks, like that right distribution, a two standard deviation improvement. Just to put that in plain language, that could take your average student and turn them into an exceptional student, it can take your below average student and turn them into an above average student.\n",
        "\n",
        "# The Challenge of Scaling Personalized Instruction\n",
        "\n",
        "Now, the reason why he framed it as a problem was he said, well, this is all good, but how do you actually scale group instruction this way? How do you actually give it to everyone in an economic way? What I'm about to show you is, I think, the first moves towards doing that. Obviously, we've been trying to approximate it in some way at Khan Academy for over a decade now, but I think we're at the cusp of accelerating it dramatically.  I'm going to show you the early stages of what RAI, which we call Khan Migo, what it can now do, and maybe a little bit of where it is actually going.  This right over here is a traditional exercise that you or many of your children might have seen on Khan Academy, but what's new is that little bot thing at the right, and we'll start by seeing one of the very important safeguards, which is the conversation is recorded and viewable by your teacher.  It's moderated, actually, by a second AI, and also, it does not tell you the answer.  It is not a cheating tool.  Notice, when the student says, tell me the answer, it says, I'm your tutor.\n",
        "\n",
        "What do you think is the next step for solving the problem? Now, if the student makes a mistake, and this will surprise people who think large language models are not good at mathematics, notice not only does it notice the mistake, it asks the student to explain their reasoning, but it's actually doing what I would say not just even an average tutor would do, but an excellent tutor would do. It's actually able to divine what is probably the misconception in that student's mind, that they probably didn't use the distributive properly.  Remember, we need to distribute the negative two to both the nine and the 2M inside of the parentheses.  This to me is a very, very, very big deal, and it's not just in math.  This is a computer programming exercise on Khan Academy where the student needs to make the clouds part, and so we can see the student starts defining a variable, left X minus minus.\n",
        "\n",
        "# AI as a Super Tutor\n",
        "\n",
        "It only made the left cloud part, but then they can ask a con amigo, what's going on? Why is only the left cloud moving? And it understands the code. It knows all the context of what the student is doing, and it understands that those ellipses are there to draw clouds, which I think is kind of mind-blowing, and it says, to make the right cloud move as well, try adding a line of code inside the draw function that increments the right X variable by one pixel in each frame.  Now, this one is maybe even more amazing, because we have a lot of math teachers.  We've all been trying to teach the world to code, but there aren't a lot of computing teachers out there, and what you just saw, even when I'm tutoring my kids when they're learning to code, I can't help them this well, this fast.  This is really going to be a super tutor.  And it's not just exercises.  It understands what you're watching.\n",
        "\n",
        "It understands the context of your video. It can answer the age-old question, why do I need to learn this? And it asks, socratically, well, what do you care about? And let's say the student says, I want to be a professional athlete, and it says, well, learning about the size of cells, which is what this video is about, that could be really useful for understanding nutrition and how your body works, et cetera.  It can answer questions.  It can quiz you.  It can connect it to other ideas.  You can now ask as many questions of a video as you could ever dream of.  So another big shortage out there, I remember the high school I went to, the student-to-guidance counselor ratio was about 200 or 300 to 1.  A lot of the country, it's worse than that.  We can use Conmigo to give every student a guidance counselor, academic coach, career coach, life coach, which is exactly what you see right over here.  And this is all, you know, we launched this with the GPT-4 launch.  We have a few thousand people on this.  This isn't a fake demo.\n",
        "\n",
        "§§§\n",
        "\n",
        "# Conversations with Historical Figures and AI Debates\n",
        "\n",
        "This is really in action. And then there's, you know, things that I think it would have been even harder, it would have been a little science fiction to do with even a traditional tutor.  There's a student, we run an online high school with Arizona State University called Khan World School.  And we have a student who attends that online school based in India, her name is Sanvi, and she was doing a report on the Great Gatsby.  And when she was reading the Great Gatsby, Jay Gatsby keeps looking at the green light off into the distance.  And she's like, well, why does he do that? She did some web searches, and people have obviously studied this and commented about the symbolism of that, but none of it was really resonating with her.  And then she realized that she had Conmigo and that she could talk to Jay Gatsby himself.\n",
        "\n",
        "# Unlocking Learning Literature and AI Debates\n",
        "\n",
        "And so, ah, splendid choice, old sport, I am now Jay Gatsby, the enigmatic millionaire from Escott Jarrell's classic. And so why do you keep staring at the green light? Ah, the green light, old sport.  It's a symbol of my dreams and desires, you see.  It's situated at the end of Daisy Buchanan's dock, across the bay from my mansion.  I gaze at it longingly as it represents my yearning for the past and my hope to reunite with Daisy, the love of my life.  And what was cool is Sanvi had said, I had this long conversation, she called him Mr.  Gatsby.  And at the end, she actually apologized for taking his time, which I thought was very polite of her.  But you can imagine, this unlocks learning literature, learning, you can talk to historical figures, we're even probably going to add an activity, you can talk to, like, the Mississippi River.  It brings things to life in ways that really were science fiction even six months or a year ago.  Students can get into debates with the AI.  And we've got, here's the students debating whether we should cancel student debt.  The student is against canceling student debt.  And we've gotten very clear feedback.  We've started running it at Con World School and our lab school that we have, Con Lab School.  The students, the high school students especially, they're saying, this is amazing to be able to fine tune my arguments without fearing judgment.\n",
        "\n",
        "# Enhancing Language Arts with AI Writing Collaboration\n",
        "\n",
        "It makes me that much more confident to kind of go into the classroom and really participate. And we all know that Socratic dialogue debate is a great way to learn.  But frankly, it's not out there for most students.  But now it can be accessible to hopefully everyone.  A lot of the narrative, we saw that in the headlines, has been it's going to do the writing for kids.  Kids are not going to learn to write.  But we are showing that there's ways that the AI doesn't write for you.  It writes with you.  So this is a little thing.  And my eight-year-old is addicted to this.  And he's not a kid that really liked writing before.  But where, you know, you could say, I want to write a horror story.  And it says, ooh, a horror story.  How spine-tingling and thrilling.  Let's dive into the world of eerie shadows and chilling mysteries.\n",
        "\n",
        "And this is an activity where the student will write two sentences. And then the AI will write two sentences.  And so they collaborate together on a story.  The students write, Beatrice was a misunderstood ghost.  She wanted to make friends but kept scaring them by accident.  And the AI says, poor Beatrice, a lonely spirit yearning for companionship.  One day she stumbled upon an old abandoned mansion, et cetera, et cetera.  I encourage you all to, you know, hopefully one day try this.  This is surprisingly fun.  Now to even more directly hit this use case.  And what I'm about to show you, everything I showed you so far is actually already part of Calmigo.  What I'm about to show you, we haven't shown to anyone yet.\n",
        "\n",
        "# Enhancing Reading Comprehension and Writing Skills with AI\n",
        "\n",
        "This is a prototype. We hope to be able to launch it in the next few months.  But this is to directly use AI, use generative AI, to not undermine English and language arts but to actually enhance it in ways that we couldn't have even conceived of even a year ago.  This is reading comprehension.  This is the students reading Steve Jobs' famous speech at Stanford.  And then as they get to certain points, they can click on that little question.  And the AI will then, Socratically, almost like an oral exam, ask the student about things.  And the AI can highlight parts of the passage.  Why did the author use that word? What was their intent? Does it back up their argument? They can start to do stuff that, once again, we never had the capability to give everyone a tutor, everyone a writing coach, to actually dig into reading at this level.  And you could go on the other side of it.  We have a whole workflow that helps them write, helps them be a writing coach, draw an outline.  But once a student actually constructs a draft, and this is where they're constructing a draft, they can ask for feedback, once again, as you would expect from a good writing coach.  In this case, the student we'll say, let's say, does my evidence support my claim? And then the AI not only is able to give feedback, but it's able to highlight certain parts of the passage and says, you know, on this passage, this doesn't quite support your claim, but once again, Socratically says, can you tell us why? So it's pulling the student, it's making them a better writer, giving them far more feedback than they've ever been able to actually get before, and we think this is going to dramatically accelerate writing, not hurt it.\n",
        "\n",
        "§§§\n",
        "\n",
        "# Personalized Education for Teachers\n",
        "Now, everything I've talked about so far is for the student, but we think this could be equally as powerful for the teacher to drive more personalized education and, frankly, save time and energy for themselves and for their students. So this is an American history exercise on Khan Academy.  It's a question about the Spanish-American war.  And at first, it's in student mode, and if you say, tell me the answer, it's not going to tell the answer, it's going to go into tutoring mode.  But that little toggle which teachers have access to, they can turn student mode off, and then it goes into teacher mode.  And what this does is, it turns into, you could view it as a teacher's guide on steroids.  Not only can it explain the answer, it can explain how you might want to teach it.\n",
        "\n",
        "# Benefits for Teachers\n",
        "It can help prepare the teacher for that material. It can help them create lesson plans, as you can see doing right there.  It'll eventually help them create progress reports, it'll help them eventually grade.  So once again, teachers spend about half their time with this type of activity, lesson planning, all of that energy can go back to them or go back to human interactions with their actual students.  So, you know, one point I want to make, these large language models are so powerful, there's a temptation to say, well, all these people are just going to slap them onto their websites, and it kind of turns the applications themselves into commodities.  And what I've got to tell you is, I kind of thought that's one of the reasons why I didn't sleep for two weeks when I first had access to GPT-4 back in August.\n",
        "\n",
        "# Enhancing AI Tutoring\n",
        "But we quickly realized that to actually make it magical, I think it's really important to make it magical, but we quickly realized that to actually make it magical, I think what you saw with Conmigo a little bit, it didn't interact with you the way that you see chat GPT interacting, it was a little bit more magical, it was more Socratic, it was clearly much better at math than what most people are used to thinking. And the reason is there was a lot of work behind the scenes to make that happen.  And I could go through the whole list of everything we've been working on, many, many people, for over six, seven months, to make it feel magical, but perhaps the most intellectually interesting one is we realized, and this was an idea from an open AI researcher, that we could dramatically improve its ability in math and its ability in tutoring if we allowed the AI to think before it speaks.\n",
        "\n",
        "# The Future of AI and Education\n",
        "So if you're tutoring someone and you immediately just start talking before you assess their math, you might not get it right. But if you construct thoughts for yourself, and what you see on the right there is an actual AI thought, something that it generates for itself but it does not share with the student, then its accuracy went up dramatically and its ability to be a world-class tutor went up dramatically.  And you can see it's talking to itself here.  It says, the student got a different answer than I did, but do not tell them they made a mistake.  Instead, ask them to explain how they got to that step.  So I'll just finish off.\n",
        "\n",
        "# The Role of AI in Education and the Need for Positive Use Cases\n",
        "Hopefully, what I've just shown you is just half of what we are working on, and we think this is just the very tip of the iceberg of where this can actually go. And I'm pretty convinced, which I wouldn't have been even a year ago, that we, together, have a chance of addressing the two-sigma problem and turning it into a two-sigma opportunity, dramatically accelerating education as we know it.  Now, just to take a step back at a meta-level, obviously, we heard a lot today, the debates on either side.  There's folks who take a more pessimistic view of AI.  They say, this is scary, there's all these dystopian scenarios.  We maybe want to slow down.  We want to pause.  On the other side, there are the more optimistic folks who say, well, we've gone through inflection points before.\n",
        "\n",
        "We've gone through the Industrial Revolution. It was scary, but it all kind of worked out.  And what I'd argue right now is, I don't think this is like a flip of a coin or this is something where we'll just have to wait and see which way it turns out.  I think everyone here and beyond, we are active participants in this decision.  I'm pretty convinced that the first line of reasoning is actually almost a self-fulfilling prophecy, that if we act with fear and if we say, hey, we just got to stop doing this stuff, what's really going to happen is the rule followers might pause, might slow down, but the rule breakers, as Alexander mentioned, the totalitarian governments, the criminal organizations, they're only going to accelerate.\n",
        "\n",
        "And that leads to what I am pretty convinced is the dystopian state, which is the good actors have worse AIs than the bad actors. But I'll also talk to the optimist a little bit.  I don't think that means that, oh yeah, then we should just relax and just hope for the best.  That might not happen either.  I think all of us together have to fight like hell to make sure that we put the guardrails, we put in, when the problems arise, reasonable regulations, but we fight like hell for the positive use cases.  Because very close to my heart, and obviously there's many potential positive use cases, perhaps the most powerful use case, and perhaps the most poetic use case, is if AI, artificial intelligence, can be used to enhance HI, human intelligence, human potential and human purpose.  Thank you.  Thank you.  Thank you.\n",
        "'''"
      ],
      "metadata": {
        "id": "z9v5qGPi3JWQ",
        "cellView": "form"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tmp = split_text_by_separator(test_text1, '\\n', '\\n', 'fix-nothing', 200)\n",
        "print(text_stats(test_text1))\n",
        "print(len(tmp))"
      ],
      "metadata": {
        "id": "52U-Eixu4ESb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ec4c4e2c-3337-4ccd-e7f6-de8815656ebc"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of words / paragraphs / §§§ segements: 197 / 1 / 1\n",
            "1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title\n",
        "# Talk to model\n",
        "\n",
        "from datetime import datetime\n",
        "import langchain\n",
        "from langchain.chains import RetrievalQA\n",
        "from langchain.llms import OpenAI\n",
        "from langchain.chat_models import ChatOpenAI\n",
        "from langchain.schema import (AIMessage, HumanMessage, SystemMessage)\n",
        "from langchain.document_loaders import WebBaseLoader\n",
        "from langchain.embeddings import OpenAIEmbeddings\n",
        "from langchain.indexes import VectorstoreIndexCreator\n",
        "from langchain.prompts import PromptTemplate\n",
        "from langchain.vectorstores import Chroma\n",
        "from langchain.schema import HumanMessage\n",
        "from langchain.callbacks.base import BaseCallbackHandler\n",
        "import pypandoc\n",
        "\n",
        "# OpenAI Key\n",
        "openAI_key = creds['OpenAI']['v2']['credential']\n",
        "\n",
        "def create_test_project(proj_name, proj_text):\n",
        "  create_file_directory(proj_name, False)\n",
        "  create_file_directory(proj_name + '/' +  folders['text-input'], False)\n",
        "  create_file_directory(proj_name + '/' +  folders['text-output'], False)\n",
        "  create_file_directory(proj_name + '/' +  folders['text-output-logs'], False)\n",
        "  if proj_text != '':\n",
        "    f= open(proj_name + '/' +  folders['text-input'] + '/testfile.txt','w+')\n",
        "    f.write(proj_text)\n",
        "    f.close()\n",
        "\n",
        "\n",
        "def execute_prompt (exec_params):\n",
        "  #    'model':'no',\n",
        "  #    'prompt-name': prompt_name,\n",
        "  #    'prompt-version': prompt_version,\n",
        "  #    'prompt-comment': prompt_comment,\n",
        "  #    'loglevel':0,\n",
        "  #    'stop-after-step':5,\n",
        "  #    'proj-name': proj_name,\n",
        "  #    'input-filepath': '',\n",
        "  #    'input-filename': '',\n",
        "  #    'folders': folders,\n",
        "  #    'prompt-obj': prompt_obj,\n",
        "  #    'language': 'lang-de',\n",
        "  #    'length-type': 'length-max-dyn',\n",
        "  #    'length-max': 0.5,\n",
        "  #    'toc-text': 'some toc-text',\n",
        "  #    'result-filename': 'paraphrased.txt'\n",
        "\n",
        "  # Read file from disk\n",
        "  if exec_params['input-filename'] != '':\n",
        "    input_file_path = exec_params['proj-name'] + '/' + exec_params['input-filepath'] + '/' + exec_params['input-filename']\n",
        "  else:\n",
        "    input_file_path = find_files(exec_params['proj-name'] + '/' + exec_params['folders']['text-input'], ['.txt','.md'], False)[0]\n",
        "  f= open(input_file_path,'r')\n",
        "  if f.mode == 'r': input_text =f.read()\n",
        "  f.close()\n",
        "  # if input text is output from a prevoius step, strip out Logs\n",
        "  input_text = input_text.split('=== LOGS: ===')[0]\n",
        "\n",
        "  # remove special characters\n",
        "  # input_text = remove_special_chars(input_text, 1) # level 1\n",
        "\n",
        "  # email.[^[\\[1\\]]{.underline}^](\\l)\n",
        "\n",
        "  if exec_params['loglevel'] >= 1:\n",
        "    print(json.dumps(exec_params['prompt-obj'], sort_keys=False, indent=2) + '\\n')\n",
        "    #print(textwrap.fill(input_text, 120) + '\\n')\n",
        "\n",
        "  llm = ChatOpenAI(model_name=exec_params['model'], temperature=0.0, openai_api_key=openAI_key)\n",
        "  # model overview see https://gptforwork.com/guides/openai-gpt3-models\n",
        "\n",
        "  #input_text_segments = input_text.split(\"§§§\")\n",
        "  input_text_segments = split_text_by_separator(input_text, '\\n', '\\n', 'fix-nothing', exec_params['prompt-obj']['input-text-max'])\n",
        "  output_text_segments = []\n",
        "\n",
        "  log_detail_model = 'Model: ' + exec_params['model']\n",
        "  print(log_detail_model)\n",
        "  log_time_start = 'Started at: ' + datetime.now().strftime(\"%H:%M:%S\") + '\\n'\n",
        "  print(log_time_start)\n",
        "  timer_start = time.time()\n",
        "\n",
        "  log_prompt = '\\n\\n\\n***********************\\n\\n# Promptname: ' + exec_params['prompt-name'] + ', Version: ' + str(exec_params['prompt-version'])  + '\\n'\n",
        "  log_prompt = '\\n' + log_prompt + exec_params['prompt-comment'] + '\\n\\n\\n'\n",
        "  prompt_obj_for_log = json.dumps(exec_params['prompt-obj'], sort_keys=False, indent=2).replace('\\n', '<br>')\n",
        "  prompt_obj_for_log = prompt_obj_for_log.replace(' ', '&nbsp;')\n",
        "  prompt_obj_for_log = prompt_obj_for_log.replace('`', '\\`')\n",
        "  log_prompt = log_prompt +  prompt_obj_for_log\n",
        "  log_input_output_compare = '\\n\\n\\n***********************\\n\\n# Compare input and output texts (' + log_detail_model + ')\\n'\n",
        "  log_input_SHORT = '\\n\\n\\n***********************\\n\\n# Prompts (Input Text shortened)\\n'\n",
        "  log_input = '\\n\\n\\n***********************\\n\\n# Prompts (Full length)\\n'\n",
        "  log_input_output = '\\n\\n\\n***********************\\n\\n# Prompts and anwers (Full length)\\n'\n",
        "\n",
        "  for index, input_text in enumerate(input_text_segments):\n",
        "\n",
        "      log_detail = 'Processing step ' + str(index + 1) + ' of ' + str(len(input_text_segments))\n",
        "      print(log_detail)\n",
        "\n",
        "      #print('TEXT FROM ARRAY:')\n",
        "      #print(textwrap.fill(input_text, 120) + '\\n')\n",
        "\n",
        "      prompt_txt_final = remove_all_double_whitespace(\n",
        "          build_prompt_from_template(input_text, exec_params['prompt-obj'], exec_params['language'], exec_params['length-type'], exec_params['length-max'], exec_params['toc-text'])\n",
        "          )\n",
        "      # Shorten input text for logging purposes\n",
        "      #input_txt_short = re.findall('(?sm)```(.+)```', prompt_txt_final)[0][:30]\n",
        "      #prompt_txt_final_SHORT = re.sub('(```)(.+)(```)', r'\\1' + input_txt_short + '...' + r'\\3' , prompt_txt_final)\n",
        "      prompt_txt_final_SHORT = prompt_txt_final[:800]\n",
        "      if exec_params['loglevel'] <= 1:\n",
        "        print(textwrap.fill(prompt_txt_final_SHORT, 120) + '\\n')\n",
        "      if exec_params['loglevel'] == 2:\n",
        "        print(textwrap.fill(prompt_txt_final, 120) + '\\n')\n",
        "\n",
        "      if exec_params['model'] != 'no':\n",
        "        gpt_response_obj = llm.generate([[HumanMessage(content=prompt_txt_final)]])\n",
        "        tmp_text = gpt_response_obj.generations[0][0].text\n",
        "        tmp_tokens = gpt_response_obj.llm_output\n",
        "        if exec_params['loglevel'] >= 1:\n",
        "          print('*** Resonse: ***')\n",
        "          print(textwrap.fill(tmp_text, 120) + '\\n')\n",
        "        print(str(tmp_tokens) + '\\n')\n",
        "        output_text_segments.append(tmp_text)\n",
        "      else:\n",
        "        tmp_text = '... Response from model ...'\n",
        "\n",
        "      # Log prompts\n",
        "      log_input = log_input + log_detail + '\\n' + prompt_txt_final + '\\n\\n'\n",
        "      log_input_SHORT = log_input_SHORT + log_detail + '\\n' + prompt_txt_final_SHORT + '\\n\\n'\n",
        "      log_input_output = log_input_output + log_detail + '\\n' + prompt_txt_final + '\\n\\n' + tmp_text + '\\n\\n\\n'\n",
        "\n",
        "      # Log input / output comparison\n",
        "      log_text = ''\n",
        "      log_text = log_text + '| Step | ' + str(index + 1) + ' of ' + str(len(input_text_segments)) + ' |\\n'\n",
        "      log_text = log_text + '| -------- | ------- |\\n'\n",
        "      log_text = log_text + '| ' + str(wordcount(input_text)) + ' | ' + str(wordcount(tmp_text)) + ' |\\n'\n",
        "      log_text = log_text + '| ' + input_text.replace('\\n','<br />') + ' | ' + tmp_text.replace('\\n','<br />') + ' |\\n'\n",
        "      log_text = log_text + '\\n'\n",
        "\n",
        "      log_input_output_compare = log_input_output_compare + log_text\n",
        "\n",
        "      # check if not all text segments/steps should be processed (eg. for debugging)\n",
        "      if (index+1) == exec_params['stop-after-step']:\n",
        "        break\n",
        "\n",
        "  timer_end = time.time()\n",
        "  timer_duration_secs = int(timer_end - timer_start)\n",
        "  timer_duration_mins = int(timer_duration_secs/60*10)/10\n",
        "\n",
        "  log_time_end = '\\nEnded at: ' + datetime.now().strftime(\"%H:%M:%S\") + '\\n\\nDuration: ' + str(timer_duration_mins) + ' Minutes\\n'\n",
        "  print(log_time_end)\n",
        "  log_time = '\\n\\n\\n***********************\\n\\n# Duration\\n' + str(timer_duration_secs) + ' Seconds\\n' + str(timer_duration_mins) + ' Minutes\\n' + log_time_start + '\\n' + log_time_end\n",
        "\n",
        "  full_output_text = '\\n\\n'.join(output_text_segments)\n",
        "\n",
        "  dot_pos = exec_params['result-filename'].rfind('.')\n",
        "  input_text_filename_only1 = exec_params['result-filename'][:dot_pos]\n",
        "  input_text_filename_only2 = exec_params['result-filename'][dot_pos:]\n",
        "  output_filename_with_model = input_text_filename_only1 + '_' + exec_params['model'][:5] + input_text_filename_only2\n",
        "\n",
        "  # save prompt log to disk\n",
        "  save_and_backup(\n",
        "      exec_params['proj-name'] + '/' + exec_params['folders']['text-output-logs'],\n",
        "      output_filename_with_model + '.log.md',\n",
        "      log_prompt + log_time + log_input_output_compare + log_input_SHORT + log_input + log_input_output,\n",
        "      True) # create .docx\n",
        "\n",
        "  # save full output to disk\n",
        "  save_and_backup(\n",
        "      exec_params['proj-name'] + '/' + exec_params['folders']['text-output'],\n",
        "      output_filename_with_model,\n",
        "      full_output_text + '\\n\\n=== LOGS: ===\\n\\n\\n\\n' + log_prompt + log_time + log_input_output_compare + log_input_SHORT + log_input + log_input_output,\n",
        "      True) # create .docx\n",
        "\n",
        "  # Always create .zip archive in root directory (for download)\n",
        "  shutil.make_archive(exec_params['proj-name'], 'zip', exec_params['proj-name'])\n",
        "\n",
        "  # return output path and filename (tuple)\n",
        "  return exec_params['proj-name'] + '/' + exec_params['folders']['text-output'], output_filename_with_model\n",
        "\n",
        "\n",
        "\n",
        "def execute_project(proj_name, model, prompt_lib, prompt_id, prompt_version, length_max_dyn, toc_text, stop_after_step, delete_output_dirs, folders, input_text_string, prompt_comment):\n",
        "  create_test_project(proj_name, '')\n",
        "  if delete_output_dirs == True:\n",
        "    create_file_directory(proj_name + '/' + folders['text-output'], True)\n",
        "    create_file_directory(proj_name + '/' + folders['text-output-logs'], True)\n",
        "  # if input_text is contains '<File: >' do not create text file\n",
        "  filename_regex = re.findall('(?sm)<File:>', input_text_string)\n",
        "  if not filename_regex:\n",
        "    # Save text to input dir\n",
        "    f= open(proj_name + '/' + folders['text-input'] + '/input.txt','w+')\n",
        "    f.write(input_text_string)\n",
        "    f.close()\n",
        "  else:\n",
        "    # Check, if docx file is in input dir\n",
        "    print('chechking for docx.')\n",
        "    input_files_all = find_files(proj_name + '/' + folders['text-input'], [''], False)\n",
        "    input_files_docx = find_files(proj_name + '/' + folders['text-input'], ['.docx'], False)\n",
        "    if (len(input_files_all) == 1) and (len(input_files_docx) == 1):\n",
        "      #convert docx to md\n",
        "      dot_pos = input_files_docx[0].rfind('.')\n",
        "      output_filename = input_files_docx[0][:dot_pos] + '.md'\n",
        "      md_file = pypandoc.convert_file(input_files_docx[0], 'md', outputfile=output_filename)\n",
        "\n",
        "  prompt_obj = get_prompt_from_lib(prompt_lib, prompt_id, model, prompt_version)\n",
        "  #print(json.dumps(prompt_obj, sort_keys=False, indent=2))\n",
        "  result_text = execute_prompt({\n",
        "      'model': model,\n",
        "      'prompt-name': prompt_id,\n",
        "      'prompt-version': prompt_version,\n",
        "      'prompt-comment': prompt_comment,\n",
        "      'loglevel': 0,\n",
        "      'stop-after-step': stop_after_step,\n",
        "      'proj-name': proj_name,\n",
        "      'input-filepath': '',\n",
        "      'input-filename': '',\n",
        "      'folders': folders,\n",
        "      'prompt-obj': prompt_obj,\n",
        "      'language': 'lang-same',\n",
        "      'length-type': length_max_dyn,\n",
        "      'length-max': 0.5,\n",
        "      'toc-text': toc_text,\n",
        "      'result-filename': 'response.md'\n",
        "  })\n",
        "  return result_text\n"
      ],
      "metadata": {
        "id": "owpR0O6MTAEz"
      },
      "execution_count": 99,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Gradio App"
      ],
      "metadata": {
        "id": "g89pWgpuUQI3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if (ios_mode == False) and (start_gradio_webapp == True):\n",
        "  import gradio as gr\n",
        "\n",
        "  # Theming\n",
        "  theme = gr.themes.Default(\n",
        "      primary_hue=\"slate\" # , radius_size=gr.themes.Size(radius_sm=\"3px\", radius_xs=\"2px\", radius_xxs=\"1px\")\n",
        "  )\n",
        "  # Styling: Change max width\n",
        "  css = \"\"\"\n",
        "    .gradio-container {max-width: 700px!important}\n",
        "    .vspacer1 {margin-top: 50px}\n",
        "  \"\"\"\n",
        "\n",
        "  with gr.Blocks(theme=theme, css=css) as demo:\n",
        "\n",
        "      gr.Markdown(\"# ChatGPTLab 2.0\", elem_classes=\"vspacer1\")\n",
        "      gr.Markdown(\"### Optimizing your work with LLMs.\")\n",
        "\n",
        "      project_name = gr.Textbox(label=\"Project name\")\n",
        "\n",
        "      #\n",
        "      # 1. Input Text\n",
        "      #\n",
        "      with gr.Tab(\"Input Text \"):\n",
        "        gr.Markdown(\"Please enter text\")\n",
        "\n",
        "        # Input text via UI\n",
        "        gr.Markdown(\"### Input your text:\")\n",
        "        text_input = gr.Textbox(label=\"Enter text\", placeholder=\"Your text here...\", lines=10)\n",
        "        text_output = gr.Textbox(label=\"Result\")\n",
        "\n",
        "        def text_save(text, proj_name):\n",
        "          create_file_directory(proj_name, False)\n",
        "          create_file_directory(proj_name + '/' +  folders['text-input'], False)\n",
        "          f= open(proj_name + '/' +  folders['text-input'] + '/input_text.txt','w+')\n",
        "          f.write(text)\n",
        "          f.close()\n",
        "          log_text = \"Text saved.\"\n",
        "          return log_text\n",
        "        text_button = gr.Button(\"Save text\")\n",
        "        text_button.click(text_save, [text_input, project_name], text_output)\n",
        "\n",
        "        gr.Markdown(\"\")\n",
        "        gr.Markdown(\"\")\n",
        "\n",
        "        # Input text via upload\n",
        "        gr.Markdown(\"### Or upload your text:\")\n",
        "        upload_button = gr.UploadButton(\"Click to Upload a File\", file_types=[\".txt\",\".md\"], file_count=\"single\")\n",
        "        file_output = gr.Textbox(label=\"Result\")\n",
        "\n",
        "        def upload_file(my_file, proj_name):\n",
        "          create_file_directory(proj_name, False)\n",
        "          create_file_directory(proj_name + '/' +  folders['text-input'], False)\n",
        "          # copy to project directory\n",
        "          full_upload_path = my_file.name\n",
        "          just_the_filename = os.path.basename(full_upload_path)\n",
        "          full_text_path = \"./\" + proj_name + '/' + folders['text-input'] + '/' + just_the_filename\n",
        "          shutil.copyfile(full_upload_path, full_text_path)\n",
        "          # check if file is empty\n",
        "          f= open(full_text_path,'r')\n",
        "          if f.mode == 'r': contents =f.read()\n",
        "          f.close()\n",
        "          log_text = just_the_filename + \"\\n\"\n",
        "          if len(contents) == 0:\n",
        "            log_text = log_text + \"Error: Upload file lengt 0 bytes\"\n",
        "          else:\n",
        "            log_text = log_text + \"Upload successful\"\n",
        "          return log_text\n",
        "        upload_button.upload(upload_file, [upload_button, project_name], file_output)\n",
        "\n",
        "      #\n",
        "      # 2. Download full project\n",
        "      #\n",
        "      with gr.Tab(\"Download\"):\n",
        "        gr.Markdown(\"Download full project as ZIP file.\")\n",
        "        download_button = gr.Button(\"Download project\")\n",
        "        download_output = gr.File()\n",
        "\n",
        "        def download_do(proj_name):\n",
        "          full_text_path = \"./\" + proj_name\n",
        "          shutil.make_archive('archive', 'zip', full_text_path)\n",
        "          result = \"Downloading \" + full_text_path\n",
        "          return \"archive.zip\"\n",
        "        download_button.click(download_do, project_name, download_output)\n",
        "\n",
        "      #\n",
        "      # 3. xxx\n",
        "      #\n",
        "      with gr.Tab(\"Step 2\"):\n",
        "        gr.Markdown(\"Please select the optimization:\")\n",
        "        radio = gr.Radio(\n",
        "          [\"by headline\", \"by paragraph\", \"by §§§\"], label=\"Text split method\"\n",
        "        )\n",
        "        name = gr.Textbox(label=\"Name\", placeholder=\"Enter text...\")\n",
        "        output = gr.Textbox(label=\"Output Box\")\n",
        "        greet_btn = gr.Button(\"Start\", scale=0)\n",
        "        def greet(name):\n",
        "          result = \"HALLO \" + name + \"!!!\"\n",
        "          return result\n",
        "        greet_btn.click(fn=greet, inputs=name, outputs=output, api_name=\"greet\")\n",
        "\n",
        "  demo.launch(quiet=True, share=True, debug=debug_mode)\n",
        "\n",
        "else:\n",
        "  print('iOS Mode - Nothing to do.')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ShdVRDZIUR7k",
        "outputId": "b803de2c-5347-45d8-92f3-9fefb9f980f2"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "iOS Mode - Nothing to do.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Test GPT"
      ],
      "metadata": {
        "id": "f34XuANJ6vIf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# test promptlib and templates\n",
        "\n",
        "import textwrap\n",
        "\n",
        "prompt_obj = get_prompt_from_lib(promptlib_global, 'summary-bullets', '1')\n",
        "# prompt_obj = get_prompt_from_lib(promptlib_global, 'summary-bullets', '1')\n",
        "print(json.dumps(prompt_obj, sort_keys=True, indent=2))\n",
        "\n",
        "input_text = 'This is the input text. Lorem ipsum.'\n",
        "\n",
        "prompt_txt_final1 = build_prompt_from_template(input_text, prompt_obj, 'lang-de', 'length-max-dyn', 0.5, 'toc')\n",
        "prompt_txt_final2 = build_prompt_from_template(input_text, prompt_obj, 'lang-de', 'length-max-fix', 0, '')\n",
        "prompt_txt_final3 = build_prompt_from_template(input_text, prompt_obj, 'lang-de', '', 0, '')\n",
        "print(textwrap.fill(prompt_txt_final1, 120))\n",
        "\n",
        "#write_prompt_to_lib(prompt_obj)\n",
        "\n",
        "#print(json.dumps(promptlib, sort_keys=True, indent=2))\n",
        "\n",
        "# myprompt = \"The given text is delimited by triple backticks. Summarize the current text to succint and clear bullet points of its contents.\n",
        "#          The length of the summary must be 200 words maximum.\"\n",
        "# myprompt = \"The given text is delimited by triple backticks.\n",
        "#           Summarize the current text to a maximum of 15 succint and clear bullet points of its contents.\"\n",
        "# myprompt = myprompt + \"The maximum number of words should be 300 words in total. \"\n",
        "# myprompt = myprompt + \"Write everything in German language. \" # this is optional !\n",
        "# myprompt = myprompt + \"```\" + input_text + \"```\""
      ],
      "metadata": {
        "id": "OsYX9xQ2mjZd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cb05c17b-d542-421f-9fcb-2032918cd551"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\n",
            "  \"category\": \"summarize\",\n",
            "  \"description\": \"Max word length: 1100 for EN, 900 for DE. approx. 1 min processing time Example: Full book: 113 parts \\u00e1 1000 words takes 15 min.\",\n",
            "  \"id\": \"summary-bullets\",\n",
            "  \"input-text-max\": 500,\n",
            "  \"lang-de\": \"Write everything in German language.\",\n",
            "  \"lang-en\": \"Write everything in English language.\",\n",
            "  \"lang-same\": \"If the following text in triple backticks is in German language write your text in German language, too.\",\n",
            "  \"length-max-dyn\": \"The length of the summary must be {{length_calc(\\\"{input_text}\\\", {max_len})}} words maximum.\",\n",
            "  \"length-max-fix\": \"The length of the summary must be 300 words maximum.\",\n",
            "  \"note\": \"summarize to bullets v2\",\n",
            "  \"prompt\": \"The given text is delimited by triple backticks. Summarize the current text to a maximum of 15 succint            and clear bullet points of its contents. {language_text} {length_text} Text:```{input_text}``` {toc_text}\",\n",
            "  \"version\": \"2\"\n",
            "}\n",
            "The given text is delimited by triple backticks. Summarize the current text to a maximum of 15 succint            and\n",
            "clear bullet points of its contents. Write everything in German language. The length of the summary must be 3 words\n",
            "maximum. Text:```This is the input text. Lorem ipsum.``` toc\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "info_1.layout.visibility = \"hidden\"\n",
        "info_1.close()\n",
        "del info_1\n",
        "button_1.layout.visibility = \"visible\"\n",
        "button_2.layout.visibility = \"visible\"\n",
        "button_3.layout.visibility = \"visible\"\n",
        "button_4.layout.visibility = \"visible\"\n",
        "#text_1.value=\"yoyo\""
      ],
      "metadata": {
        "id": "J2HUTsPjygWN"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Workbench"
      ],
      "metadata": {
        "id": "-75HtkuDz9eP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "proj_name = 'S4HANA'\n",
        "#create_file_directory(proj_name, True) # For dev: Initial folder structure\n",
        "#create_file_directory(proj_name + '/' + folders['text-output'], True)\n",
        "#create_file_directory(proj_name + '/' + folders['text-output-logs'], True)\n",
        "#create_test_project(proj_name, '')\n",
        "\n",
        "# Step 1\n",
        "def step_1():\n",
        "  model = 'gpt-3.5-turbo'\n",
        "  prompt_name = 'summary-shortened'\n",
        "  prompt_version = '1'\n",
        "  prompt_comment = 'TODO: HIER EINE NOTIZ. HIER EINE NOTIZ. HIER EINE NOTIZ. HIER EINE NOTIZ.'\n",
        "  prompt_obj = get_prompt_from_lib(promptlib_global, prompt_name, model, prompt_version)\n",
        "  #print(json.dumps(prompt_obj, sort_keys=False, indent=2))\n",
        "  result_file = execute_prompt({\n",
        "      'model': model,\n",
        "      'prompt-name': prompt_name,\n",
        "      'prompt-version': prompt_version,\n",
        "      'prompt-comment': prompt_comment,\n",
        "      'loglevel': 0,\n",
        "      'stop-after-step': 1,\n",
        "      'proj-name': proj_name,\n",
        "      'input-filepath': '', #'text-output',\n",
        "      'input-filename': '', #'paraphrased.txt',\n",
        "      'folders': folders,\n",
        "      'prompt-obj': prompt_obj,\n",
        "      'language': 'lang-de',\n",
        "      'length-type': 'length-max-dyn',\n",
        "      'length-max': 0.5,\n",
        "      'toc-text': '',\n",
        "      'result-filename': '01-paraphr-short.md'\n",
        "  })\n",
        "  print(result_file)\n",
        "  a, b = result_file\n",
        "  print(a)\n",
        "  print(b)\n",
        "\n",
        "# Step 2\n",
        "def step_2():\n",
        "  model = 'gpt-3.5-turbo'\n",
        "  prompt_name = 'create-subheadlines'\n",
        "  prompt_version = '1'\n",
        "  prompt_obj = get_prompt_from_lib(promptlib_work, prompt_name, model, prompt_version)\n",
        "  #print(json.dumps(prompt_obj, sort_keys=False, indent=2))\n",
        "  result_file = execute_prompt({\n",
        "      'model': model,\n",
        "      'prompt-name': prompt_name,\n",
        "      'prompt-version': prompt_version,\n",
        "      'loglevel': 0,\n",
        "      'stop-after-step': 3,\n",
        "      'proj-name': proj_name,\n",
        "      'input-filepath': 'text-output',\n",
        "      'input-filename': '01-paraphr-short_gpt-3.md',\n",
        "      'folders': folders,\n",
        "      'prompt-obj': prompt_obj,\n",
        "      'language': 'lang-same',\n",
        "      'length-type': '',\n",
        "      'length-max': 0,\n",
        "      'toc-text': '',\n",
        "      'result-filename': '01-paraphr-short-headlines.md'\n",
        "  })\n",
        "\n",
        "# Step 3\n",
        "def step_3():\n",
        "  model = 'gpt-3.5-turbo'\n",
        "  prompt_name = 'summary-shortened'\n",
        "  prompt_version = '1'\n",
        "  prompt_obj = get_prompt_from_lib(promptlib_work, prompt_name, model, prompt_version)\n",
        "  #print(json.dumps(prompt_obj, sort_keys=False, indent=2))\n",
        "  result_file = execute_prompt({\n",
        "      'model': model,\n",
        "      'prompt-name': prompt_name,\n",
        "      'prompt-version': prompt_version,\n",
        "      'loglevel': 0,\n",
        "      'stop-after-step': 3,\n",
        "      'proj-name': proj_name,\n",
        "      'input-filepath': 'text-output',\n",
        "      'input-filename': '01-paraphr-short-headlines_gpt-3.md',\n",
        "      'folders': folders,\n",
        "      'prompt-obj': prompt_obj,\n",
        "      'language': 'lang-de',\n",
        "      'length-type': 'length-max-dyn',\n",
        "      'length-max': 0.5,\n",
        "      'toc-text': '',\n",
        "      'result-filename': '02-paraphr-short.md'\n",
        "  })\n",
        "\n",
        "#step_1()\n",
        "#step_2()\n",
        "#step_3()\n",
        "\n",
        "# Idea: chain by returning filename of last file => can be input for next"
      ],
      "metadata": {
        "id": "xC1LzpVwasQr"
      },
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "notiz = {\n",
        "  \"prompt\": \"I want you to act as a very proficient SEO and high-end. I want you to pretend that you can write content so well that it can\\\n",
        "   outrank other websites. All output must be 100% human writing style and fix grammar issues and change to active voice. Your task is to\\\n",
        "   write an article starting with SEO Title with a bold letter and rewrite the content and include subheadings using related keywords.\\\n",
        "   Write in the style and tone of a professional IT magazine for software experts. Write every sentence in your very own words and do not\\\n",
        "   only rephrase the given content. The article must be 100% unique and remove plagiarism. Do not write a summary or conclusions in the\\\n",
        "  last paragraph. Avoid lists. Include subheadings. {language_text} {length_text} Text:```{input_text}```\"\n",
        "}"
      ],
      "metadata": {
        "id": "L-0jGjPwCAVW"
      },
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "proj_name = 'Handelsblatt'\n",
        "#create_file_directory(proj_name + '/' + folders['text-output'], True)\n",
        "#create_file_directory(proj_name + '/' + folders['text-output-logs'], True)\n",
        "#create_test_project(proj_name, '')\n",
        "\n",
        "\n",
        "# Step 1\n",
        "def step_1():\n",
        "  model = 'gpt-4'\n",
        "  prompt_obj = get_prompt_from_lib(promptlib_work, 'summary-multiple-articles', model, '1')\n",
        "  #print(json.dumps(prompt_obj, sort_keys=False, indent=2))\n",
        "  result_text = execute_prompt({\n",
        "      'model': model,\n",
        "      'loglevel': 0,\n",
        "      'stop-after-step': 0,\n",
        "      'proj-name': proj_name,\n",
        "      'input-filepath': '', #'text-output',\n",
        "      'input-filename': '', #'paraphrased.txt',\n",
        "      'folders': folders,\n",
        "      'prompt-obj': prompt_obj,\n",
        "      'language': 'lang-de',\n",
        "      'length-type': '',\n",
        "      'length-max': 0,\n",
        "      'toc-text': '',\n",
        "      'result-filename': '01-paraphr-short.md'\n",
        "  })\n",
        "\n",
        "#step_1()"
      ],
      "metadata": {
        "id": "No_0zjVjHkkT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Quick Action"
      ],
      "metadata": {
        "id": "ioFOFSZWAQBN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "my_input_text = widgets.Textarea(placeholder='Enter input text', layout=Layout(width='50%', height='150px'), disabled=False)\n",
        "button = widgets.Button(description=\"Summarize!\")\n",
        "def on_button_clicked(b):\n",
        "  comment = 'Kommentar zum Projekt...'\n",
        "  execute_project('Handelsblatt Fr', 'gpt-4', promptlib_global, 'summary-multiple-articles', '1', 'length-max-dyn', 5, '' ,True, folders, my_input_text.value, comment)\n",
        "button.on_click(on_button_clicked)\n",
        "display(my_input_text, button)"
      ],
      "metadata": {
        "id": "8zhMIX90AUlW",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 526,
          "referenced_widgets": [
            "05ad4d76acd046f8a0e12df68e97ccd8",
            "5e07f70bae7f45cfaebee40e196e2837",
            "15f749c6cd9941cea4e7f86580683d87",
            "07e51845fd7e4853a560ea7051cd6623",
            "2f63e3f4338549f38ea700305c140a2d",
            "51ae0f25bc4d40069e223a9ec6ca8399"
          ]
        },
        "outputId": "d9ef3640-4db0-490b-ae83-6f10057b88ab"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Textarea(value='', layout=Layout(height='150px', width='50%'), placeholder='Enter input text')"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "05ad4d76acd046f8a0e12df68e97ccd8"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Button(description='Summarize!', style=ButtonStyle())"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "07e51845fd7e4853a560ea7051cd6623"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: gpt-4\n",
            "Started at: 09:20:32\n",
            "\n",
            "Processing step 1 of 1\n",
            "The given text is delimited by triple backticks. It is a newspaper text with several articles. Summarize each article\n",
            "with its headline and succint and clear bullet points of its contents. Format everything in markdown syntax. If the\n",
            "following text in triple backticks is in German language write your text in German language, too. The length of the full\n",
            "text must be 45 words maximum. Text:```Auch Underdogs präsentieren sich Etliche der republikanischen Kandidaten\n",
            "schafften es nicht, die Klappstuhlreihen zu füllen. Francis Suarez, der Bürgermeister von Miami etwa, oder Perry\n",
            "Johnson, ein Unternehmer aus Illinois. Dagegen hatten die beiden Demokraten, die gegen Joe Biden antreten wollen,\n",
            "zumindest den Reiz des Exotischen: Marianne Williamson, eine Buchautorin, und Robert F. Kennedy Junior bek\n",
            "\n",
            "{'token_usage': {'prompt_tokens': 263, 'completion_tokens': 107, 'total_tokens': 370}, 'model_name': 'gpt-4'}\n",
            "\n",
            "\n",
            "Ended at: 09:20:40\n",
            "\n",
            "Duration: 0.1 Minutes\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "t508EftHM4U2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Current Work / Test"
      ],
      "metadata": {
        "id": "0GpudYkTcdAG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "promptlib_global['summary-shortened-same-tone'] = {\n",
        "      'description': 'Abgeleitet aus \"summary-shortened\"',\n",
        "      'category': 'summarize',\n",
        "      '1': {\n",
        "          'note': 'Summary without changing the tone',\n",
        "          \"prompt\": \"Paraphrase the following text and shorten each paragraph of the paraphrased text to maxiumum the half of its original length by focussing\\\n",
        "            on the key aspects. Write in the same style and tone as the given text. Be detailed and precise\\\n",
        "            and use every content detail of the text. {language_text} {length_text} Text:```{input_text}```\",\n",
        "          \"lang-de\": \"Write everything in German language.\",\n",
        "          \"lang-en\": \"Write everything in English language.\",\n",
        "          \"lang-same\": \"If the following text in triple backticks is in German language write your text in German language, too.\",\n",
        "          'gpt-3.5-turbo': {\n",
        "              \"input-text-max\": 1200,\n",
        "              \"length-max-fix\": \"The length of the full text must be 1200 words maximum.\",\n",
        "              \"length-max-dyn\": \"The length of the full text must be {{length_calc(\\\"{input_text}\\\", {max_len})}} words maximum.\"\n",
        "          },\n",
        "          'gpt-4': {\n",
        "              \"input-text-max\": 2400,\n",
        "              \"length-max-fix\": \"The length of the full text must be 2400 words maximum.\",\n",
        "              \"length-max-dyn\": \"The length of the full text must be {{length_calc(\\\"{input_text}\\\", {max_len})}} words maximum.\"\n",
        "          }\n",
        "      }\n",
        "    }\n",
        "text_from_file = \"<File:>\"\n",
        "comment = 'Kommentar zum Projekt...'\n",
        "# execute_project('S4HANA', 'gpt-4', promptlib_global, 'summary-shortened-same-tone', '1', 'length-max-dyn', 0, '', True, folders, text_from_file, comment)"
      ],
      "metadata": {
        "id": "SyjjeU56chJK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "4FuTcPBgxhn1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Todo:\n",
        "- Markdown Konvertierung wenn docx\n",
        "- Chaining (ausgabefile)\n",
        "- Artikel schreiben TOC, danach Kapitel"
      ],
      "metadata": {
        "id": "0gKN4n33a3Rz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "comment = 'Kommentar zum Projekt...'\n",
        "execute_project('Handelsblatt Fr', 'gpt-4', promptlib_global, 'summary-multiple-articles', '1', 'length-max-dyn', 5, '' ,True, folders, '<File:>', comment)"
      ],
      "metadata": {
        "id": "pWfQO90TmCEd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "promptlib_global['article-create-toc'] = {\n",
        "      'description': '',\n",
        "      'category': 'create-article',\n",
        "      '1': {\n",
        "          'note': 'Step 1: Create TOC',\n",
        "          \"prompt\": \"Here is some context for an article. The context is marked with 'Text:' and delimited by triple backticks. \\\n",
        "            Create a table of contents for an article titled 'Der Wert von Geschriebenem in Zeiten von Chat-GPT'. {language_text} {length_text} Text:```{input_text}``` {toc_text}\",\n",
        "          \"lang-de\": \"Write everything in German language.\",\n",
        "          \"lang-en\": \"Write everything in English language.\",\n",
        "          \"lang-same\": \"If the following text in triple backticks is in German language write your text in German language, too.\",\n",
        "          'gpt-3.5-turbo': {\n",
        "              \"input-text-max\": 1200,\n",
        "              \"length-max-fix\": \"The length of the full text must be 1200 words maximum.\",\n",
        "              \"length-max-dyn\": \"The length of the full text must be {{length_calc(\\\"{input_text}\\\", {max_len})}} words maximum.\"\n",
        "          },\n",
        "          'gpt-4': {\n",
        "              \"input-text-max\": 2400,\n",
        "              \"length-max-fix\": \"The length of the full text must be 2400 words maximum.\",\n",
        "              \"length-max-dyn\": \"The length of the full text must be {{length_calc(\\\"{input_text}\\\", {max_len})}} words maximum.\"\n",
        "          },\n",
        "          'default-model': {\n",
        "              \"input-text-max\": 2400,\n",
        "              \"length-max-fix\": \"The length of the full text must be 2400 words maximum.\",\n",
        "              \"length-max-dyn\": \"The length of the full text must be {{length_calc(\\\"{input_text}\\\", {max_len})}} words maximum.\"\n",
        "          }\n",
        "      }\n",
        "    }\n",
        "promptlib_global['article-create-chapter'] = {\n",
        "      'description': '',\n",
        "      'category': 'create-article',\n",
        "      '1': {\n",
        "          'note': 'Step 2: Create first chapter',\n",
        "          \"prompt\": \"Here is some context for an article titled 'Der Wert von Geschriebenem in Zeiten von Chat-GPT'. The context is marked with 'Text:' and delimited by triple backticks. \\\n",
        "            The table of contents is marked with 'TOC:' and delimited by triple backticks.\\\n",
        "            Write chapter 1 with a length of 500 words. {language_text} {length_text} Text:```{input_text}``` {toc_text}\",\n",
        "          \"lang-de\": \"Write everything in German language.\",\n",
        "          \"lang-en\": \"Write everything in English language.\",\n",
        "          \"lang-same\": \"If the following text in triple backticks is in German language write your text in German language, too.\",\n",
        "          'gpt-3.5-turbo': {\n",
        "              \"input-text-max\": 1200,\n",
        "              \"length-max-fix\": \"The length of the full text must be 1200 words maximum.\",\n",
        "              \"length-max-dyn\": \"The length of the full text must be {{length_calc(\\\"{input_text}\\\", {max_len})}} words maximum.\"\n",
        "          },\n",
        "          'gpt-4': {\n",
        "              \"input-text-max\": 2400,\n",
        "              \"length-max-fix\": \"The length of the full text must be 2400 words maximum.\",\n",
        "              \"length-max-dyn\": \"The length of the full text must be {{length_calc(\\\"{input_text}\\\", {max_len})}} words maximum.\"\n",
        "          },\n",
        "          'default-model': {\n",
        "              \"input-text-max\": 2400,\n",
        "              \"length-max-fix\": \"The length of the full text must be 2400 words maximum.\",\n",
        "              \"length-max-dyn\": \"The length of the full text must be {{length_calc(\\\"{input_text}\\\", {max_len})}} words maximum.\"\n",
        "          }\n",
        "      }\n",
        "    }\n",
        "text_from_file = \"<File:>\"\n",
        "\n",
        "# Step 1\n",
        "comment = 'Kommentar zum Projekt...'\n",
        "#execute_project('article-future-of-text', 'gpt-4', promptlib_global, 'article-create-toc', '1', '', 0, '', True, folders, text_from_file, comment)\n",
        "\n",
        "# Step 2\n",
        "toc_text = f\"\"\"TOC: \\`\\`\\`Inhaltsverzeichnis:\n",
        "Titel: Der Wert von Geschriebenem in Zeiten von Chat-GPT\n",
        "1. Künstliche Intelligenz und ihre Auswirkungen auf die täglichen Aufgaben\n",
        "2. Die Rolle von Bots in der schriftlichen Kommunikation\n",
        "3. Verhandlungen und Diskussionen in einer von Bots dominierten Welt\n",
        "4. Die Auswirkungen von Künstlicher Intelligenz auf die Kreativität und die Wahrnehmung von Originalität\n",
        "5. Die Auswirkungen von Künstlicher Intelligenz auf die Arbeit von Autoren und die Bedeutung von Charisma\n",
        "6. Fazit: Die Zukunft von Geschriebenem in Zeiten von Chat-GPT.\n",
        "\\`\\`\\`\"\"\"\n",
        "execute_project('article-future-of-text', 'gpt-4', promptlib_global, 'article-create-chapter', '1', '', 0, toc_text, False, folders, text_from_file, comment)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KtiPlr6jbGrw",
        "outputId": "e694c813-4714-4cf7-fad3-46302535b3e5"
      },
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: gpt-4\n",
            "Started at: 11:09:04\n",
            "\n",
            "Processing step 1 of 1\n",
            "Here is some context for an article titled 'Der Wert von Geschriebenem in Zeiten von Chat-GPT'. The context is marked\n",
            "with 'Text:' and delimited by triple backticks. The table of contents is marked with 'TOC:' and delimited by triple\n",
            "backticks. Write chapter 1 with a length of 500 words. If the following text in triple backticks is in German language\n",
            "write your text in German language, too. Text:```# Too Much Email? Let Your Bot Answer It ## As artificial intelligence\n",
            "continues to improve, we humans are going tohave to decide what we're comfortable letting it do. What will it be like\n",
            "when you have your own bot, and it is as good as or better than you at many daily tasks? The answer may come sooner than\n",
            "you think. Google’s new [Pathway Languages Model](https://ai.googleblog.com/2022/04/path\n",
            "\n",
            "{'token_usage': {'prompt_tokens': 1777, 'completion_tokens': 897, 'total_tokens': 2674}, 'model_name': 'gpt-4'}\n",
            "\n",
            "\n",
            "Ended at: 11:09:48\n",
            "\n",
            "Duration: 0.7 Minutes\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('article-future-of-text/text-output', 'response_gpt-4.md')"
            ]
          },
          "metadata": {},
          "execution_count": 85
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMuWdLuUOgCKgbmZahsmufQ",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "e0d1791da2ad4cc68ab08c12bb4429bc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "VBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_127bd2a95b554e86b33774b5417f5424",
              "IPY_MODEL_28259723b582419ca057b52bba9b74e7",
              "IPY_MODEL_abfedcbcab1144ad91eea8de578567f1",
              "IPY_MODEL_23d1d32e0702475c9eb575797c56db00",
              "IPY_MODEL_548b7826d8f74664b0af3068ff684632"
            ],
            "layout": "IPY_MODEL_2bdac73c245d4e988b834058e50afd3f"
          }
        },
        "127bd2a95b554e86b33774b5417f5424": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "BoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "BoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "BoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_3c8072c6a1d24cbe8a9a9f5e3f80c11a"
            ],
            "layout": "IPY_MODEL_c037f0e8b2654d309ea090c0eb1e18bc"
          }
        },
        "28259723b582419ca057b52bba9b74e7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "BoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "BoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "BoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_baf295ccea144243b20510b7eda0934e"
            ],
            "layout": "IPY_MODEL_c037f0e8b2654d309ea090c0eb1e18bc"
          }
        },
        "abfedcbcab1144ad91eea8de578567f1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "BoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "BoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "BoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_46033148e5c64d49a5e9860d101b82f4",
              "IPY_MODEL_2e6ba526696f4d318d7e1c1f5ba6c750",
              "IPY_MODEL_bac54a37a0484d21a190cda886e01c3c",
              "IPY_MODEL_6d9a3defe3354dd499a322779b3ac7ea"
            ],
            "layout": "IPY_MODEL_c037f0e8b2654d309ea090c0eb1e18bc"
          }
        },
        "23d1d32e0702475c9eb575797c56db00": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "BoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "BoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "BoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_edc59731919f4414b31c3fe8af367193",
              "IPY_MODEL_0961343291444357b5285721dc5365e2",
              "IPY_MODEL_27413f6e7cf0498a991fc06d0abf39b8",
              "IPY_MODEL_b8bad9dd76fc453eb3a1e193a0fefd69"
            ],
            "layout": "IPY_MODEL_c037f0e8b2654d309ea090c0eb1e18bc"
          }
        },
        "548b7826d8f74664b0af3068ff684632": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "BoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "BoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "BoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_719fcbc5263c4a44a1782694aa6cf6ed"
            ],
            "layout": "IPY_MODEL_c037f0e8b2654d309ea090c0eb1e18bc"
          }
        },
        "2bdac73c245d4e988b834058e50afd3f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3c8072c6a1d24cbe8a9a9f5e3f80c11a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d064827f45544bbb908fb3784fefad76",
            "placeholder": "​",
            "style": "IPY_MODEL_aa21165055ff407e99ffd5f2c9314888",
            "value": "<div style=\"background-color: red; text-align: center\"><b>Please wait for initial setup...</b></div>"
          }
        },
        "c037f0e8b2654d309ea090c0eb1e18bc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": "stretch",
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": "flex",
            "flex": null,
            "flex_flow": "row",
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "90%"
          }
        },
        "baf295ccea144243b20510b7eda0934e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f1daa1c0f5d242148e4f7be62b68104c",
            "placeholder": "​",
            "style": "IPY_MODEL_32b5427d93164f539a8d422b66b5b199",
            "value": "<div style=\"background-color: #ccc; text-align: center\">Hello <b>World</b></div>"
          }
        },
        "46033148e5c64d49a5e9860d101b82f4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c853d0bdf89f4ba3bb49fe6821b9cf33",
            "placeholder": "​",
            "style": "IPY_MODEL_31eb55c9aa8b45c4a887851b4102f300",
            "value": "Infotext"
          }
        },
        "2e6ba526696f4d318d7e1c1f5ba6c750": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fb82952e40104a52bef15c090b89c157",
            "placeholder": "​",
            "style": "IPY_MODEL_7657f29b25654df7b9c869242b8c7753",
            "value": "Infotext jdskl fjkdslf jsdklfjslf"
          }
        },
        "bac54a37a0484d21a190cda886e01c3c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0dc354d2b8174cd78583dd1befb82f35",
            "placeholder": "​",
            "style": "IPY_MODEL_665642f42f35461e922e849ffc1fe6c9",
            "value": "Infotext jdskl fjkdslf jsdklfjslf"
          }
        },
        "6d9a3defe3354dd499a322779b3ac7ea": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_edcd256d704c4aae88e5e4e8206a8bbf",
            "placeholder": "​",
            "style": "IPY_MODEL_8238d9a69ab7499a81fbad89d4363e7f",
            "value": "Infotext jdskl fjkdslf jsdklfjslf"
          }
        },
        "edc59731919f4414b31c3fe8af367193": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ButtonView",
            "button_style": "success",
            "description": "Install",
            "disabled": false,
            "icon": "",
            "layout": "IPY_MODEL_4dcb1742bb5946b7b45c9a4fe6008b50",
            "style": "IPY_MODEL_97569c137b1540d186df3e6a03061c9b",
            "tooltip": ""
          }
        },
        "0961343291444357b5285721dc5365e2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ButtonView",
            "button_style": "success",
            "description": "Save Text",
            "disabled": false,
            "icon": "",
            "layout": "IPY_MODEL_ad3b2c076e454e21b732aa310517b1db",
            "style": "IPY_MODEL_da2d9c76889745a4b37a5ef8aff816bd",
            "tooltip": ""
          }
        },
        "27413f6e7cf0498a991fc06d0abf39b8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ButtonView",
            "button_style": "success",
            "description": "Split Text",
            "disabled": false,
            "icon": "",
            "layout": "IPY_MODEL_3c2318d4d12842c2af4b3fe5ab2ef6f1",
            "style": "IPY_MODEL_8dcf46a0934f4211a9186058fa426fb9",
            "tooltip": ""
          }
        },
        "b8bad9dd76fc453eb3a1e193a0fefd69": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ButtonView",
            "button_style": "success",
            "description": "Chat",
            "disabled": false,
            "icon": "",
            "layout": "IPY_MODEL_447bb76f04e24893af4e8d5b4439635f",
            "style": "IPY_MODEL_bbabbf1347e24cdba0253a399fae5fa9",
            "tooltip": ""
          }
        },
        "719fcbc5263c4a44a1782694aa6cf6ed": {
          "model_module": "@jupyter-widgets/output",
          "model_name": "OutputModel",
          "model_module_version": "1.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/output",
            "_model_module_version": "1.0.0",
            "_model_name": "OutputModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/output",
            "_view_module_version": "1.0.0",
            "_view_name": "OutputView",
            "layout": "IPY_MODEL_10d382213150488ba702757d915662a1",
            "msg_id": "",
            "outputs": []
          }
        },
        "d064827f45544bbb908fb3784fefad76": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": "1 1 auto",
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": "hidden",
            "width": "auto"
          }
        },
        "aa21165055ff407e99ffd5f2c9314888": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f1daa1c0f5d242148e4f7be62b68104c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": "1 1 auto",
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "auto"
          }
        },
        "32b5427d93164f539a8d422b66b5b199": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c853d0bdf89f4ba3bb49fe6821b9cf33": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": "1 1 auto",
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "25%"
          }
        },
        "31eb55c9aa8b45c4a887851b4102f300": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "fb82952e40104a52bef15c090b89c157": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": "1 1 auto",
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "25%"
          }
        },
        "7657f29b25654df7b9c869242b8c7753": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0dc354d2b8174cd78583dd1befb82f35": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": "1 1 auto",
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "25%"
          }
        },
        "665642f42f35461e922e849ffc1fe6c9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "edcd256d704c4aae88e5e4e8206a8bbf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": "1 1 auto",
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "25%"
          }
        },
        "8238d9a69ab7499a81fbad89d4363e7f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4dcb1742bb5946b7b45c9a4fe6008b50": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": "1 1 0%",
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": "visible",
            "width": "auto"
          }
        },
        "97569c137b1540d186df3e6a03061c9b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "button_color": null,
            "font_weight": ""
          }
        },
        "ad3b2c076e454e21b732aa310517b1db": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": "1 1 0%",
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": "visible",
            "width": "auto"
          }
        },
        "da2d9c76889745a4b37a5ef8aff816bd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "button_color": null,
            "font_weight": ""
          }
        },
        "3c2318d4d12842c2af4b3fe5ab2ef6f1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": "1 1 0%",
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": "visible",
            "width": "auto"
          }
        },
        "8dcf46a0934f4211a9186058fa426fb9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "button_color": null,
            "font_weight": ""
          }
        },
        "447bb76f04e24893af4e8d5b4439635f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": "1 1 0%",
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": "visible",
            "width": "auto"
          }
        },
        "bbabbf1347e24cdba0253a399fae5fa9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "button_color": null,
            "font_weight": ""
          }
        },
        "10d382213150488ba702757d915662a1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": "1 1 auto",
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "auto"
          }
        },
        "837d4a9832454a8e864d8e3f0b14ab78": {
          "model_module": "@jupyter-widgets/output",
          "model_name": "OutputModel",
          "model_module_version": "1.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/output",
            "_model_module_version": "1.0.0",
            "_model_name": "OutputModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/output",
            "_view_module_version": "1.0.0",
            "_view_name": "OutputView",
            "layout": "IPY_MODEL_f4ac03a220974d4f9c71dd344f3478a1",
            "msg_id": "",
            "outputs": []
          }
        },
        "f4ac03a220974d4f9c71dd344f3478a1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "05ad4d76acd046f8a0e12df68e97ccd8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "TextareaModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "TextareaModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "TextareaView",
            "continuous_update": true,
            "description": "",
            "description_tooltip": null,
            "disabled": false,
            "layout": "IPY_MODEL_5e07f70bae7f45cfaebee40e196e2837",
            "placeholder": "Enter input text",
            "rows": null,
            "style": "IPY_MODEL_15f749c6cd9941cea4e7f86580683d87",
            "value": "Auch Underdogs präsentieren sich\n\nEtliche der republikanischen Kandidaten schafften es nicht, die Klappstuhlreihen zu füllen. Francis Suarez, der Bürgermeister von Miami etwa, oder Perry Johnson, ein Unternehmer aus Illinois. Dagegen hatten die beiden Demokraten, die gegen Joe Biden antreten wollen, zumindest den Reiz des Exotischen: Marianne Williamson, eine Buchautorin, und Robert F. Kennedy Junior bekamen freundlichen Applaus.\n\nDie Iowa State Fair ist eine der größten, ältesten und bekanntesten Landwirtschaftsmessen der USA. An den zehn Tagen im August kommen über eine Million Menschen. Das heißt, jeder dritte Einwohner des Bundesstaates schaut vorbei."
          }
        },
        "5e07f70bae7f45cfaebee40e196e2837": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": "150px",
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "50%"
          }
        },
        "15f749c6cd9941cea4e7f86580683d87": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "07e51845fd7e4853a560ea7051cd6623": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ButtonView",
            "button_style": "",
            "description": "Summarize!",
            "disabled": false,
            "icon": "",
            "layout": "IPY_MODEL_2f63e3f4338549f38ea700305c140a2d",
            "style": "IPY_MODEL_51ae0f25bc4d40069e223a9ec6ca8399",
            "tooltip": ""
          }
        },
        "2f63e3f4338549f38ea700305c140a2d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "51ae0f25bc4d40069e223a9ec6ca8399": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "button_color": null,
            "font_weight": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}