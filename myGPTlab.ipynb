{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aknip/Streamlit-Gradio/blob/main/myGPTlab.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# myGPTlab\n",
        "\n",
        "This app helps to process texts (longform content) with ChatGPT via API.\n",
        "\n",
        "## Start:\n",
        "**Run all cells - that's it.**\n",
        "- The notebooks checks automatically, if an initial setup (with PIP etc.) is necessary. The setup status is saved in the file 'installation.done'\n",
        "- You can force the setup by deleting this file or by going to Seciton \"Setup and Configuration\" and checking \"inital_setup_mode\". Afterwards uncheck \"Setup and Configuration\".\n",
        "\n",
        "## Working with myGPTlab\n",
        "\n",
        "## FAQ\n",
        "### Was tun, wenn kryptische Fehlermeldungen erscheinen, wie z. B. \"error: invalid group reference 11 at position 1\"?\n",
        "Den Input-Text neu anlegen bzw. konvertieren (z. b. per pandoc). Die Ursache kann Encoding sein.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "Ht3Wkxk7Rpn_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here we go"
      ],
      "metadata": {
        "id": "v1Tk6QX28RZN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# @title\n",
        "import os\n",
        "import requests\n",
        "# os.environ.pop('CREDS') # delete environment variable for debugging\n",
        "if not os.getenv('CREDS'):\n",
        "  #popup('Enter API Keys as JSON:')\n",
        "  fname = 'aknip-colab-setup'\n",
        "  url = 'https://bit.ly/' + fname\n",
        "  r = requests.get(url)\n",
        "  open(fname, 'wb').write(r.content)\n",
        "  %run aknip-colab-setup\n",
        "else:\n",
        "  print(\"API Keys available in env 'CREDS'\")\n",
        "\n",
        "!pip install ipywidgets -q"
      ],
      "metadata": {
        "cellView": "form",
        "id": "VDc8hEXF1Zra",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a01c3713-b91f-4677-b81f-3df24aa6d5f2"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Secrets (JSON string): ··········\n",
            "Credentials stored in env 'CREDS'. Get values via: \n",
            "creds = json.loads(os.getenv('CREDS')) \n",
            "key = creds['OpenAI']['v1']['credential']\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m8.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title\n",
        "import ipywidgets\n",
        "from ipywidgets import Layout, Button, Box, VBox, HTML, Output, Textarea\n",
        "\n",
        "# Info flex proportionally to the weight\n",
        "info_1 = HTML(value='<div style=\"background-color: red; text-align: center\"><b>Please wait for initial setup...</b></div>', layout=Layout(flex='1 1 auto', width='auto'))\n",
        "items_info = [info_1]\n",
        "\n",
        "# Header flex proportionally to the weight\n",
        "header_1 = HTML(value='<div style=\"background-color: #ccc; text-align: center\">Hello <b>World</b></div>', layout=Layout(flex='1 1 auto', width='auto'))\n",
        "items_header = [header_1]\n",
        "\n",
        "# Text flex proportionally to the weight\n",
        "text_1 = HTML(value='Infotext', layout=Layout(flex='1 1 auto', width='25%'))\n",
        "text_2 = HTML(value='Infotext jdskl fjkdslf jsdklfjslf', layout=Layout(flex='1 1 auto', width='25%'))\n",
        "text_3 = HTML(value='Infotext jdskl fjkdslf jsdklfjslf', layout=Layout(flex='1 1 auto', width='25%'))\n",
        "text_4 = HTML(value='Infotext jdskl fjkdslf jsdklfjslf', layout=Layout(flex='1 1 auto', width='25%'))\n",
        "items_texts = [text_1, text_2, text_3, text_4]\n",
        "\n",
        "# Textinput flex proportionally to the weight\n",
        "input_1 = Textarea(placeholder='Enter input text', layout=Layout(flex='1 1 auto', width='25%', height='150px'), disabled=False)\n",
        "input_2 = Textarea(placeholder='Enter input text', layout=Layout(flex='1 1 auto', width='25%', height='150px'), disabled=False)\n",
        "input_3 = Textarea(placeholder='Enter input text', layout=Layout(flex='1 1 auto', width='25%', height='150px'), disabled=False)\n",
        "input_4 = Textarea(placeholder='Enter input text', layout=Layout(flex='1 1 auto', width='25%', height='150px'), disabled=False)\n",
        "items_inputs = [input_1, input_2, input_3, input_4]\n",
        "\n",
        "# Buttons flex proportionally to the weight\n",
        "button_1 = Button(description='Summarize Articles', layout=Layout(flex='1 1 0%', width='auto'), button_style='success')\n",
        "button_2 = Button(description='Save Text', layout=Layout(flex='1 1 0%', width='auto'), button_style='success')\n",
        "button_3 = Button(description='Split Text', layout=Layout(flex='1 1 0%', width='auto'), button_style='success')\n",
        "button_4 = Button(description='Chat', layout=Layout(flex='1 1 0%', width='auto'), button_style='success')\n",
        "items_buttons = [button_1, button_2, button_3, button_4]\n",
        "\n",
        "# Output flex proportionally to the weight\n",
        "output_1 = Output(layout=Layout(flex='1 1 auto', width='auto'))\n",
        "items_output = [output_1]\n",
        "\n",
        "box_layout = Layout(display='flex',\n",
        "                    flex_flow='row',\n",
        "                    align_items='stretch',\n",
        "                    width='90%')\n",
        "\n",
        "box_info = Box(children=items_info, layout=box_layout)\n",
        "box_header = Box(children=items_header, layout=box_layout)\n",
        "box_texts = Box(children=items_texts, layout=box_layout)\n",
        "box_inputs = Box(children=items_inputs, layout=box_layout)\n",
        "box_buttons = Box(children=items_buttons, layout=box_layout)\n",
        "box_output = Box(children=items_output, layout=box_layout)\n",
        "\n",
        "def on_button_1_clicked(b):\n",
        "    #with output_1:\n",
        "    comment = 'Kommentar zum Projekt...'\n",
        "    execute_project('Handelsblatt', 'gpt-3.5-turbo', '', promptlib_global, 'summary-multiple-articles', '1', 'length-max-dyn', '', 0 ,True, folders, input_1.value, comment)\n",
        "button_1.on_click(on_button_1_clicked)\n",
        "\n",
        "def on_button_2_clicked(b):\n",
        "    output_1.clear_output()\n",
        "\n",
        "button_2.on_click(on_button_2_clicked)\n",
        "\n",
        "#button_1.layout.visibility = \"hidden\"\n",
        "#button_2.layout.visibility = \"hidden\"\n",
        "#button_3.layout.visibility = \"hidden\"\n",
        "#button_4.layout.visibility = \"hidden\"\n",
        "\n",
        "VBox([box_info, box_header, box_texts, box_inputs, box_buttons, box_output])\n"
      ],
      "metadata": {
        "id": "IwvcO7XF5j5f",
        "cellView": "form",
        "outputId": "8e68a212-488f-4db9-e3c1-5624d13b2a53",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 267,
          "referenced_widgets": [
            "a829738f8c90455c9daa109b44abc55d",
            "5ce7f5e6c7c641c5ab943f3046372629",
            "339f449797b2482c903685ad47b1d8b9",
            "84933faa02c24ed9af73992c11446a93",
            "aa9a5498f1c348f9ae285d81097bd30d",
            "3be510e876924a128169ccf010dcbba3",
            "408dbdc87d504ec2ac7d7f16ad96f474",
            "9ba888272187427f9662cc2a42248882",
            "a2f5672325be44dfb09435f8a51918ad",
            "76e86997daff4ca29e16a1228578947f",
            "35d7d5bc127e448992b410494ac36e0d",
            "5efd3aa14e254b84b2f34d2b9aceeddf",
            "52f97d7d3dbe45a08393f0bd97032947",
            "55799e20bcbf4fddaddf39d5ab0e764b",
            "93d11d613aeb4cf8a955ccc772f92073",
            "2532a2f7705246249dbdd962f79ca2c0",
            "215f495f18484612aa52e5e1141f06c7",
            "8125bba543c544d29a489583b28afd58",
            "b7fe0a1d139547d1a5204125278e19ea",
            "1ce1ae8a53524cfc9d48432ba04c7754",
            "0a20bb9cd93649c5a604b7e69e3e98fc",
            "16289ab2dd1342f5a8ec46665c33c850",
            "c99206c78a1d4280abfdd1febad36c16",
            "96ef5680617e46938619961b02e3b16c",
            "d52e67f11d544f449f30727584ebad59",
            "1b94f8a6cbba4e0281be9d1a92c7b6f7",
            "7e9ce601785847e6a5d69ddc7d536072",
            "644c2a4d400447cd9d841138e051410e",
            "c1a2f88f233b46c7b1883722ed73caa3",
            "5d022a971b554f91b3da02d701ba6a5c",
            "46d7d9d2d40a4c539216f8a4df88296f",
            "5436693acd5d4691b08aeab299c2c9f4",
            "bd73248f5bbe443d850f2463c41b0599",
            "6aecb9209d75414b8f0d967fcce41a27",
            "47741962461f4b6aaba1aec0a706f3ee",
            "ca5864e4fb5546c5924460031fe9ae67",
            "67bdc1c7f2d44c92af7c744cd403e673",
            "3e3fcf49787a402893df0b4883d1cb2e",
            "1c8d9820ee374abd8d1b061ffaaa275c",
            "eb1c8af3aea74ba7b66acb67ff5d61ad",
            "87c6ff2387514390b1e470e8b2a43eb3",
            "b5b5828b9f7a4ce59ab5a8c8e1ebdb33",
            "ebdbc656822d478485da17fb8fe5705f",
            "0ff7e796bf6942dcb5ccbcf3d6ed125e",
            "8532fa5f72f54d3a98e37874d30960d2",
            "a56a81ea85644a0fbd56954319131712",
            "ce1eb6ea7911436dbf4e639c720756e7",
            "b33c7a9ed3cd41f982d7427e6e2d112f",
            "806b5ef1eac14e5e91c822911c8e2bd6",
            "3f7bda997b744f5fa85a1b81b60ab2ad",
            "d1a87be6276f421d84a372d5645e79ba",
            "129afcfee9bc4da1b3b556e974a86269",
            "fdd710a7c1924786a1a0d9d56f5b9424"
          ]
        }
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "VBox(children=(Box(children=(HTML(value='<div style=\"background-color: red; text-align: center\"><b>Please wait…"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a829738f8c90455c9daa109b44abc55d"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Install"
      ],
      "metadata": {
        "id": "vcKyPYho08Y2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Settings\n",
        "\n",
        "# @markdown Default model\n",
        "default_model = 'GPT-3.5' # @param [\"GPT-3.5\", \"GPT-4\"]\n",
        "\n",
        "# @markdown Start Gradio webapp.\n",
        "start_gradio_webapp = False # @param {type:\"boolean\"}\n",
        "\n",
        "# @markdown Initial Setup Mode for pip install, fetch credentials etc.\n",
        "initial_setup_mode = False # @param {type:\"boolean\"}\n",
        "\n",
        "# @markdown Debug Mode for extensive logging.\n",
        "debug_mode = True # @param {type:\"boolean\"}\n",
        "\n",
        "# @markdown iOS Mode to develop helper functions, no Gradio.\n",
        "# @markdown Useful for development on iOS, eg. with Carnets App\n",
        "ios_mode = False # @param {type:\"boolean\"}"
      ],
      "metadata": {
        "cellView": "form",
        "id": "9NyekTkaGU3Z"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "folders = {\n",
        "    'audio': 'audio',\n",
        "    'audio-chunks': 'audio/chunks',\n",
        "    'transcript':'audio-transcript',\n",
        "    'transcript-chunks': 'audio-transcript/chunks',\n",
        "    'text-input': 'text-input',\n",
        "    'text-input-backup': 'text-input-backup',\n",
        "    'text-output': 'text-output',\n",
        "    'text-output-logs': 'text-output-logs'\n",
        "}"
      ],
      "metadata": {
        "id": "FBJns82oduIg"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from ipywidgets import widgets\n",
        "from IPython.display import Javascript, display, clear_output\n",
        "notify_output = widgets.Output()\n",
        "display(notify_output)\n",
        "@notify_output.capture()\n",
        "def popup(text):\n",
        "    clear_output()\n",
        "    display(Javascript(\"alert('{}')\".format(text)))\n",
        "#popup('Hello World!')"
      ],
      "metadata": {
        "id": "Z-9rgUetGeu0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17,
          "referenced_widgets": [
            "eef4ef83589741d48dfb57aa37a3bbd0",
            "a0f24a372dd74f33b612ef857edbcb4a"
          ]
        },
        "outputId": "d9a00237-ac5b-49d3-e7fd-0b18f07fb9bb"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Output()"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "eef4ef83589741d48dfb57aa37a3bbd0"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "if initial_setup_mode != True:\n",
        "  if os.path.exists('installation.done'):\n",
        "      initial_setup_mode = False\n",
        "      print('No initial setup - forced by existing file \"installation.done\"')\n",
        "  else:\n",
        "    initial_setup_mode = True\n",
        "    print('Starting automatic setup - forced by missing file \"installation.done\".\\n\\nEnter API Keys as JSON (in next notebook cell).')\n",
        "    #popup('Starting automatic setup. Enter API Keys as JSON (in next notebook cell).')\n",
        "else:\n",
        "  print('Starting setup.\\n\\nEnter API Keys as JSON (in next notebook cell).')\n",
        "  #popup('Starting setup. Enter API Keys as JSON (in next notebook cell).')"
      ],
      "metadata": {
        "id": "4cDDPr809eC4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1b2236bb-9cc4-4130-cdcd-b6d32208491a"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting automatic setup - forced by missing file \"installation.done\".\n",
            "\n",
            "Enter API Keys as JSON (in next notebook cell).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "creds = json.loads(os.getenv('CREDS'))\n",
        "# openAI_key = creds['OpenAI']['v2']['credential']\n",
        "# print(openAI_key)"
      ],
      "metadata": {
        "id": "iEwJ4-ShAt0v"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "Wtw0CARBQhTQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c5369604-2a6d-45db-f7c8-740f4583524e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m72.0/72.0 kB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.0/3.0 MB\u001b[0m \u001b[31m10.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m253.0/253.0 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m18.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m232.6/232.6 kB\u001b[0m \u001b[31m15.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.1/14.1 MB\u001b[0m \u001b[31m29.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m20.1/20.1 MB\u001b[0m \u001b[31m48.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.4/194.4 kB\u001b[0m \u001b[31m16.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m51.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m129.9/129.9 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.7/2.7 MB\u001b[0m \u001b[31m60.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m90.0/90.0 kB\u001b[0m \u001b[31m8.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m16.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m66.2/66.2 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m298.2/298.2 kB\u001b[0m \u001b[31m28.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.4/75.4 kB\u001b[0m \u001b[31m8.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m268.8/268.8 kB\u001b[0m \u001b[31m24.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m139.9/139.9 kB\u001b[0m \u001b[31m11.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.7/45.7 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m59.5/59.5 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.4/49.4 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.0/67.0 kB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m74.5/74.5 kB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for pickle-mixin (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for ffmpy (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ],
      "source": [
        "if initial_setup_mode == True:\n",
        "  !pip install openai==0.27.7 yt-dlp==2023.7.6 librosa==0.10.0.post2 pickle-mixin==1.0.2 langchain==0.0.225 PyPDF2==3.0.1 PyMuPDF==1.22.5 pypandoc==1.11 gradio -q\n",
        "  %load_ext gradio\n",
        "else:\n",
        "  print('No initial setup.')\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "if initial_setup_mode == True:\n",
        "  f= open('installation.done','w+')\n",
        "  f.close()\n",
        "  print('Initial setup done. Application starting.')\n",
        "  # popup('Initial setup done. Application starting.')\n",
        "else:\n",
        "  print('No initial setup.')"
      ],
      "metadata": {
        "id": "l0Lx1eHL9Nik",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7ddd2106-d21d-4d34-e593-f258f1276475"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Initial setup done. Application starting.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "\n",
        "def import_prompt_lib():\n",
        "  fname = 'prompt_lib.ipynb'\n",
        "  url = 'https://raw.githubusercontent.com/aknip/Streamlit-Gradio/main/' + fname\n",
        "  r = requests.get(url)\n",
        "  open(fname, 'wb').write(r.content)\n",
        "  %run prompt_lib.ipynb\n",
        "\n",
        "def import_helper_lib():\n",
        "  fname = 'helper_lib.ipynb'\n",
        "  url = 'https://raw.githubusercontent.com/aknip/Streamlit-Gradio/main/' + fname\n",
        "  r = requests.get(url)\n",
        "  open(fname, 'wb').write(r.content)\n",
        "  %run helper_lib.ipynb"
      ],
      "metadata": {
        "id": "GEUDe8zCj17s"
      },
      "execution_count": 97,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import_helper_lib()\n",
        "import_prompt_lib()"
      ],
      "metadata": {
        "id": "HD6BlP4FjB4p"
      },
      "execution_count": 98,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(promptlib_global)\n",
        "print(testfunc(3,4))"
      ],
      "metadata": {
        "id": "CGQ46eH6aeun",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fcd77158-f8c6-475f-add7-e40f81a0d9ff"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'summary-shortened': {'description': '', 'category': 'summarize', '1': {'note': 'Gleichzeitiges Einfügen/Formatieren von Headlines funktioniert nicht, lässt GPT alles umformulieren           (\"Format headings and subheadings in markdown syntax.\").           Test S4/HANA Kap. 4: Input 12.300 Wörter, GPT-3.5 Output: 4.500 Wörter (36%), GPT-4 Output: 3.400 Wörter (27%)', 'prompt': 'Paraphrase the following text and shorten each paragraph of the paraphrased text to maxiumum the half of its original length by focussing            on the key aspects. Write in the style and tone of a professional business analyst and use passive form. Be detailed and precise            and use every content detail of the text. Note that there may be typographical or grammatical errors in the passages due to the            text being fetched from a transcript of a talk or a speech.            {language_text} {length_text} Text:```{input_text}``` {toc_text}', 'lang-de': 'Write everything in German language.', 'lang-en': 'Write everything in English language.', 'lang-same': 'If the following text in triple backticks is in German language write your text in German language, too.', 'gpt-3.5-turbo': {'input-text-max': 1200, 'length-max-fix': 'The length of the full text must be 1200 words maximum.', 'length-max-dyn': 'The length of the full text must be {{length_calc(\"{input_text}\", {max_len})}} words maximum.'}, 'gpt-4': {'input-text-max': 2400, 'length-max-fix': 'The length of the full text must be 2400 words maximum.', 'length-max-dyn': 'The length of the full text must be {{length_calc(\"{input_text}\", {max_len})}} words maximum.'}, 'default-model': {'input-text-max': 500, 'length-max-fix': 'The length of the full text must be 500 words maximum.', 'length-max-dyn': 'The length of the full text must be {{length_calc(\"{input_text}\", {max_len})}} words maximum.'}}}, 'summary-multiple-articles': {'description': '', 'category': 'summarize', '1': {'note': 'summarize each headline / paragraph', 'prompt': 'The given text is delimited by triple backticks. It is a newspaper text with several articles.            Summarize each article with its headline and succint and clear bullet points of its contents.            Format everything in markdown syntax. {language_text} {length_text} Text:```{input_text}``` {toc_text}', 'lang-de': 'Write everything in German language.', 'lang-en': 'Write everything in English language.', 'lang-same': 'If the following text in triple backticks is in German language write your text in German language, too.', 'gpt-3.5-turbo': {'input-text-max': 1200, 'length-max-fix': 'The length of the full text must be 1200 words maximum.', 'length-max-dyn': 'The length of the full text must be {{length_calc(\"{input_text}\", {max_len})}} words maximum.'}, 'gpt-4': {'input-text-max': 2400, 'length-max-fix': 'The length of the full text must be 2400 words maximum.', 'length-max-dyn': 'The length of the full text must be {{length_calc(\"{input_text}\", {max_len})}} words maximum.'}, 'default-model': {'input-text-max': 500, 'length-max-fix': 'The length of the full text must be 500 words maximum.', 'length-max-dyn': 'The length of the full text must be {{length_calc(\"{input_text}\", {max_len})}} words maximum.'}}}, 'summary-bullets': {'description': 'Max word length: 1100 for EN, 900 for DE. approx. 1 min processing time Example: Full book: 113 parts á 1000 words takes 15 min.', 'category': 'summarize', '1': {'note': 'summarize to bullets v1', 'prompt': 'The given text is delimited by triple backticks. Summarize the current text to succint and clear bullet points            of its contents. {language_text} {length_text} Text:```{input_text}``` {toc_text}', 'lang-de': 'Write everything in German language.', 'lang-en': 'Write everything in English language.', 'lang-same': 'If the following text in triple backticks is in German language write your text in German language, too.', 'gpt-3.5-turbo': {'input-text-max': 1200, 'length-max-fix': 'The length of the summary must be 300 words maximum.', 'length-max-dyn': 'The length of the summary must be {{length_calc(\"{input_text}\", {max_len})}} words maximum.'}, 'gpt-4': {'input-text-max': 2400, 'length-max-fix': 'The length of the summary must be 300 words maximum.', 'length-max-dyn': 'The length of the summary must be {{length_calc(\"{input_text}\", {max_len})}} words maximum.'}, 'default-model': {'input-text-max': 500, 'length-max-fix': 'The length of the summary must be 300 words maximum.', 'length-max-dyn': 'The length of the summary must be {{length_calc(\"{input_text}\", {max_len})}} words maximum.'}}, '2': {'note': 'summarize to bullets v2', 'prompt': 'The given text is delimited by triple backticks. Summarize the current text to a maximum of 15 succint            and clear bullet points of its contents. {language_text} {length_text} Text:```{input_text}``` {toc_text}', 'lang-de': 'Write everything in German language.', 'lang-en': 'Write everything in English language.', 'lang-same': 'If the following text in triple backticks is in German language write your text in German language, too.', 'gpt-3.5-turbo': {'input-text-max': 1200, 'length-max-fix': 'The length of the summary must be 300 words maximum.', 'length-max-dyn': 'The length of the summary must be {{length_calc(\"{input_text}\", {max_len})}} words maximum.'}, 'gpt-4': {'input-text-max': 2400, 'length-max-fix': 'The length of the summary must be 300 words maximum.', 'length-max-dyn': 'The length of the summary must be {{length_calc(\"{input_text}\", {max_len})}} words maximum.'}, 'default-model': {'input-text-max': 500, 'length-max-fix': 'The length of the summary must be 300 words maximum.', 'length-max-dyn': 'The length of the summary must be {{length_calc(\"{input_text}\", {max_len})}} words maximum.'}}, '3': {'note': 'summarize to bullets v3', 'prompt': 'The given text is delimited by triple backticks. Write a detailed bullet-point summary. {language_text} {length_text} Text:```{input_text}``` {toc_text}', 'lang-de': 'Write everything in German language.', 'lang-en': 'Write everything in English language.', 'lang-same': 'If the following text in triple backticks is in German language write your text in German language, too.', 'gpt-3.5-turbo': {'input-text-max': 1200, 'length-max-fix': 'The length of the summary must be 300 words maximum.', 'length-max-dyn': 'The length of the summary must be {{length_calc(\"{input_text}\", {max_len})}} words maximum.'}, 'gpt-4': {'input-text-max': 2400, 'length-max-fix': 'The length of the summary must be 300 words maximum.', 'length-max-dyn': 'The length of the summary must be {{length_calc(\"{input_text}\", {max_len})}} words maximum.'}, 'default-model': {'input-text-max': 500, 'length-max-fix': 'The length of the summary must be 300 words maximum.', 'length-max-dyn': 'The length of the summary must be {{length_calc(\"{input_text}\", {max_len})}} words maximum.'}}}, 'create-subheadlines': {'description': '', 'category': 'structure', '1': {'note': 'create subheadlien, keep text the same', 'prompt': 'The given text is delimited by triple backticks. Divide the text into 3 paragraphs of approximately           equal length according to the meaning of the content and insert subheadings for the paragraphs.           Please respond with the full original text including the inserted subheadings.           Format the subheadings in markdown syntax. {language_text} {length_text} Text:```{input_text}``` {toc_text}', 'lang-de': 'Write everything in German language.', 'lang-en': 'Write everything in English language.', 'lang-same': 'Write in the language of the original text.', 'gpt-3.5-turbo': {'input-text-max': 1200, 'length-max-fix': 'The length of the full text must be 1200 words maximum.', 'length-max-dyn': 'The length of the full text must be {{length_calc(\"{input_text}\", {max_len})}} words maximum.'}, 'gpt-4': {'input-text-max': 2400, 'length-max-fix': 'The length of the full text must be 2400 words maximum.', 'length-max-dyn': 'The length of the full text must be {{length_calc(\"{input_text}\", {max_len})}} words maximum.'}, 'default-model': {'input-text-max': 500, 'length-max-fix': 'The length of the full text must be 500 words maximum.', 'length-max-dyn': 'The length of the full text must be {{length_calc(\"{input_text}\", {max_len})}} words maximum.'}}}, 'summary-3-sentences': {'description': '', 'category': 'summarize', '1': {'note': 'create subheadlien, keep text the same', 'prompt': 'The given text is delimited by triple backticks. Summarize the text into three           sentences. {language_text} {length_text} Text:```{input_text}``` {toc_text}', 'lang-de': 'Write everything in German language.', 'lang-en': 'Write everything in English language.', 'lang-same': 'Write in the language of the original text.', 'gpt-3.5-turbo': {'input-text-max': 1200, 'length-max-fix': 'The length of the full text must be 300 words maximum.', 'length-max-dyn': 'The length of the full text must be {{length_calc(\"{input_text}\", {max_len})}} words maximum.'}, 'gpt-4': {'input-text-max': 2400, 'length-max-fix': 'The length of the full text must be 300 words maximum.', 'length-max-dyn': 'The length of the full text must be {{length_calc(\"{input_text}\", {max_len})}} words maximum.'}, 'default-model': {'input-text-max': 500, 'length-max-fix': 'The length of the full text must be 300 words maximum.', 'length-max-dyn': 'The length of the full text must be {{length_calc(\"{input_text}\", {max_len})}} words maximum.'}}}}\n",
            "7\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title\n",
        "test_text1 = 'Die Photosynthese ist ein physiologischer Prozess zur Erzeugung energiereicher Biomoleküle aus energieärmeren Stoffen mit Hilfe\\\n",
        "  von Lichtenergie. Sie wird von Pflanzen, Algen und manchen Bakterien betrieben. Bei diesem biochemischen Vorgang wird Lichtenergie mit Hilfe\\\n",
        "  von lichtabsorbierenden Farbstoffen wie Chlorophyll in chemische Energie umgewandelt. Diese wird dann genutzt, um aus energiearmen\\\n",
        "  anorganischen Stoffen (vor allem Kohlenstoffdioxid (CO2) und Wasser (H2O)) energiereiche organische Verbindungen (vor allem Kohlenhydrate)\\\n",
        "  aufzubauen. Der genutzte Anteil der eingestrahlten Energie, nämlich der zum Aufbau der Assimilate verwendete Anteil, wird photosynthetische\\\n",
        "  Effizienz genannt. Soweit die energiereichen organischen Stoffe zu Bestandteilen des Lebewesens werden, bezeichnet man deren Synthese als\\\n",
        "  Assimilation. Man unterscheidet zwischen oxygener und anoxygener Photosynthese. Bei der oxygenen Photosynthese wird molekularer\\\n",
        "  Sauerstoff (O2) freigesetzt. Bei der anoxygenen Photosynthese, die nur von Bakterien betrieben wird, entstehen statt Sauerstoff andere\\\n",
        "  anorganische Stoffe, beispielsweise elementarer Schwefel (S). Die Photosynthese ist der einzige biochemische Prozess, bei dem\\\n",
        "  Lichtenergie, meistens Sonnenlicht, in chemisch gebundene Energie umgewandelt wird (Phototrophie). Indirekt sind auch fast alle\\\n",
        "  heterotrophen (nicht zur Photosynthese fähigen) Lebewesen von ihr abhängig, da sie der Photosynthese letztlich ihre Nahrung und auch\\\n",
        "  den zur Energiegewinnung mittels aerober Atmung benötigten Sauerstoff verdanken. Aus dem Sauerstoff entsteht außerdem die schützende\\\n",
        "  Ozonschicht der Erdatmosphäre.'\n",
        "test_text2 = f'''\n",
        "# The Potential of AI in Education\n",
        "\n",
        "So, anyone who's been paying attention for the last few months has been seeing headlines like this, especially in education. The thesis has been students are going to be using chat GPT and other forms of AI to cheat, do their assignments, they're not going to learn, and it's going to completely undermine education as we know it.\n",
        "\n",
        "Now what I'm going to argue today is not only are there ways to mitigate all of that, if we put the right guardrails, we do the right things, we can mitigate it, but I think we're at the cusp of using AI for probably the biggest positive transformation that education has ever seen. And the way we're going to do that is by giving every student on the planet an artificially intelligent but amazing personal tutor, and we're going to give every teacher on the planet an amazing, artificially intelligent teaching assistant.  And just to appreciate how big of a deal it would be to give everyone a personal tutor, I show you this clip from Benjamin Bloom's 1984 two-sigma study, or he called it the two-sigma problem.\n",
        "\n",
        "The two-sigma comes from two standard deviations, sigma the symbol for standard deviation, and he had good data that showed that, look, a normal distribution, that's the one that you see in the traditional bell curve right in the middle, that's how the world kind of sorts itself out, that if you were to give personal one-to-one tutoring for students, that you could actually get a distribution that looks like that right, it says tutorial one-to-one with the asterisks, like that right distribution, a two standard deviation improvement. Just to put that in plain language, that could take your average student and turn them into an exceptional student, it can take your below average student and turn them into an above average student.\n",
        "\n",
        "# The Challenge of Scaling Personalized Instruction\n",
        "\n",
        "Now, the reason why he framed it as a problem was he said, well, this is all good, but how do you actually scale group instruction this way? How do you actually give it to everyone in an economic way? What I'm about to show you is, I think, the first moves towards doing that. Obviously, we've been trying to approximate it in some way at Khan Academy for over a decade now, but I think we're at the cusp of accelerating it dramatically.  I'm going to show you the early stages of what RAI, which we call Khan Migo, what it can now do, and maybe a little bit of where it is actually going.  This right over here is a traditional exercise that you or many of your children might have seen on Khan Academy, but what's new is that little bot thing at the right, and we'll start by seeing one of the very important safeguards, which is the conversation is recorded and viewable by your teacher.  It's moderated, actually, by a second AI, and also, it does not tell you the answer.  It is not a cheating tool.  Notice, when the student says, tell me the answer, it says, I'm your tutor.\n",
        "\n",
        "What do you think is the next step for solving the problem? Now, if the student makes a mistake, and this will surprise people who think large language models are not good at mathematics, notice not only does it notice the mistake, it asks the student to explain their reasoning, but it's actually doing what I would say not just even an average tutor would do, but an excellent tutor would do. It's actually able to divine what is probably the misconception in that student's mind, that they probably didn't use the distributive properly.  Remember, we need to distribute the negative two to both the nine and the 2M inside of the parentheses.  This to me is a very, very, very big deal, and it's not just in math.  This is a computer programming exercise on Khan Academy where the student needs to make the clouds part, and so we can see the student starts defining a variable, left X minus minus.\n",
        "\n",
        "# AI as a Super Tutor\n",
        "\n",
        "It only made the left cloud part, but then they can ask a con amigo, what's going on? Why is only the left cloud moving? And it understands the code. It knows all the context of what the student is doing, and it understands that those ellipses are there to draw clouds, which I think is kind of mind-blowing, and it says, to make the right cloud move as well, try adding a line of code inside the draw function that increments the right X variable by one pixel in each frame.  Now, this one is maybe even more amazing, because we have a lot of math teachers.  We've all been trying to teach the world to code, but there aren't a lot of computing teachers out there, and what you just saw, even when I'm tutoring my kids when they're learning to code, I can't help them this well, this fast.  This is really going to be a super tutor.  And it's not just exercises.  It understands what you're watching.\n",
        "\n",
        "It understands the context of your video. It can answer the age-old question, why do I need to learn this? And it asks, socratically, well, what do you care about? And let's say the student says, I want to be a professional athlete, and it says, well, learning about the size of cells, which is what this video is about, that could be really useful for understanding nutrition and how your body works, et cetera.  It can answer questions.  It can quiz you.  It can connect it to other ideas.  You can now ask as many questions of a video as you could ever dream of.  So another big shortage out there, I remember the high school I went to, the student-to-guidance counselor ratio was about 200 or 300 to 1.  A lot of the country, it's worse than that.  We can use Conmigo to give every student a guidance counselor, academic coach, career coach, life coach, which is exactly what you see right over here.  And this is all, you know, we launched this with the GPT-4 launch.  We have a few thousand people on this.  This isn't a fake demo.\n",
        "\n",
        "§§§\n",
        "\n",
        "# Conversations with Historical Figures and AI Debates\n",
        "\n",
        "This is really in action. And then there's, you know, things that I think it would have been even harder, it would have been a little science fiction to do with even a traditional tutor.  There's a student, we run an online high school with Arizona State University called Khan World School.  And we have a student who attends that online school based in India, her name is Sanvi, and she was doing a report on the Great Gatsby.  And when she was reading the Great Gatsby, Jay Gatsby keeps looking at the green light off into the distance.  And she's like, well, why does he do that? She did some web searches, and people have obviously studied this and commented about the symbolism of that, but none of it was really resonating with her.  And then she realized that she had Conmigo and that she could talk to Jay Gatsby himself.\n",
        "\n",
        "# Unlocking Learning Literature and AI Debates\n",
        "\n",
        "And so, ah, splendid choice, old sport, I am now Jay Gatsby, the enigmatic millionaire from Escott Jarrell's classic. And so why do you keep staring at the green light? Ah, the green light, old sport.  It's a symbol of my dreams and desires, you see.  It's situated at the end of Daisy Buchanan's dock, across the bay from my mansion.  I gaze at it longingly as it represents my yearning for the past and my hope to reunite with Daisy, the love of my life.  And what was cool is Sanvi had said, I had this long conversation, she called him Mr.  Gatsby.  And at the end, she actually apologized for taking his time, which I thought was very polite of her.  But you can imagine, this unlocks learning literature, learning, you can talk to historical figures, we're even probably going to add an activity, you can talk to, like, the Mississippi River.  It brings things to life in ways that really were science fiction even six months or a year ago.  Students can get into debates with the AI.  And we've got, here's the students debating whether we should cancel student debt.  The student is against canceling student debt.  And we've gotten very clear feedback.  We've started running it at Con World School and our lab school that we have, Con Lab School.  The students, the high school students especially, they're saying, this is amazing to be able to fine tune my arguments without fearing judgment.\n",
        "\n",
        "# Enhancing Language Arts with AI Writing Collaboration\n",
        "\n",
        "It makes me that much more confident to kind of go into the classroom and really participate. And we all know that Socratic dialogue debate is a great way to learn.  But frankly, it's not out there for most students.  But now it can be accessible to hopefully everyone.  A lot of the narrative, we saw that in the headlines, has been it's going to do the writing for kids.  Kids are not going to learn to write.  But we are showing that there's ways that the AI doesn't write for you.  It writes with you.  So this is a little thing.  And my eight-year-old is addicted to this.  And he's not a kid that really liked writing before.  But where, you know, you could say, I want to write a horror story.  And it says, ooh, a horror story.  How spine-tingling and thrilling.  Let's dive into the world of eerie shadows and chilling mysteries.\n",
        "\n",
        "And this is an activity where the student will write two sentences. And then the AI will write two sentences.  And so they collaborate together on a story.  The students write, Beatrice was a misunderstood ghost.  She wanted to make friends but kept scaring them by accident.  And the AI says, poor Beatrice, a lonely spirit yearning for companionship.  One day she stumbled upon an old abandoned mansion, et cetera, et cetera.  I encourage you all to, you know, hopefully one day try this.  This is surprisingly fun.  Now to even more directly hit this use case.  And what I'm about to show you, everything I showed you so far is actually already part of Calmigo.  What I'm about to show you, we haven't shown to anyone yet.\n",
        "\n",
        "# Enhancing Reading Comprehension and Writing Skills with AI\n",
        "\n",
        "This is a prototype. We hope to be able to launch it in the next few months.  But this is to directly use AI, use generative AI, to not undermine English and language arts but to actually enhance it in ways that we couldn't have even conceived of even a year ago.  This is reading comprehension.  This is the students reading Steve Jobs' famous speech at Stanford.  And then as they get to certain points, they can click on that little question.  And the AI will then, Socratically, almost like an oral exam, ask the student about things.  And the AI can highlight parts of the passage.  Why did the author use that word? What was their intent? Does it back up their argument? They can start to do stuff that, once again, we never had the capability to give everyone a tutor, everyone a writing coach, to actually dig into reading at this level.  And you could go on the other side of it.  We have a whole workflow that helps them write, helps them be a writing coach, draw an outline.  But once a student actually constructs a draft, and this is where they're constructing a draft, they can ask for feedback, once again, as you would expect from a good writing coach.  In this case, the student we'll say, let's say, does my evidence support my claim? And then the AI not only is able to give feedback, but it's able to highlight certain parts of the passage and says, you know, on this passage, this doesn't quite support your claim, but once again, Socratically says, can you tell us why? So it's pulling the student, it's making them a better writer, giving them far more feedback than they've ever been able to actually get before, and we think this is going to dramatically accelerate writing, not hurt it.\n",
        "\n",
        "§§§\n",
        "\n",
        "# Personalized Education for Teachers\n",
        "Now, everything I've talked about so far is for the student, but we think this could be equally as powerful for the teacher to drive more personalized education and, frankly, save time and energy for themselves and for their students. So this is an American history exercise on Khan Academy.  It's a question about the Spanish-American war.  And at first, it's in student mode, and if you say, tell me the answer, it's not going to tell the answer, it's going to go into tutoring mode.  But that little toggle which teachers have access to, they can turn student mode off, and then it goes into teacher mode.  And what this does is, it turns into, you could view it as a teacher's guide on steroids.  Not only can it explain the answer, it can explain how you might want to teach it.\n",
        "\n",
        "# Benefits for Teachers\n",
        "It can help prepare the teacher for that material. It can help them create lesson plans, as you can see doing right there.  It'll eventually help them create progress reports, it'll help them eventually grade.  So once again, teachers spend about half their time with this type of activity, lesson planning, all of that energy can go back to them or go back to human interactions with their actual students.  So, you know, one point I want to make, these large language models are so powerful, there's a temptation to say, well, all these people are just going to slap them onto their websites, and it kind of turns the applications themselves into commodities.  And what I've got to tell you is, I kind of thought that's one of the reasons why I didn't sleep for two weeks when I first had access to GPT-4 back in August.\n",
        "\n",
        "# Enhancing AI Tutoring\n",
        "But we quickly realized that to actually make it magical, I think it's really important to make it magical, but we quickly realized that to actually make it magical, I think what you saw with Conmigo a little bit, it didn't interact with you the way that you see chat GPT interacting, it was a little bit more magical, it was more Socratic, it was clearly much better at math than what most people are used to thinking. And the reason is there was a lot of work behind the scenes to make that happen.  And I could go through the whole list of everything we've been working on, many, many people, for over six, seven months, to make it feel magical, but perhaps the most intellectually interesting one is we realized, and this was an idea from an open AI researcher, that we could dramatically improve its ability in math and its ability in tutoring if we allowed the AI to think before it speaks.\n",
        "\n",
        "# The Future of AI and Education\n",
        "So if you're tutoring someone and you immediately just start talking before you assess their math, you might not get it right. But if you construct thoughts for yourself, and what you see on the right there is an actual AI thought, something that it generates for itself but it does not share with the student, then its accuracy went up dramatically and its ability to be a world-class tutor went up dramatically.  And you can see it's talking to itself here.  It says, the student got a different answer than I did, but do not tell them they made a mistake.  Instead, ask them to explain how they got to that step.  So I'll just finish off.\n",
        "\n",
        "# The Role of AI in Education and the Need for Positive Use Cases\n",
        "Hopefully, what I've just shown you is just half of what we are working on, and we think this is just the very tip of the iceberg of where this can actually go. And I'm pretty convinced, which I wouldn't have been even a year ago, that we, together, have a chance of addressing the two-sigma problem and turning it into a two-sigma opportunity, dramatically accelerating education as we know it.  Now, just to take a step back at a meta-level, obviously, we heard a lot today, the debates on either side.  There's folks who take a more pessimistic view of AI.  They say, this is scary, there's all these dystopian scenarios.  We maybe want to slow down.  We want to pause.  On the other side, there are the more optimistic folks who say, well, we've gone through inflection points before.\n",
        "\n",
        "We've gone through the Industrial Revolution. It was scary, but it all kind of worked out.  And what I'd argue right now is, I don't think this is like a flip of a coin or this is something where we'll just have to wait and see which way it turns out.  I think everyone here and beyond, we are active participants in this decision.  I'm pretty convinced that the first line of reasoning is actually almost a self-fulfilling prophecy, that if we act with fear and if we say, hey, we just got to stop doing this stuff, what's really going to happen is the rule followers might pause, might slow down, but the rule breakers, as Alexander mentioned, the totalitarian governments, the criminal organizations, they're only going to accelerate.\n",
        "\n",
        "And that leads to what I am pretty convinced is the dystopian state, which is the good actors have worse AIs than the bad actors. But I'll also talk to the optimist a little bit.  I don't think that means that, oh yeah, then we should just relax and just hope for the best.  That might not happen either.  I think all of us together have to fight like hell to make sure that we put the guardrails, we put in, when the problems arise, reasonable regulations, but we fight like hell for the positive use cases.  Because very close to my heart, and obviously there's many potential positive use cases, perhaps the most powerful use case, and perhaps the most poetic use case, is if AI, artificial intelligence, can be used to enhance HI, human intelligence, human potential and human purpose.  Thank you.  Thank you.  Thank you.\n",
        "'''"
      ],
      "metadata": {
        "id": "z9v5qGPi3JWQ",
        "cellView": "form"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Gradio App"
      ],
      "metadata": {
        "id": "g89pWgpuUQI3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def run_gradio_app():\n",
        "  import gradio as gr\n",
        "\n",
        "  # Theming\n",
        "  theme = gr.themes.Default(\n",
        "      primary_hue=\"slate\" # , radius_size=gr.themes.Size(radius_sm=\"3px\", radius_xs=\"2px\", radius_xxs=\"1px\")\n",
        "  )\n",
        "  # Styling: Change max width\n",
        "  css = \"\"\"\n",
        "    .gradio-container {max-width: 800px!important}\n",
        "    .vspacer1 {margin-top: 50px}\n",
        "  \"\"\"\n",
        "\n",
        "  with gr.Blocks(theme=theme, css=css) as demo:\n",
        "\n",
        "      gr.Markdown(\"# ChatGPTLab 2.0\", elem_classes=\"vspacer1\")\n",
        "      gr.Markdown(\"### Optimizing your work with LLMs.\")\n",
        "\n",
        "      project_name = gr.Textbox(label=\"Project name\")\n",
        "\n",
        "      #\n",
        "      # 1. Input Text\n",
        "      #\n",
        "      with gr.Tab(\"Input Text \"):\n",
        "        gr.Markdown(\"Please enter text\")\n",
        "\n",
        "        # Input text via UI\n",
        "        gr.Markdown(\"### Input your text:\")\n",
        "        text_input = gr.Textbox(label=\"Enter text\", placeholder=\"Your text here...\", lines=10)\n",
        "        text_output = gr.Textbox(label=\"Result\")\n",
        "\n",
        "        def text_save(text, proj_name):\n",
        "          create_file_directory(proj_name, False)\n",
        "          create_file_directory(proj_name + '/' +  folders['text-input'], False)\n",
        "          f= open(proj_name + '/' +  folders['text-input'] + '/input_text.txt','w+')\n",
        "          f.write(text)\n",
        "          f.close()\n",
        "          log_text = \"Text saved.\"\n",
        "          return log_text\n",
        "        text_button = gr.Button(\"Save text\")\n",
        "        text_button.click(text_save, [text_input, project_name], text_output)\n",
        "\n",
        "        gr.Markdown(\"\")\n",
        "        gr.Markdown(\"\")\n",
        "\n",
        "        # Input text via upload\n",
        "        gr.Markdown(\"### Or upload your text:\")\n",
        "        upload_button = gr.UploadButton(\"Click to Upload a File\", file_types=[\".txt\",\".md\"], file_count=\"single\")\n",
        "        file_output = gr.Textbox(label=\"Result\")\n",
        "\n",
        "        def upload_file(my_file, proj_name):\n",
        "          create_file_directory(proj_name, False)\n",
        "          create_file_directory(proj_name + '/' +  folders['text-input'], False)\n",
        "          # copy to project directory\n",
        "          full_upload_path = my_file.name\n",
        "          just_the_filename = os.path.basename(full_upload_path)\n",
        "          full_text_path = \"./\" + proj_name + '/' + folders['text-input'] + '/' + just_the_filename\n",
        "          shutil.copyfile(full_upload_path, full_text_path)\n",
        "          # check if file is empty\n",
        "          f= open(full_text_path,'r')\n",
        "          if f.mode == 'r': contents =f.read()\n",
        "          f.close()\n",
        "          log_text = just_the_filename + \"\\n\"\n",
        "          if len(contents) == 0:\n",
        "            log_text = log_text + \"Error: Upload file lengt 0 bytes\"\n",
        "          else:\n",
        "            log_text = log_text + \"Upload successful\"\n",
        "          return log_text\n",
        "        upload_button.upload(upload_file, [upload_button, project_name], file_output)\n",
        "\n",
        "      #\n",
        "      # 2. Download full project\n",
        "      #\n",
        "      with gr.Tab(\"Download\"):\n",
        "        gr.Markdown(\"Download full project as ZIP file.\")\n",
        "        download_button = gr.Button(\"Download project\")\n",
        "        download_output = gr.File()\n",
        "\n",
        "        def download_do(proj_name):\n",
        "          full_text_path = \"./\" + proj_name\n",
        "          shutil.make_archive('archive', 'zip', full_text_path)\n",
        "          result = \"Downloading \" + full_text_path\n",
        "          return \"archive.zip\"\n",
        "        download_button.click(download_do, project_name, download_output)\n",
        "\n",
        "      #\n",
        "      # 3. xxx\n",
        "      #\n",
        "      with gr.Tab(\"Step 2\"):\n",
        "        gr.Markdown(\"Please select the optimization:\")\n",
        "        radio = gr.Radio(\n",
        "          [\"by headline\", \"by paragraph\", \"by §§§\"], label=\"Text split method\"\n",
        "        )\n",
        "        name = gr.Textbox(label=\"Name\", placeholder=\"Enter text...\")\n",
        "        output = gr.Textbox(label=\"Output Box\")\n",
        "        greet_btn = gr.Button(\"Start\", scale=0)\n",
        "        def greet(name):\n",
        "          result = \"HALLO \" + name + \"!!!\"\n",
        "          return result\n",
        "        greet_btn.click(fn=greet, inputs=name, outputs=output, api_name=\"greet\")\n",
        "\n",
        "  demo.launch(quiet=True, share=False, debug=debug_mode)\n",
        "\n",
        "#run_gradio_app()"
      ],
      "metadata": {
        "id": "ShdVRDZIUR7k"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Test GPT"
      ],
      "metadata": {
        "id": "f34XuANJ6vIf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tmp = split_text_by_separator(test_text1, '\\n', '\\n', 'fix-nothing', 200)\n",
        "print(text_stats(test_text1))\n",
        "print(len(tmp))"
      ],
      "metadata": {
        "id": "RlmHqVJijfXY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f189d65c-7b5d-4679-a157-3b3f4d6bf458"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of words / paragraphs / §§§ segements: 197 / 1 / 1\n",
            "1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# test promptlib and templates\n",
        "\n",
        "import textwrap\n",
        "\n",
        "prompt_obj = get_prompt_from_lib(promptlib_global, 'summary-bullets', '1')\n",
        "# prompt_obj = get_prompt_from_lib(promptlib_global, 'summary-bullets', '1')\n",
        "print(json.dumps(prompt_obj, sort_keys=True, indent=2))\n",
        "\n",
        "input_text = 'This is the input text. Lorem ipsum.'\n",
        "\n",
        "prompt_txt_final1 = build_prompt_from_template(input_text, prompt_obj, 'lang-de', 'length-max-dyn', 0.5, 'toc')\n",
        "prompt_txt_final2 = build_prompt_from_template(input_text, prompt_obj, 'lang-de', 'length-max-fix', 0, '')\n",
        "prompt_txt_final3 = build_prompt_from_template(input_text, prompt_obj, 'lang-de', '', 0, '')\n",
        "print(textwrap.fill(prompt_txt_final1, 120))\n",
        "\n",
        "#write_prompt_to_lib(prompt_obj)\n",
        "\n",
        "#print(json.dumps(promptlib, sort_keys=True, indent=2))\n",
        "\n",
        "# myprompt = \"The given text is delimited by triple backticks. Summarize the current text to succint and clear bullet points of its contents.\n",
        "#          The length of the summary must be 200 words maximum.\"\n",
        "# myprompt = \"The given text is delimited by triple backticks.\n",
        "#           Summarize the current text to a maximum of 15 succint and clear bullet points of its contents.\"\n",
        "# myprompt = myprompt + \"The maximum number of words should be 300 words in total. \"\n",
        "# myprompt = myprompt + \"Write everything in German language. \" # this is optional !\n",
        "# myprompt = myprompt + \"```\" + input_text + \"```\""
      ],
      "metadata": {
        "id": "OsYX9xQ2mjZd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3b479a9d-1807-4b1b-8547-148d386e1c8f"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\n",
            "  \"category\": \"summarize\",\n",
            "  \"description\": \"Max word length: 1100 for EN, 900 for DE. approx. 1 min processing time Example: Full book: 113 parts \\u00e1 1000 words takes 15 min.\",\n",
            "  \"id\": \"summary-bullets\",\n",
            "  \"input-text-max\": 500,\n",
            "  \"lang-de\": \"Write everything in German language.\",\n",
            "  \"lang-en\": \"Write everything in English language.\",\n",
            "  \"lang-same\": \"If the following text in triple backticks is in German language write your text in German language, too.\",\n",
            "  \"length-max-dyn\": \"The length of the summary must be {{length_calc(\\\"{input_text}\\\", {max_len})}} words maximum.\",\n",
            "  \"length-max-fix\": \"The length of the summary must be 300 words maximum.\",\n",
            "  \"note\": \"summarize to bullets v3\",\n",
            "  \"prompt\": \"The given text is delimited by triple backticks. Write a detailed bullet-point summary. {language_text} {length_text} Text:```{input_text}``` {toc_text}\",\n",
            "  \"version\": \"3\"\n",
            "}\n",
            "The given text is delimited by triple backticks. Write a detailed bullet-point summary. Write everything in German\n",
            "language. The length of the summary must be 3 words maximum. Text:```This is the input text. Lorem ipsum.``` toc\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "info_1.layout.visibility = \"hidden\"\n",
        "info_1.close()\n",
        "del info_1\n",
        "button_1.layout.visibility = \"visible\"\n",
        "button_2.layout.visibility = \"visible\"\n",
        "button_3.layout.visibility = \"visible\"\n",
        "button_4.layout.visibility = \"visible\"\n",
        "#text_1.value=\"yoyo\""
      ],
      "metadata": {
        "id": "J2HUTsPjygWN"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Workbench"
      ],
      "metadata": {
        "id": "-75HtkuDz9eP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "proj_name = 'S4HANA'\n",
        "#create_file_directory(proj_name, True) # For dev: Initial folder structure\n",
        "#create_file_directory(proj_name + '/' + folders['text-output'], True)\n",
        "#create_file_directory(proj_name + '/' + folders['text-output-logs'], True)\n",
        "#create_test_project(proj_name, '')\n",
        "\n",
        "# Step 1\n",
        "def step_1():\n",
        "  model = 'gpt-3.5-turbo'\n",
        "  prompt_name = 'summary-shortened'\n",
        "  prompt_version = '1'\n",
        "  prompt_comment = 'TODO: HIER EINE NOTIZ. HIER EINE NOTIZ. HIER EINE NOTIZ. HIER EINE NOTIZ.'\n",
        "  prompt_obj = get_prompt_from_lib(promptlib_global, prompt_name, model, prompt_version)\n",
        "  #print(json.dumps(prompt_obj, sort_keys=False, indent=2))\n",
        "  result_file = execute_prompt({\n",
        "      'model': model,\n",
        "      'prompt-name': prompt_name,\n",
        "      'prompt-version': prompt_version,\n",
        "      'prompt-comment': prompt_comment,\n",
        "      'loglevel': 0,\n",
        "      'stop-after-step': 1,\n",
        "      'proj-name': proj_name,\n",
        "      'input-filepath': '', #'text-output',\n",
        "      'input-filename': '', #'paraphrased.txt',\n",
        "      'folders': folders,\n",
        "      'prompt-obj': prompt_obj,\n",
        "      'language': 'lang-de',\n",
        "      'length-type': 'length-max-dyn',\n",
        "      'length-max': 0.5,\n",
        "      'toc-text': '',\n",
        "      'result-filename': '01-paraphr-short.md'\n",
        "  })\n",
        "  print(result_file)\n",
        "  a, b = result_file\n",
        "  print(a)\n",
        "  print(b)\n",
        "\n",
        "# Step 2\n",
        "def step_2():\n",
        "  model = 'gpt-3.5-turbo'\n",
        "  prompt_name = 'create-subheadlines'\n",
        "  prompt_version = '1'\n",
        "  prompt_obj = get_prompt_from_lib(promptlib_work, prompt_name, model, prompt_version)\n",
        "  #print(json.dumps(prompt_obj, sort_keys=False, indent=2))\n",
        "  result_file = execute_prompt({\n",
        "      'model': model,\n",
        "      'prompt-name': prompt_name,\n",
        "      'prompt-version': prompt_version,\n",
        "      'loglevel': 0,\n",
        "      'stop-after-step': 3,\n",
        "      'proj-name': proj_name,\n",
        "      'input-filepath': 'text-output',\n",
        "      'input-filename': '01-paraphr-short_gpt-3.md',\n",
        "      'folders': folders,\n",
        "      'prompt-obj': prompt_obj,\n",
        "      'language': 'lang-same',\n",
        "      'length-type': '',\n",
        "      'length-max': 0,\n",
        "      'toc-text': '',\n",
        "      'result-filename': '01-paraphr-short-headlines.md'\n",
        "  })\n",
        "\n",
        "# Step 3\n",
        "def step_3():\n",
        "  model = 'gpt-3.5-turbo'\n",
        "  prompt_name = 'summary-shortened'\n",
        "  prompt_version = '1'\n",
        "  prompt_obj = get_prompt_from_lib(promptlib_work, prompt_name, model, prompt_version)\n",
        "  #print(json.dumps(prompt_obj, sort_keys=False, indent=2))\n",
        "  result_file = execute_prompt({\n",
        "      'model': model,\n",
        "      'prompt-name': prompt_name,\n",
        "      'prompt-version': prompt_version,\n",
        "      'loglevel': 0,\n",
        "      'stop-after-step': 3,\n",
        "      'proj-name': proj_name,\n",
        "      'input-filepath': 'text-output',\n",
        "      'input-filename': '01-paraphr-short-headlines_gpt-3.md',\n",
        "      'folders': folders,\n",
        "      'prompt-obj': prompt_obj,\n",
        "      'language': 'lang-de',\n",
        "      'length-type': 'length-max-dyn',\n",
        "      'length-max': 0.5,\n",
        "      'toc-text': '',\n",
        "      'result-filename': '02-paraphr-short.md'\n",
        "  })\n",
        "\n",
        "#step_1()\n",
        "#step_2()\n",
        "#step_3()\n",
        "\n",
        "# Idea: chain by returning filename of last file => can be input for next"
      ],
      "metadata": {
        "id": "xC1LzpVwasQr"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "notiz = {\n",
        "  \"prompt\": \"I want you to act as a very proficient SEO and high-end. I want you to pretend that you can write content so well that it can\\\n",
        "   outrank other websites. All output must be 100% human writing style and fix grammar issues and change to active voice. Your task is to\\\n",
        "   write an article starting with SEO Title with a bold letter and rewrite the content and include subheadings using related keywords.\\\n",
        "   Write in the style and tone of a professional IT magazine for software experts. Write every sentence in your very own words and do not\\\n",
        "   only rephrase the given content. The article must be 100% unique and remove plagiarism. Do not write a summary or conclusions in the\\\n",
        "  last paragraph. Avoid lists. Include subheadings. {language_text} {length_text} Text:```{input_text}```\"\n",
        "}"
      ],
      "metadata": {
        "id": "L-0jGjPwCAVW"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "proj_name = 'Handelsblatt'\n",
        "#create_file_directory(proj_name + '/' + folders['text-output'], True)\n",
        "#create_file_directory(proj_name + '/' + folders['text-output-logs'], True)\n",
        "#create_test_project(proj_name, '')\n",
        "\n",
        "\n",
        "# Step 1\n",
        "def step_1():\n",
        "  model = 'gpt-4'\n",
        "  prompt_obj = get_prompt_from_lib(promptlib_work, 'summary-multiple-articles', model, '1')\n",
        "  #print(json.dumps(prompt_obj, sort_keys=False, indent=2))\n",
        "  result_text = execute_prompt({\n",
        "      'model': model,\n",
        "      'loglevel': 0,\n",
        "      'stop-after-step': 0,\n",
        "      'proj-name': proj_name,\n",
        "      'input-filepath': '', #'text-output',\n",
        "      'input-filename': '', #'paraphrased.txt',\n",
        "      'folders': folders,\n",
        "      'prompt-obj': prompt_obj,\n",
        "      'language': 'lang-de',\n",
        "      'length-type': '',\n",
        "      'length-max': 0,\n",
        "      'toc-text': '',\n",
        "      'result-filename': '01-paraphr-short.md'\n",
        "  })\n",
        "\n",
        "#step_1()"
      ],
      "metadata": {
        "id": "No_0zjVjHkkT"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Current Work / Test"
      ],
      "metadata": {
        "id": "0GpudYkTcdAG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "promptlib_global['summary-shortened-same-tone'] = {\n",
        "      'description': 'Abgeleitet aus \"summary-shortened\"',\n",
        "      'category': 'summarize',\n",
        "      '1': {\n",
        "          'note': 'Summary without changing the tone',\n",
        "          \"prompt\": \"Paraphrase the following text and shorten each paragraph of the paraphrased text to maxiumum the half of its original length by focussing\\\n",
        "            on the key aspects. Write in the same style and tone as the given text. Be detailed and precise\\\n",
        "            and use every content detail of the text. {language_text} {length_text} Text:```{input_text}```\",\n",
        "          \"lang-de\": \"Write everything in German language.\",\n",
        "          \"lang-en\": \"Write everything in English language.\",\n",
        "          \"lang-same\": \"If the following text in triple backticks is in German language write your text in German language, too.\",\n",
        "          'gpt-3.5-turbo': {\n",
        "              \"input-text-max\": 1200,\n",
        "              \"length-max-fix\": \"The length of the full text must be 1200 words maximum.\",\n",
        "              \"length-max-dyn\": \"The length of the full text must be {{length_calc(\\\"{input_text}\\\", {max_len})}} words maximum.\"\n",
        "          },\n",
        "          'gpt-4': {\n",
        "              \"input-text-max\": 2400,\n",
        "              \"length-max-fix\": \"The length of the full text must be 2400 words maximum.\",\n",
        "              \"length-max-dyn\": \"The length of the full text must be {{length_calc(\\\"{input_text}\\\", {max_len})}} words maximum.\"\n",
        "          }\n",
        "      }\n",
        "    }\n",
        "text_from_file = \"<File:>\"\n",
        "comment = 'Kommentar zum Projekt...'\n",
        "# execute_project('S4HANA', 'gpt-4', promptlib_global, 'summary-shortened-same-tone', '1', 'length-max-dyn', 0, '', True, folders, text_from_file, comment)"
      ],
      "metadata": {
        "id": "SyjjeU56chJK"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "4FuTcPBgxhn1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "comment = 'Kommentar zum Projekt...'\n",
        "#execute_project('Handelsblatt Fr', 'gpt-4', promptlib_global, 'summary-multiple-articles', '1', 'length-max-dyn', 5, '' ,True, folders, '<File:>', comment)"
      ],
      "metadata": {
        "id": "pWfQO90TmCEd"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "promptlib_global['article-create-toc'] = {\n",
        "      'description': '',\n",
        "      'category': 'create-article',\n",
        "      '1': {\n",
        "          'note': 'Step 1: Create TOC',\n",
        "          \"prompt\": \"Here is some context for an article. The context is marked with 'Text:' and delimited by triple backticks. \\\n",
        "            Create a table of contents for an article titled 'Der Wert von Geschriebenem in Zeiten von Chat-GPT'. {language_text} {length_text} Text:```{input_text}``` {toc_text}\",\n",
        "          \"lang-de\": \"Write everything in German language.\",\n",
        "          \"lang-en\": \"Write everything in English language.\",\n",
        "          \"lang-same\": \"If the following text in triple backticks is in German language write your text in German language, too.\",\n",
        "          'gpt-3.5-turbo': {\n",
        "              \"input-text-max\": 1200,\n",
        "              \"length-max-fix\": \"The length of the full text must be 1200 words maximum.\",\n",
        "              \"length-max-dyn\": \"The length of the full text must be {{length_calc(\\\"{input_text}\\\", {max_len})}} words maximum.\"\n",
        "          },\n",
        "          'gpt-4': {\n",
        "              \"input-text-max\": 2400,\n",
        "              \"length-max-fix\": \"The length of the full text must be 2400 words maximum.\",\n",
        "              \"length-max-dyn\": \"The length of the full text must be {{length_calc(\\\"{input_text}\\\", {max_len})}} words maximum.\"\n",
        "          },\n",
        "          'default-model': {\n",
        "              \"input-text-max\": 2400,\n",
        "              \"length-max-fix\": \"The length of the full text must be 2400 words maximum.\",\n",
        "              \"length-max-dyn\": \"The length of the full text must be {{length_calc(\\\"{input_text}\\\", {max_len})}} words maximum.\"\n",
        "          }\n",
        "      }\n",
        "    }\n",
        "promptlib_global['article-create-chapter'] = {\n",
        "      'description': '',\n",
        "      'category': 'create-article',\n",
        "      '1': {\n",
        "          'note': 'Step 2: Create first chapter',\n",
        "          \"prompt\": \"Here is some context for an article titled 'Der Wert von Geschriebenem in Zeiten von Chat-GPT'. The context is marked with 'Text:' and delimited by triple backticks. \\\n",
        "            The table of contents is marked with 'TOC:' and delimited by triple backticks.\\\n",
        "            Write chapter 1 with a length of 500 words. {language_text} {length_text} Text:```{input_text}``` {toc_text}\",\n",
        "          \"lang-de\": \"Write everything in German language.\",\n",
        "          \"lang-en\": \"Write everything in English language.\",\n",
        "          \"lang-same\": \"If the following text in triple backticks is in German language write your text in German language, too.\",\n",
        "          'gpt-3.5-turbo': {\n",
        "              \"input-text-max\": 1200,\n",
        "              \"length-max-fix\": \"The length of the full text must be 1200 words maximum.\",\n",
        "              \"length-max-dyn\": \"The length of the full text must be {{length_calc(\\\"{input_text}\\\", {max_len})}} words maximum.\"\n",
        "          },\n",
        "          'gpt-4': {\n",
        "              \"input-text-max\": 2400,\n",
        "              \"length-max-fix\": \"The length of the full text must be 2400 words maximum.\",\n",
        "              \"length-max-dyn\": \"The length of the full text must be {{length_calc(\\\"{input_text}\\\", {max_len})}} words maximum.\"\n",
        "          },\n",
        "          'default-model': {\n",
        "              \"input-text-max\": 2400,\n",
        "              \"length-max-fix\": \"The length of the full text must be 2400 words maximum.\",\n",
        "              \"length-max-dyn\": \"The length of the full text must be {{length_calc(\\\"{input_text}\\\", {max_len})}} words maximum.\"\n",
        "          }\n",
        "      }\n",
        "    }\n",
        "text_from_file = \"<File:>\"\n",
        "\n",
        "# Step 1\n",
        "comment = 'Kommentar zum Projekt...'\n",
        "#execute_project('article-future-of-text', 'gpt-4', promptlib_global, 'article-create-toc', '1', '', 0, '', True, folders, text_from_file, comment)\n",
        "\n",
        "# Step 2\n",
        "toc_text = f\"\"\"TOC: \\`\\`\\`Inhaltsverzeichnis:\n",
        "Titel: Der Wert von Geschriebenem in Zeiten von Chat-GPT\n",
        "1. Künstliche Intelligenz und ihre Auswirkungen auf die täglichen Aufgaben\n",
        "2. Die Rolle von Bots in der schriftlichen Kommunikation\n",
        "3. Verhandlungen und Diskussionen in einer von Bots dominierten Welt\n",
        "4. Die Auswirkungen von Künstlicher Intelligenz auf die Kreativität und die Wahrnehmung von Originalität\n",
        "5. Die Auswirkungen von Künstlicher Intelligenz auf die Arbeit von Autoren und die Bedeutung von Charisma\n",
        "6. Fazit: Die Zukunft von Geschriebenem in Zeiten von Chat-GPT.\n",
        "\\`\\`\\`\"\"\"\n",
        "#execute_project('article-future-of-text', 'gpt-4', promptlib_global, 'article-create-chapter', '1', '', 0, toc_text, False, folders, text_from_file, comment)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "KtiPlr6jbGrw"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#import_prompt_lib()\n",
        "#import_helper_lib()\n",
        "#print(test_pypandoc())"
      ],
      "metadata": {
        "id": "LJQKtb0jjzSX"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Ideas\n",
        "- Markdown Konvertierung wenn docx\n",
        "- Chaining (ausgabefile)\n",
        "- Artikel schreiben TOC, danach Kapitel\n",
        "\n",
        "\n",
        "## How to Overcome GPT Token Limit: With Vector indices\n",
        "- Vector search enables the inclusion of only pertinent information from the loaded data into the model's context.\n",
        "- Steps to implement this solution include registering for a database service, splitting documents into smaller chunks, converting them into vectors, and querying the index to find relevant information.\n",
        "- The provided code examples utilize the Pinecone database and OpenAI's Ada model for vector conversion, but other alternatives can be explored.\n",
        "- https://uxplanet.org/how-to-overcome-gpt-token-limit-721c30a18d55"
      ],
      "metadata": {
        "id": "HbqC5kDF-ms5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Quick Action"
      ],
      "metadata": {
        "id": "ZwFqoRERWSCg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#import_promptlib() # during dev: update promptlib from promptlib.ipynb\n",
        "my_input_text = widgets.Textarea(placeholder='Enter input text', layout=Layout(width='50%', height='150px'), disabled=False)\n",
        "button = widgets.Button(description=\"Summarize!\")\n",
        "def on_button_clicked(b):\n",
        "  comment = 'Kommentar zum Projekt...'\n",
        "  #execute_project('Handelsblatt', 'gpt-3.5-turbo', '', promptlib_global, 'summary-multiple-articles', '1', 'length-max-dyn', '', 0 ,True, folders, my_input_text.value, comment)\n",
        "  execute_project('quick-action', 'gpt-3.5-turbo', 'Shorten this text, answer in German: ', {}, 'Manual prompt', '', '1000', '', 0, True, folders, my_input_text.value, comment)\n",
        "button.on_click(on_button_clicked)\n",
        "display(my_input_text, button)"
      ],
      "metadata": {
        "id": "8zhMIX90AUlW",
        "outputId": "94c51adc-3724-4628-c429-dcce71fd825f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 203,
          "referenced_widgets": [
            "58d8f3bf3f464572aeda481d875b3589",
            "b867e32b455348398cb747079c41941f",
            "8e740ccf763c4ea2acecca7c18d0efe4",
            "16bb471b4b9f42e8a8d70ee6c83dc23d",
            "4559a204277247cc8d8bd110f643688c",
            "04466e626ca841068fef16b239fc76ee"
          ]
        }
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Textarea(value='', layout=Layout(height='150px', width='50%'), placeholder='Enter input text')"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "58d8f3bf3f464572aeda481d875b3589"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Button(description='Summarize!', style=ButtonStyle())"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "16bb471b4b9f42e8a8d70ee6c83dc23d"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "t508EftHM4U2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Manual Prompt\n",
        "\n",
        "- Variable `input_dev` enthält Kontext\n",
        "- Variable `prompt_dev` enthält Prompt\n",
        "\n",
        "**Aufruf:**\n",
        "```\n",
        "execute_project('quick-action', 'gpt-3.5-turbo', prompt_dev, {}, 'Manual prompt', '', '500', '', 2, True, folders, input_dev, comment)\n",
        "```\n",
        "- quick-action: Projekt/Ordnername\n",
        "- '500' Anzahl Wort-Split bei langen Texten\n",
        "- 2 => Abbruch nach Step 2 (für Dev), sonst 0\n"
      ],
      "metadata": {
        "id": "ioFOFSZWAQBN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# @title\n",
        "input_dev = f\"\"\"\n",
        " Herzlich willkommen zum Content-Performance-Podcast mit Fabian Deckert und Benjamin Odani, der Online-Marketing-Podcast für Fortgeschrittene. Hallo Fabian. Hallo Benjamin. Und hallo Michael. Ja, hallo zusammen. Heute sprechen wir darüber, wie Deloitte Thought Leadership Content entwickelt und dafür haben wir uns einen super Gast geholt in unserem Podcast, und zwar den Michael Gramp. Du bist Chefökonom bei Deloitte in der Schweiz, Leiter des Research Teams und eben auch verantwortlich für diese Thought Leadership Publikation. Vielen Dank, dass du dir die Zeit nimmst, um mit uns darüber zu sprechen. Ja, unbedingt. Und vielen Dank für die Einladung und toll, dass ich in einem meiner Lieblings-Podcasts, die ich ja schon seit Jahren kenne, zu Gast sein darf. Ja, also vollkommen zurecht, finde ich, und vielen Dank für das Lob und dann lass uns doch mal direkt reinspringen in das Thema, also das, weil Thought Leadership ist ja sowas, das wird viel diskutiert, aber die Wenigsten machen das ja wirklich, weil es ja auch teilweise sehr intensiv ist, was die Umsetzung angeht und deswegen direkt die erste Frage, warum macht ihr denn oder warum investiert ihr denn als Deloitte in Thought Leadership Content? Ja, also das ist eine gute Frage und was man vielleicht vorausschicken muss, bei uns ist es keine Auftragsarbeit, denn häufig sehe ich Content-Inhalte, die von Firmen erstellt werden, die aber teilweise irgendwelche Auftraggeber im Hintergrund haben, extern, also das ist mal wichtig, das machen wir nicht. Es ist wirklich ein reines Investment, ein Geldinvestment letzten Endes auch, weil du natürlich ein Team dazu brauchst und Thought Leadership hilft dir dabei, sage ich mal, ein Unternehmen, aber auch eine Einzelperson zu positionieren als Vordenker, als innovativer Thought Leader zu einzelnen Themen als Experte und diese Positionierung hilft natürlich bei der, sage ich mal, Marke, beim Auftritt des Unternehmens etc. und dadurch langfristig kannst du natürlich Kundenbeziehungen aufbauen oder eine Kundenbindung verstärken dadurch, also das ist natürlich das langfristige Ziel immer dabei. Ja, sprechen wir später nochmal über KPIs, sprechen wir später nochmal, ne? Ja, genau, KPIs ist natürlich eine ganz wichtige Sache dabei und die können wir ganz später noch im Detail besprechen, ja. Jetzt habt ihr, die Leute ist ja richtig groß, also ihr habt, ich glaube, 450.000 Angestellte weltweit, so weit ich weiß. Richtig, richtig. Und da fragt man sich natürlich, wie ist das denn dann organisiert? Also wie habt ihr diesen, ihr sagt, wir wollen strategisch investieren in Thought Leadership und in Thought Leadership Content, um uns eben im Markt zu positionieren als Vordenker. Wie habt ihr das dann in so einem großen Konzern organisiert? Genau, also wichtig ist mal zu wissen, die Leute, also wir sind ja die größte Beratungsgesellschaft der Welt und wir sind einzelne Ländergesellschaften, also wir sind nicht der klassische Konzern, wie es jetzt vielleicht ein Google wäre oder ein Mercedes oder so, die wo ein großes Headquart ist und alles bestimmt, sondern wir sind regional aufgestellt und daher ist auch der Thought Leadership-Bereich auf drei Ebenen gegliedert. Es gibt globales Thought Leadership, also ein Team, das sitzt in den USA bei uns, das globale Themen quasi für alle Ländergesellschaften erstellt. Logischerweise ist das ein bisschen mehr high-level, also ein bisschen oberflächlicher. Man kann natürlich jetzt nicht was schweizspezifisches oder spezifisches für Deutschland darin erstellen, aber man hat eine gute Pipeline, eine Inhaltspipeline und es werden die für uns wichtigen Themen global erstellt. Dann haben wir regionale Research-Teams und Content-Teams, die Thought Leadership erstellen. EMEA, die sitzt bei uns in Großbritannien und in Deutschland. Es ist ein Team, das europäische Themen, aber auch mal afrikanische Themen, also EMEA ist ja Afrika und Far East as well, mit aufnimmt und Mittel-East, sorry, nicht Far East. Und dann gibt es die lokalen nationalen Teams, hat nicht jedes Land. Wir sind in 160 Ländern weltweit tätig. Das haben eher ein bisschen die größeren Gesellschaften Großbritannien, Deutschland, die Schweiz und haben ja lokale Teams, wie zum Beispiel in der Schweiz. Und wir bearbeiten ausschließlich Schweizer Thought Leadership Themen oder die deutschen Kollegen eben eher die deutschen Themen und haben dann natürlich auch andere Schwerpunkte als in Deutschland. Ist die Automobilindustrie nach wie vor wichtig, weshalb hier mehr Content für die Automobilindustrie erstellt wird. In der Schweiz weniger, weil es für uns nicht so ein wichtiger Sektor ist. Dafür sind es dann andere Themen. Kannst du mal so ein paar Beispiele nennen, was ihr so für Themen macht? Ja, genau. Also es gibt so industriespezifische. Das hängt wirklich von der Branche ab. Also hier in der Schweiz ist natürlich die Bankenbranche wichtig, die Versicherungsbranche, Life Science, die MEM-Industrie, wie wir die hier nennen. Das ist also Maschinenbau etc. In Deutschland ist dann mehr ein bisschen Automobilindustrie, aber auch noch andere Pharma- und chemische Industrie. Und dann gibt es industrieübergreifende Themen. Das sind natürlich sehr häufig Technologiethemen. Das sind aber auch Themen wie die Zukunft der Arbeit, das heißt, wie wir in Zukunft arbeiten werden. Das sind Themen wie Cyberkriminalität, also Cybersicherheit, wie wir das nennen. Das sind dann die industrieübergreifenden Themen. Also wir greifen immer Themen auf, die für Unternehmen wichtig sind und die gerade so diese Hot Topics, diese aktuellen Themen sind oder die in Zukunft kommen. Denn das sind Herausforderungen, wo wir dann glauben, dass wir Lösungen haben für Unternehmen. Und diese Sachen thematisieren wir dann. Und wie ist das denn? Also ist das wirklich, seid ihr Thought Leadership? Ist das so das, was über eurem Team drübersteht? Oder ist das eher so noch im Marketing aufgehangen und dann macht man das noch so nebenbei? Oder ist es wirklich eure Kernaufgabe, an Thought Leadership zu arbeiten? Kein organisatorisch oder von Titel her? Also wir sind nicht im Marketing aufgehängt und wir können gerne nachher noch mal drüber sprechen, wie man es eigentlich nicht machen sollte, weil den größten Fehler, den die meisten Firmen machen, sie hängen es im Marketing auf. Können wir aber später noch dazu sprechen. Können wir gerne auch jetzt machen. Warum? Lass uns erst mal kurz. Also wir sind ganz klar Content-Driven, das heißt, Inhalt treibt alles andere bei uns. Und die Erstellung von Inhalt Thought Leadership Inhalt steht ganz am Anfang. Den produzieren wir und damit füttern wir Kommunikation, Marketing, Kundenbeziehungen etc. Und deswegen sollte auch ein Research Team, das diese Sachen arbeitet, nicht im Marketing sitzen. Jetzt kann man ein bisschen drüber streiten, rein von der Organisation, wenn das Team natürlich relativ unabhängig arbeiten kann und die Experten hat, kann das natürlich organisatorisch schon im Marketing sitzen. Was ich aber häufig sehe, ist, dass Marketing oft glaubt, sie können Thought Leadership Content produzieren. Und das ist in der Regel nicht der Fall, weil du brauchst wirklich die Contentexperten dafür. Und das sind meistens Researcher, es sind Leute, die gut schreiben können. Noch am ehesten funktioniert es in der Kommunikationsabteilung. Aber noch besser ist es, einen losgelösten Bereich bis in eine Stabsstelle zu haben, so wie wir das haben. Also ich bin, unser Bereich ist separat und auf gleicher Ebene gibt es dann Kommunikation und Marketing. Aber was ich immer sage, Content drives Marketing. Inhalte treiben Marketing und nicht andersherum. Und das Problem ist, wenn Marketing die Inhalte erstellt, glauben sie häufig, Marketing treibt Inhalte und das ist eben falsch. Das hat man vor 10, 15 Jahren noch gemacht. Und wenn du dir die Inhalte, die Firmen vor 10, 15 Jahren oder teilweise auch noch heute erstellen, dann siehst du, dass das eher Marketing für Chaos Messages waren. Das funktioniert heutzutage nicht mehr. Es machen aber immer noch viele falsch. Also diese klassische nur Marketing-Message rauszuhauen, das funktioniert nicht mehr. Also musst du einen anderen Weg gehen und es geht über Inhalte, die relativ neutral sind und nicht primär im ersten Schritt dem Verkauf dienen. Kannst du das mal genau so ein bisschen an einem Beispiel erklären? Also wenn du, was bedeutet denn dann Research für euch? Also wo macht ihr dann eine eigene Studie und geht darüber dann raus? Oder kannst du das mal vielleicht... Erzähl mal, an was in der Studie hast du letzte Woche gearbeitet oder letzten Monat? Genau. Immer ein gutes Beispiel, Generative AI. Ein heißes Thema, derzeit wird in Unternehmen sehr intensiv diskutiert. Keiner hat noch so wirklich eine Ahnung, was da auf uns zurollt. Wir haben sehr schnell reagiert, weil wir gemerkt haben, da ist eine Nachfrage da. Und ein bisschen so ein White Space, wie wir das nennen. Also wir schauen auch immer nach Themen, die noch nicht von 10 anderen behandelt werden, weil wir wollen ja ein bisschen Aufmerksamkeit auch. Das ist dann die Medienarbeit damit erzeugen und auch mit was Neuem rauskommen. Klassisches Beispiel, wir haben eine Befragung, Konsumentenbefragung, dann zu dem Thema Generative AI auf dem Arbeitsplatz durchgeführt. Die Ergebnisse ausgewertet und jetzt erstellen wir einen Bericht drumherum. Das wird letzten Endes dann schon eine Studie sein, aber jetzt auch hier wichtig, was man heutzutage auch nicht mehr macht, aber immer noch viele machen. Die erstellen eine Studie dann als PDF auf die Website fertig. Also das geht natürlich überhaupt nicht mehr, funktioniert nicht mehr. Und dann wundern sich die Leute, dass die KPI so schlecht sind. Wir machen immer einen Digital First Approach, nennen wir das. Wir schauen erst mal an, wie soll eigentlich das Ergebnis auf unseren digitalen Plattformen aussehen? Weil dort werden die Sachen eben inzwischen am meisten gelesen. PDF laden sich manche noch herunter, aber Digital First, das heißt Website, Microsite auf dem Mobiltelefon. Und dann erstellen wir die Inhalte, eine Studie, die dann schon eine finale Studie ist. im PDF-Format haben, aber nicht im Mittelpunkt stehen. Und was jetzt auch noch wichtig ist, ist jetzt nur ein Beispiel. Wir nehmen eine Befragung. Befragungen sind immer schön, weil dann hast du eigene Daten. Wir machen natürlich auch Desktop-Research. Das heißt, wir suchen natürlich auch andere Erkenntnisse in dem Bereich raus. Und dann arbeiten wir auch sehr viel mit Interviews. Und zwar mit Interviews mit Externen auch und holen die Expertenmeinung aus unterschiedlicher Seite rein. Und auch noch ganz wichtig, wir haben zwar Research Team, aber wir sind natürlich auch nicht bei allen Themen die Experten. Wir arbeiten hier sehr eng mit den anderen Kollegen in unseren anderen Abteilungen zusammen, die beim Kunden genau diese Themen behandeln. Weil die wissen ganz genau, wo drückt der Schuh besonders, was sind Lösungsansätze etc. Und dieses Wissen bringen wir mit rein, aber auch zusammen mit den Externen. Weil was wir nicht wollen, ist, dass es so eine reine Deloitte-Studie wird, wo nur unsere Meinung abgebildet wird. Auch das funktioniert heutzutage nicht mehr. Man muss diese Plattformen, die man hier betreibt, öffnen, um auch Externen die Möglichkeit geben, sich zu positionieren und die Meinung rauszuholen. Und da sind wir jetzt dabei. Bevor Benjamin jetzt reingeht, ich weiß, der ist schon in den Schlagzeugheim. Ich würde gerne eine Zwischenfrage noch stellen, bevor die ein bisschen untergeht, weil du hast gesagt, Distribution. Also man macht was, als PDF hast du gesagt. Klar, das ist sozusagen der zentrale Content oder das, was dann dabei rauskommt. Dann hast du gesagt, ihr stellt es auf die Webseite und auf eine Microsite hast du gesagt. Also das heißt, ihr baut für jede Studie auch noch eine einzelne Unterseite? Für die Großen, für die Großen. Also für die Größeren und für jeden Zuhörer einfach mal auf unsere Schweizer Seite gehen. Ein gutes Beispiel ist unsere jährliche Uhrenstudie. Das ist eine klassische Microsite, wo eine separate Seite aufgebaut wird, wo wir natürlich auch viel freier sind bezüglich grafischer Elemente. Da arbeiten wir auch mit einer Agentur dann zusammen, Interaktivität und so weiter. Und es sieht einfach cooler aus. Und wir merken einfach, mit Microsites bleiben die Leute zwei bis dreimal länger auf der Seite, wie auf der Standard-Website, weil ich eben ganz andere Sachen mit einbauen kann. Also richtig, eine separate Microsite. Die verlinken wir auf jeden Fall in den Shownotes, damit man sich das auch noch angucken kann. Über Microsites diskutieren wir heute nicht. Aber es ist sozusagen auf einer hängenden Unterseite. Also es ist ja sehr aufwendig, das zu machen. Da sieht man auch, wie wichtig euch das dann ist. Und aber macht ihr denn auch dann, wie, ich meine, gut, dann hat man das jetzt auf der Seite, hat eine Microsite, aber wie tragt ihr das denn dann nach außen? Brecht ihr dann Sachen raus und streut die dann über eure Social-Media-Kanäle? Genau, richtig. Kannst du vielleicht einmal noch gerade erzählen, wie dann nachher das Seeding sozusagen weitergeht? Genau, weil das ist ja das Entscheidende immer. Was nützt es, den besten Content zu haben, aber nicht zu wissen, wie ich ihn verteile? Also erstmal wichtig, ich bin ein großer Fan von Gary Vaynerchuk's Content-Pyramide. Das heißt, wir ermöglichen großen Basis-Content. Und um diese Shelf-Life, also damit ich länger die Kampagne fahren kann, nutzen zu können, hole ich dann aus diesem zum Beispiel eine breite Studie, die dann natürlich abgebildet ist auf einer Microsite, hole ich einzelne Inhaltsstücke raus und mache neuen Inhalt daraus. Das ist so, wie wenn ihr jetzt einen Podcast aufnehmt, aber dann noch 5 Social-Media-Posts macht und hier noch ein kurzes Video etc. Also Content-Pyramide, Einzelteile brechen wir raus. Unsere Hauptkommunikationskanäle sind LinkedIn und Twitter. Das sind im Social-Media-Bereich unsere Hauptkanäle. Wir haben bei den Leuten natürlich auch Instagram usw., aber das ist eher dann für unsere HR-Abteilung, für Talent usw. Und mit TikTok machen wir auch ein bisschen was, aber 4 für unseren Content. LinkedIn, weil wir dort am besten unser Zielpublikum erreichen. Dann nimmt natürlich Marketing auch das für Direct-Mailing. Newsletter machen wir jetzt in dem Sinn nicht mehr so häufig, aber wir machen natürlich auch viele Webinars für Events usw. Und da gibt es überall die Möglichkeiten, das zu streuen. Und dann natürlich die Medienarbeit. Da kommt jetzt unser Kommunikationsteam rein. Interne Kommunikation ist wichtig, dass also unsere internen Leute, jetzt in der Schweiz sind wir bei 2.500, davon informiert sind, weil die teilen es dann auch wieder weiter. Und natürlich die Medienarbeit, also versuchen, die Inhalte zu platzieren bei Print, Online, TV und Radio. Das sind eigentlich die 4 Großen. Das gelingt uns mal gut, mal weniger gut. Das kann man immer nicht so ganz steuern, weil Medien brauchen ein bisschen Glück, dass die gerade an dem Tag oder in der Woche Interesse an dem Thema haben. Und vielleicht noch zu LinkedIn. Da arbeiten wir auch mit Live Social. Das ist so ein Tool. Es gibt ähnliche Tools, wo unser Social Media Team eigentlich zum Beispiel zu einer Studie, zu einer neuen Kampagne Posts vorbereitet. Und jeder Mitarbeiter hat Zugriff auf diese Plattform, die verknüpft ist mit LinkedIn und kann dadurch relativ schnell eigene Posts kreieren. Weil das Hauptproblem, ihr wisst, einen LinkedIn Post zu machen, gut, das dauert natürlich. Das mache ich nicht in zwei Minuten. Aber wir helfen da unseren Mitarbeitern bis auf dieses Tool. Du gibst ein Future of Health, Zukunft der Arbeit ist ein spannendes Thema und da siehst du fünf Posts dazu. Nicht nur eigene Sachen, auch mal ein Artikel und so weiter. Oh ja, das würde ich gern teilen über mein LinkedIn Netzwerk. Und da kannst du auch einstellen, an welchen Tagen und so weiter. Du kannst eigentlich, mache ich immer Montag, komplette Pipeline eine Woche schon mal vorausplanen, um wie viel Uhr, an welchem Tag, welche Posts mit reingehen. Und es geht dadurch natürlich schneller, weil ich nur noch kleine Anpassungen machen muss beim Text. Also es gibt unterschiedliche Möglichkeiten, wie wir das treiben. Und wie viele seid ihr in eurem Fortleadership Content Team, Schrägstrich Research Team? Du hast ja gesagt, wie eine Stabsstelle organisiert. Kannst du da mal sagen, wie viele seid ihr? Fünf. Fünf Personen. Deutschen Kollegen haben natürlich mehr, weil sie größer sind und mehr Themen bearbeiten. Deutschen Kollegen haben, glaube ich, so um die 20, zwischen 20 und 25 Leute. Genau. Und ihr seid eben, wie du, ich finde das sehr spannend, was du gesagt hast, dass ihr wirklich unabhängig eure Forschung macht, sozusagen. Eure relevanten Themen macht, die nicht zu marketinglastig sind. Also nicht, wo sozusagen keine Produktkommunikation stattfindet, keine werbliche Kommunikation, sondern wirklich fachliche Inhalte, die ihr dann übergebt ans Marketing, an PR, an die verschiedenen sozusagen Abteilungen, die für die Distribution zuständig sind und auch für die Reichweite dann. Korrekt. Und das ist ein ganz, ganz wichtiger Erfolgsfaktor. Die Leute lesen, also in Unternehmen. Unser Zielpublikum sind ja die Unternehmen C-Level, mittleres Management, die sind an diesem Marketing-Blabla nicht mehr interessiert. Vergiss es. Also das kommt einfach nicht an. Aber an Content, und da gibt es ja viele Untersuchungen dazu, an wirklich guten Inhalten sind die sehr interessiert. Und die sehen es dann auch an, wenn Sachen gelesen wird, Feedback und so weiter. Oder wenn ich für Interviews anfrage, ich bekomme fast immer einen Termin, weil ich einfach jemand als Experte anfrage zu einem Thema. Also er hat jetzt nicht Angst, ich will ihm eine Dienstleistung verkaufen. Und das ist ganz entscheidend. Das Gleiche beim Podcast. Ihr macht es ja genauso. Ich auch mit meinem Podcast, ich interviewe niemand von den Leuten, sondern ich interviewe Externe. Und dadurch wird es natürlich für viele noch interessanter. Das machst du ja schon lange, euren Future Talk Podcast. Darüber haben wir uns ja auch kennengelernt, schon vor vielen Jahren. Richtig, vor vielen Jahren, genau. Du hast ja zur ähnlichen Zeit natürlich unsere Podcasts gelauncht, richtig. Ja, finde ich sehr spannend. Da habe ich ja auch damals schon sehr gefreut und da höre ich immer wieder regelmäßig rein, weil wirklich konsequent Externe auch eben wirklich aus dem C-Level-Bereich auch durchaus eben selbst auch reinholt und interviewt. Ja, genau. Und wir bieten eigentlich, und das machen wir auch vor allen Dingen auf den Microsites, die vorhin angesprochen wurden, wir öffnen, wir haben vor Jahren schon diese Plattform geöffnet für Externe. Das machen auch viele Unternehmen, nicht? Da werden nur die eigenen Sachen publiziert. Wir holen auch Externe rein, zum Beispiel mit Interviewserien, auch schriftlich mal kurze Interviews und das hilft natürlich sehr bei der Kundenbindung. Also das ist wahrscheinlich einer der wichtigsten Sachen, warum wir auch Content kreieren, Kundenbindung entweder aufzubauen oder zu verfestigen, weil wir bieten Externen eine Plattform, sich selbst zu präsentieren als Experte und das mag ja jeder. Also ich habe jetzt schon gehört, aus Studien, Interviewserien, sozusagen Artikel, Fachartikel drumherum und das wiederum brecht dir ja sehr stark auch auf verschiedene Branchen runter. Ihr habt ja einen sehr starken auch Branchenansatz, das finde ich auch nochmal sehr spannend. Kannst du denn nochmal sagen, wer schreibt, also ihr schreibt dann auch aus dem Research-Team, schreibt dann auch die Artikel zu den einzelnen Industrien? Genau, richtig, richtig. Natürlich haben wir so innerhalb vom Team ein bisschen Expertise. Also wir haben jetzt einen, der halt früher auch bei einer Bank gearbeitet hat, der macht natürlich die Bankgeschichten, dann natürlich, sagen wir mal Public Sector, also öffentliche Verwaltung haben wir jemand aus dem Bereich Konsumgüterindustrie ist wichtig. Genau, also die schreiben das dann, aber immer in enger Abstimmung mit unseren, sage ich mal, Experten, die nahe beim Kunden sind, mit den Beratern und so weiter, damit wir da eben sicher sind, dass wir auch die richtigen Inhalte bringen. Aber so dann auch das Schreiben und vom Stil her, das ist ja auch noch sehr wichtig, das machen wir alles. Und was auch noch wichtig ist, darum sage ich mal, was wir machen, wir machen Forschung, wir machen aber keine akademische Forschung, würde ich mal sagen, sondern eher die angewandtsorientierte Forschung. Wir bringen Lösungsansätze und wir schreiben keine akademischen Papiere, weil die liest keiner, mal ganz ehrlich. Also letztendlich die Akademiker kritisieren, aber innerhalb des akademischen Zirkels ist es durchaus sinnvoll, diese academic papers, aber die liest ja keiner. Ich glaube, das war die Weltbank, wo man selbst veröffentlicht hat, durchschnittliche Downloads von ihren Studien, die oft 100, 150 Seiten sind. Das waren irgendwie im Schnitt nicht mehr als 20. Also das ist natürlich völlig lächerlich, muss man sich mal vorstellen. Und auch die Sprache ist daher sehr, sehr wichtig. Da kommt unser Job schon sehr nah ans Journalistische rein. Wir müssen so schreiben, dass es jeder versteht einfach. Und dass man es auch schnell lesen kann. Also unsere Studien sind auch wesentlich kürzer in den letzten Jahren geworden, weil die Leute, man kann es jetzt beklagen, aber es ist eben so, die haben nicht mehr die Zeit, vor allen Dingen in den Unternehmen. Es muss schnell gehen, da muss eine knackige Summary sein, da müssen die Visuals drin sein. Also wir haben viel mehr, arbeiten jetzt auch mit Bildern, mit Grafiken, mit Abbildungen als vor zehn Jahren. Und dadurch bleiben die Leute auch länger dran und lesen die Sachen auch. Jetzt muss ich zwei Sachen einmal nochmal nachfragen, weil wir da wieder so drüber gehüpft sind. Also einmal würde ich einfach eine ganz blöde Frage stellen. Und zwar, warum macht ihr Branchen? Also warum unterteilt ihr das in diese Branchen? Was ist eure Erfahrung, dass das sinnvoll ist, das so thematisch aufzuteilen? Das hat damit zu tun, weil wir bei Deloitte, genauso wie auch unsere Konkurrenz, eben eine Matrix-Organisation haben. Wir haben nach Industrien die Experten und nach Themen. Und daher, es gibt Themen, die sind industrieübergreifend wichtig, Zukunft der Arbeit, da kann ich mit jedem HR-Verantwortlichen, egal von welchem, sprechen. Aber es gibt eben auch industriespezifische Themen, zum Beispiel digitale Währung oder kontaktloses Zahlen. Das ist dann primär ein Thema für die Banken und vielleicht noch für die Konsumgüterindustrie. Also es hängt alles immer vom Zielpublikum ab. Also bei uns geht es ja immer erstmal, wer ist unser Zielkunde? Wir schreiben ja jetzt nicht einfach so los, ein spannendes Thema, sondern wir überlegen uns der erste Schritt immer, für wen schreiben wir das eigentlich? Wen adressieren wir? Und da bist du halt bei vielen Themen, hast du entweder Industriethemen oder die übergreifenden Themen. Und daher machen wir Industriestudien, aber auch die anderen Studien. Genau, das hätte ich eigentlich auch erwartet, dass ihr da auch strukturell vom Unternehmen her so aufgebaut seid. Und auf der anderen Seite geht es natürlich auch darum, die Leute abzuholen. Jetzt einfach ganz blöd gesagt, wenn ich auf der Homepage bin und ich möchte Informationen für meine Branche finden, ist das ja auch schon wieder eine Einordnung, wenn ich mich da auch wieder finde, dass ihr da halt auch die Experten für seid. Und das Zweite war, was mir so ein bisschen aufgefallen ist in dem, was du uns erzählt hast, ist, dass du auch schon Lösungen angesprochen hast. Also der Content ist nicht werblich in dem Sinne. Aber man möchte ja schon auch transportieren, dass man sehr viel Ahnung davon hat und natürlich auch Lösungsansätze bringt. Im Gegensatz zu den ganzen wissenschaftlichen Studien, die das ja wirklich sehr global mal betrachten und vielleicht auch einen dann, bevor man eine Lösung findet, zu Tode gelangweilt hat. Es geht ja auch darum, dann auch ein Ergebnis zu produzieren. Also von daher würde mich schon interessieren, ob ihr die Themen auch auf eure Leistungen ein Stück weit abstimmt, dass ihr dann auch sagt, vielleicht auch in Form von einer Case Study oder dass man sagt, also wie bringt man denn dann in den Content auch das Angebot rein, was man hat? Ist es wirklich so unwerblich oder wie würdest du sagen, wie ist da deine Erfahrung oder wie geht ihr das an, dass man dann aber im Endeffekt aber dann auch signalisiert, dass ihr ja auch diejenigen seid, die man nachher fragen kann, wenn man dieses Problem zum Beispiel hat mit der Kryptowährung oder wenn man das implementieren will oder wenn ich als Bank wissen will, was für ein Risiko besteht denn das für meine Organisation, wenn es jetzt Kryptowährungen gibt? Ja, jetzt mal als Beispiel. Wie kann man sich denn da als Beratungsunternehmen dann trotzdem positionieren? Eigentlich genauso, wie es du es beschrieben hast. Und ich nehme mal den aktuellen Beispiel, an dem ich arbeite. Es gibt dann eben im zweiten Teil von der Studie gibt es in dem Teil Risikovermeidung, also wo ich dann zum Beispiel die Risiken, wir haben analysiert, was sind die Risiken, was müsste ich tun, um die Risiken zu vermeiden oder was gibt es sonst noch für Empfehlungen, was Unternehmen tun müssen, um dies oder jenes zu tun. Aber wir schreiben das nicht in dem Stil, wir wissen es und so weiter, weil nicht so direkt. Aber unterschwellig, wenn du natürlich jetzt einmal noch zwei, drei Seiten über diese Lösungsansätze schreibst, ist ja unterschwellig eine Aufforderung für jemand A, die kennen sich aus und darum geht es ja zu signalisieren. Wir sind in Thordly, da sind wir wieder bei der ersten Frage. Die kennen sich aus, oh ja, die Lösungsansätze macht Sinn, könnte für mich auch interessant sein und über den zweiten, dritten, nächsten Schritt kontaktieren sie vielleicht uns. Ja, sehr, sehr spannend, dass du jetzt auch sagst, es kommt sozusagen automatisch über die… Ja, das muss das Ziel sein und nicht dieses Push. Ja, und jetzt lassen wir mal über die KPIs sprechen, die wir schon am Anfang schon so, haben kurz fallen lassen, oder du. Wie misst du denn dann den Erfolg? Also, was sind denn dann wirklich, ja, die Zahlen? Von Thordly und Content. Genau, richtig. Wir haben eigentlich vier Bereiche, wir haben digitale KPIs, wir haben klassische Marketing KPIs, wir haben Medien KPIs und wir haben Kunden KPIs. Am leichtesten sind natürlich die digitalen KPIs, das wisst ihr, weil die kann man halt schön messen. Ja, und das sind die klassischen, also brauche ich jetzt, glaube ich, nicht so ganz im Detail, sind halt die Website, Visits, Scroll Rate, Bounce Rate, Time on Page, Leads und so weiter. Dann haben wir Organic Social Media und da teilen wir Organic Social Media und Paid, also bezahlte Kampagnen. Wir machen auf LinkedIn auch bezahlte Kampagnen, das funktioniert ja da recht gut. Und da geht es dann natürlich auch um Impressions, Klicks, Likes, Shares, Total Engagement. Also, haben wir auch einige Tools, unser Digital-Team natürlich Tools, um das zu messen entsprechend. Ich sehe dann immer nur die Auswertung, also ich bin jetzt da bei der Analyse nicht so direkt involviert. Und dann haben wir bei den Marketing KPIs, das sind alle kundenbezogenen Zusammenhänge, also das heißt, wie viele Touchpoints, also Berührungspunkte man eigentlich durch eine Studie mit Kunden hat. Das kann schon bei der Erstellung der Kunden, beim Inhalt sein, also bei der Erstellung Inhalt komme ich, weil gleich noch bei den Kunden KPIs dazu. Das sehen wir oft bei Marketing auch viel mit Events oder irgendwelche Mittagessen, wo man dann mit Kunden zusammensitzt und dann natürlich das vielleicht auch als Aufhänger nimmt, vielleicht auch für ein Event. Also, viele Events machen wir, basieren auf Ergebnisse von der Studie zum Beispiel. Also, das sind dann auch KPIs. Dann Marketing haben wir noch so diese Qualified Leads, wie wir es ja nennen. Das heißt, gibt es dann wirklich irgendwelche Engagements über welche Kanäle auch immer und kommt dann im zweiten, dritten Schritt vielleicht doch mal ein Gespräch über ein Projekt zustande. Die sind aber am schwierigsten zu messen, weil wir das natürlich nicht immer mitbekommen. Also, wir können nicht alle Mitarbeiter kontrollieren. Der hat jetzt eine Studie erwähnt bei einem Kunden und er fand es so interessant, dass er ein zweites Meeting hatte über dieses Thema und zwei Schritte später ist ein Auftrag herausgekommen. Das ist schwierig zu messen. Dann haben wir die Medien KPIs, die sind auch relativ leicht zu messen. Also, die Anzahl der Clippings in Zeitungen, Online, TV, Radio. In dem Zusammenhang dann so genannten Organic Reach. Also, das heißt, die Leser, Hörer, Zuschauer, also die dahinterstecken. Ist ja natürlich ein Unterschied, ob ich jetzt in einem Artikel mit einer Studie bin, in einer Lokalzeitung oder in der FAZ. Das ist ein großer Unterschied. Oder in den Abendnachrichten oder eher bei einem lokalen Radiosender. Share of Voice messen wir. Also, das messen wir bei Medien, weil da geht es auch. Share of Voice. Social Media auch ein bisschen. Also, wir vergleichen uns mit unseren direkten Konkurrenten und sehen, wie viele Medien Echo Tee hatten. Und da teilen die natürlich positiv, negativ. Das ist natürlich ganz wichtig. Und auch digital schauen wir natürlich, was die anderen auf LinkedIn und so weiter machen. Und dann haben wir noch die Kunden KPIs. Die sind jetzt für mich, für mein Team am wichtigsten, weil Ziel ist natürlich, von diesem Thought Leadership möglichst viel Kunden in der Aktivität zu erzeugen. Das sind persönliche Kundengespräche. Und da kommen wir in die Interviews herein. Darum führe ich sehr gerne Interviews im Rahmen von Studien, weil wenn ich da mit fünf Head of HR Leuten von Unternehmen spreche, ist das natürlich schon mal ein Checkpoint. Weil ich meine, das ist FaceTime mit jemanden oder halt jetzt dann über Zoom oder so. Das zählt mit rein. Auch Follow-up. Wir nutzen natürlich die Studien dann auch für weitere Diskussionen bei Kunden. Dann gibt es noch die externen Experten oder auch Politik. Politik ist auch wichtig bei manchen Themen. Also, ich bin häufig bei, ist ja bei uns die Bundeshauptstadt, wo ich dann auch mit Leuten aus der Politik zu einzelnen Themen rede oder auch mit der Nationalbank. Genau. Und dann gibt es noch die interne Kommunikation und Interaktion. Das ist auch für unser Team wieder wichtig. Das heißt, wie gelingt es mir, dass ich halt mal beim Thema auch mal mit unserem CEO darüber spreche, weil ich dann mit ihm vielleicht gemeinsam meinen Medientermin wahrnehme und so weiter. Also, das ist dann noch das, was intern auch möglich ist. Das ist vielleicht die größte Herausforderung in einem großen Unternehmen. Mir ist schon häufig aufgefallen, Externe kennen unsere Studien oft besser als die internen. Und da ist es interne immer wichtig, die Leute abzuholen. Hey, hier haben wir was Gutes. Und das reicht halt nicht nur aufs Intranet zu stellen oder mal ein Newsletter, den keiner mehr liest, sondern da muss ich oft die Leute ein bisschen persönlich abholen. Ich glaube, wir haben noch nie mit jemanden fünf Minuten hier über seine KPIs oder zehn Minuten über die KPIs erzählen lassen. Das ist eindrucksvoll. Das finde ich sehr spannend und sehr interessant, wie ihr das aufgefächert habt. Das ist bestimmt für den einen oder anderen auch vielleicht eine Inspiration, das auch in die Richtung zu entwickeln. Ja, und gleichzeitig Und gleichzeitig kam auch, finde ich, sehr schön heraus, wie schwierig es wird, wenn man jetzt sagt, wir haben eine super Studie und einer unserer Berater hat das in dem Mittagessen als Gesprächsanlass genutzt, worauf dann der Kunde das wieder in sein nächstes Teammeeting reingetragen hat und vielleicht dann der nächste Entscheider oder die Entscheiderin sich das nochmal runtergeladen hat und dann entsteht daraus irgendwie ein Projekt ein halbes Jahr später. Das kannst du nicht tracken. Das kannst du nicht mehr verfolgen. Das ist schwierig. Es ist nicht alles messbar, wenn man in Leadership-Content investiert, gerade auf dieser Qualified-Leads-Ebene, wie du da jetzt auch gesagt hast. Richtig. Also früher konnten wir noch, früher hatten wir noch Printouts, also wirklich Studien ausgedruckt in größerem Stil und dann konntest du immer hier, 500 hast du bestellt und nach drei Monaten sind noch 100 da, dann kannst du so ein bisschen, okay, also da hat jeder, aber du weißt nicht, wo die 400 hingekommen sind, außer du machst natürlich ein Mailing, dann kannst du das natürlich schon tracken. Aber wenn die natürlich, die liegen dann bei uns immer rum und wer es halt was braucht, oh spannend, nehme ich mit, das kannst du nicht tracken. Und trotzdem investiert ihr ja ganz klar und mit einem eigenen Team in diesen Ansatz. Also braucht man auch ein Stück weit, muss man auch überzeugt sein von diesem Ansatz oder woher beruht das? Du hast, ihr habt ein Future Talk, ich glaube, ihr habt auch schon weit über 100, 150 Folgen oder noch viel mehr. Genau, richtig. Und das ist ja schon eine sehr, wirklich ein sehr konsistentes und konstantes Format, das du selbst ja auch mitbetreust. Also Zweifel scheinen da ja noch nicht aufgekommen zu sein. Wie kommt das? Ne, weil da helfen halt doch die KPIs, mit denen man dann manche Sachen messen kann. Also Medien ist noch am leichtesten und da haben wir halt gemerkt, seit wir Content, eigenen Content produzieren, wir haben ja vor elf, zwölf Jahren damit begonnen, ist unsere Media Attention stark hochgegangen. Und wir sehen ja, über was dann über die Leute geschrieben wird und das ist sehr stark von den Studien getrieben. Also da Medien ist ganz klar zu sehen. Und klar, das dauert ein bisschen. Dann machen wir natürlich Brand, also unsere Markenabteilung, die macht natürlich dann auch entsprechende Analysen, wie wird die Marke, die Leute innerhalb der Schweiz wahrgenommen oder halt bei anderen Unternehmen innerhalb von Deutschland und so weiter. Und da sieht man das auch. Und dann haben wir sogenannte Client Feedback Diskussionen, das heißt Kundengespräche nach Projekten. Und da hören wir dann auch ab und zu, ich habe letztendlich das und so gelesen von euch und dadurch hört man es raus und daher ist der Case für uns relativ klar und wurde auch nie großartig bisher angezweifelt. Und die Tatsache, dass ich das ja auf ein Fünfmann aufbauen konnte, hatte ich ja nicht von Anfang an. Zeigt ja auch, dass dies der richtige Weg ist und man sieht es auch in anderen Ländern Gesellschaften, die eine ähnliche Entwicklung hinter sich haben. Also wenn du das so erzählst, dann ist das für mich total logisch. Also ich meine, wir arbeiten ja auch so, ja, also vielleicht auch ein bisschen intuitiv, aber ihr macht das ja schon sehr strukturiert. Eine Frage hätte ich noch. Du hast gesagt, dass du dich gerade intensiv mit dem Thema Generative AI auseinandersetzt und grundsätzlich ist es wahrscheinlich auch ein Thema, was ihr viel auch bearbeitet, jetzt auch als Research-Thema. Meinst du, dass AI also jetzt rein von der Produktion her mal irgendwann auch für Solidarship-Content relevant wird? Oder ist das einfach was, wo man AI nicht für benutzen kann? Also ich muss dich jetzt schocken. Es ist schon relevant. Ja? Es ist jetzt schon relevant. Erzähl. Also ich sehe Generative AI, also JetGBT oder all die anderen Tools, ein bisschen als Co-Pilot und ist, glaube ich, eine ganz gute Beschreibung als Assistent-Co-Pilot, der einfach hilft bei mehreren Themen. Ideenentwicklung, würde ich mal sagen, also es geht schneller, um neue Ideen zu entwickeln. Also oft, wenn man ein bisschen so einen Block hat, wenn man ein neues Thema und da hilft es mir sehr. Dann beim Schreiben, also nicht, dass jetzt JetGBT schon komplett eine Studie schreibt, weil es so zu 50 Prozent auch schon geht, aber, sag ich mal, dann bei der Formulierung einfach. Und wir schreiben ja auch viel auf Englisch. Und wenn du dann nicht in deinen eigenen Muttersprache, aber dann mit JetGBT hilft es schon, den Text zu verbessern, relativ schnell, Formulierung und Unterstützung bei einfachen repetitiven Aufgaben. Also ich würde sagen, aktuell spare ich schon mindestens fünf Stunden die Woche durch den Einsatz von dem Tool und es wird noch viel weiter zunehmen. Jetzt bin ich nur im textbasierten Bereich. Noch dramatischer ist es ja bei Visuals. Und also ich sehe es, wir haben ja auch ein Digital-Team, das Kunden berät, was da alles möglich ist. Und da ist der Einsparfaktor, also um was du schneller bist, zum Beispiel, um irgendwelche Bilder zu erstellen, massiv. Also da sprechen wir davon, wo vorher jemand zwei Monate dran saß, machst du jetzt in zwei Stunden und ist kein Witz. Videos. Wir haben ein eigenes Videoproduktionsteam, aber durch den Einsatz von AI, du sparst massiv. Und Video ist ja auch eine Art von Content, den du erstellen kannst. Was aber wichtig ist, weil viele immer Angst haben, ersetzt mich das und so weiter. Also die Message ist ganz klar. Wer einen Job hat in diesen Bereichen, muss sich möglichst schnell mit dem Thema auseinandersetzen. Keiner wird durch Chat-GPT ersetzt, aber er wird definitiv ersetzt durch eine Person, die Chat-GPT anwenden kann. Definitiv. Also das kann ich so behaupten. Was aber auch wichtig ist, und daher habe ich keine Sorge jetzt für, sagen wir mal, Researcher etc. langfristig, weil auch das Tool, gibt es ja die alte Regel, Rubbish in, Rubbish out. Und das gilt natürlich auch für Chat-GPT. Also wenn ich dann nicht das richtig mache, bekomme ich auch nicht die richtigen Antworten. Und da ist die Kunst, Faktencheck zu betreiben. Und wenn ich jetzt so unsere Rolle als Research, unsere tägliche Rolle ansehe, ich glaube, unsere Hauptrolle ist wirklich, Faktencheck zu machen. Das heißt, die einzelnen Quellen zusammentragen und zu schauen, macht das Sinn, stimmt das überhaupt, ist das die richtige Quelle? Und die Herausforderung steigt natürlich jetzt massiv mit den AI-Tools. Und daher glaube ich, dass Leute wie wir und auch wir zunehmend einen noch höheren Wert haben werden in Unternehmen, weil wir das gelernt haben, jahrelang genau zu unterscheiden, das ist richtig, das ist falsch. Und da kommt jetzt ein bisschen meine Sorge, also ich bin euphorisch bei dem Thema, aber auch die Sorge rein, wie es dann der nächsten Generation mal ergehen wird, die vielleicht mit den Tools aufwächst und es nicht mehr lernt, wirklich dieses Faktenchecken oder das Unterscheiden, was ist gute Qualität, was ist schlechte Qualität? Weil um den guten Text beurteilen zu können, musst du idealerweise auch selber schon guten Text schreiben können, behaupte ich mal. Vor allen Dingen, wenn dann Inhalte kommen und das ist ja noch ein bisschen das Manko bei den aktuellen Tools, dass ich eben nicht sehe, woher die Inhalte, die Informationen kommen. Also so gesehen, generell bin ich sehr optimistisch eingestellt, aber es gibt schon viele Risiken, die man beachten muss, aber es wird den ganzen Bereich und am meisten natürlich Marketing, Marketing-Kommunikation massiv verändern. Sehr, sehr spannend. Hast du auch, finde ich, sehr schön auf den Punkt gebracht und ich würde sagen, Fabian, es ist genau das, wie wir es auch sehen und es ist der Co-Pilot, finde ich, ein sehr schönes Bild, weil es super hilfreich sein kann, aber den eigenen Verstand ausschalten, das wird halt zu keinem so guten Ergebnis führen. Das weiß eigentlich auch jeder. Und trotzdem ist das natürlich die Gefahr so da. Ah, ist schön, dass da wird was automatisch generiert und ich muss nichts mehr tun. Nee, so ist es nicht. Vor allen Dingen in der größeren Firma, dann habe ich ja das Reputationsrisiko sofort. Ich meine, das ist ja und drum sind die großen Firmen jetzt natürlich schon aktuell sehr dahinter, das erst mal ein bisschen zu limitieren und die Leute auch zu klären und weil die wissen genau, was da schieflaufen kann. Ja, es ist kein Prozess, der effizienter machen, aber ich glaube, dieses, das, was wir unter Solidarship verstehen, das muss ja irgendwoher kommen, aus irgendwas Erwachsenem. Jemand muss die Idee haben, dass in diesen Daten was Spannendes drin steckt und das kann die KI nicht für dich machen, sondern das musst du ja selber die Erfahrung haben und dann in der Arbeit unterstützt es einen, finde ich auch sehr interessant, was da jetzt gerade passiert, auch für SEO und ja, deswegen. Ja, also SEO ist ein Riesenthema bei uns natürlich auch und ihr habt es ja in etlichen Episoden schon gesagt, okay, jetzt sind wir ja dauernd in SEO und Google investiert, ja, okay, aber what's next? Also ich habe viele in meinem privaten Umfeld, die kaum mehr Google nutzen. Ich weiß nicht, wie das bei euch ist und das heißt, wie werden wir als die Leute mit uns im Inhalt eigentlich jetzt dann bei JetGBT gefunden, ist ein Riesenthema. Ja, sehr, sehr spannendes Thema, aber das würde ich sagen, das wäre vielleicht nur was, was wir noch mal in einer neuen Folge besprechen, Michael. Heute haben wir wirklich über euren Solidarship-Content-Ansatz gesprochen, mega interessant. Vielen Dank, dass du dir die Zeit genommen hast. Sehr gerne und vielen Dank. Danke dir. Bis dann. Ciao. Untertitel im Auftrag des ZDF für funk, 2017\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "Sg-JwTcFWLof"
      },
      "execution_count": 108,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prompt_dev = f\"\"\"\n",
        "Du bist mein persönlicher Assistent, der mir bei der Tages- und Wochenplanung hilft. Ich übermittle nun meine Notizen und Aufzeichnungen. Es ist in chronologisch umgekehrter Reihenfolge aufgebaut, die neuesten Einträge stehen zu Beginn. Die Tage sind in Markdown-Syntax  mit \"# \" gekennzeichnet, die Themenabschnitte mit \"## \". Markierungen für Aufgaben oder Tags können an beliebigen Stellen in den Notizen auftauchen: Offene Aufgaben sind immer mit \"[ ]\" markiert, erledigte Aufgaben mit \"[x]\".\n",
        "Bitte beantworte alle Folgefragen nur und ausschließlich auf Basis der übermittelten Aufzeichnungen.\n",
        "Gebe alle Texte 1:1 wieder und erfinde nichts neues.\n",
        "Erstelle eine Liste aller offenen Aufgaben als kurze bullet-point Liste.\n",
        "\n",
        "Hier die Notizen:\n",
        "\"\"\"\n"
      ],
      "metadata": {
        "id": "Q20WZ6QqVeXR"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prompt_dev = f\"\"\"\n",
        "You are in the role of an assistant for an editor.\n",
        "Shorten the following text. Paraphrase the text, do not invent anything new and keep the original tone and style.\n",
        "The output format is in Markdown syntax.\n",
        "Write in German language.\n",
        "\n",
        "\"\"\"\n",
        "# Create 2-3 subheadings."
      ],
      "metadata": {
        "id": "6K9QzirAEvRM"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Wie wirkt sich Chunk-Größe auf Zusammenfassungsgröße in % aus?\n",
        "\n",
        " Chunkgröße | 500 | 750 | 1000 | 1500 | 2000\n",
        "-------- | -------- | -------- | -------- | -------- | --------\n",
        "Klima   | 85%   | 78% | 76% | x | 39%\n",
        "A12 Model DIff   | 88%   | 85% | 87% | x |  38%\n",
        "- mit GPT4:  | 67%   | 63% | 55% | 50% |  35%\n",
        "Deloitte Podcast   | 50%   | 28%   | 21%  | x |  16%\n",
        "B2B Content Podcast | 63%   | 43%  | 43%  | 19% |  17%\n",
        "- mit GPT4: | 39%   | 31%  | 28%  | 23% |  10%\n",
        "Adrenalin   | 89%   | 77%   | 77%  | x |  21%\n",
        "Inhalt   | Inhalt   | Inhalt   | Inhalt  | Inhalt |  Inhalt\n",
        "\n",
        "# Rules\n",
        "\n",
        "GPT4 ist immer ca. 25% kürzer\n",
        "\n",
        "Default: 1000\n",
        "\n",
        "Sehr dichte Information (Fachtext): 2000\n",
        "\n",
        "Gesprochen, Podcast: 500\n",
        "\n",
        "# Rekursiver Test\n",
        "\n",
        " Step | Input words | Chunk-Size | 1 | 2 | 3 | 4 | Output words\n",
        "-------- | -------- | -------- | -------- | -------- | -------- | -------- | --------  \n",
        "A12 Model DIff | 7900 |1000   | 88% | 49% | 76% | - | 2500\n",
        "A12 Model DIff | 7900 |1500   | 58% | 23% | 70% | - |753\n",
        "Deloitte Podcast | 6600 |1000   | 24% | 81% | 99% | 100% | 1300\n",
        "Deloitte Podcast | 6600 |500   | 51% | 96% | 77% | 98% | 2497"
      ],
      "metadata": {
        "id": "SCj-MeOwE13i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "step1 = execute_project('step1', 'gpt-3.5-turbo', prompt_dev, {}, 'Manual prompt', '', '1000', '', 0, True, folders, input_dev, comment)\n",
        "\n",
        "step2 = execute_project('step2', 'gpt-3.5-turbo', prompt_dev, {}, 'Manual prompt', '', '1000', '', 0, True, folders, step1[2], comment)\n",
        "\n",
        "step3 = execute_project('step3', 'gpt-3.5-turbo', prompt_dev, {}, 'Manual prompt', '', '1000', '', 0, True, folders, step2[2], comment)\n",
        "\n",
        "step4 = execute_project('step4', 'gpt-3.5-turbo', prompt_dev, {}, 'Manual prompt', '', '1000', '', 0, True, folders, step3[2], comment)"
      ],
      "metadata": {
        "id": "_E5qosTJWZ9P",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7a0a085b-f16c-4998-946b-bae645ba0434"
      },
      "execution_count": 111,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: gpt-3.5-turbo\n",
            "Started at: 22:39:02\n",
            "\n",
            "Processing step 1 of 7\n",
            " You are in the role of an assistant for an editor. Shorten the following text. Paraphrase the text, do not invent\n",
            "anything new and keep the original tone and style.  The output format is in Markdown syntax. Write in German language.\n",
            "``Herzlich willkommen zum Content-Performance-Podcast mit Fabian Deckert und Benjamin Odani, der Online-Marketing-\n",
            "Podcast für Fortgeschrittene. Hallo Fabian. Hallo Benjamin. Und hallo Michael. Ja, hallo zusammen. Heute sprechen wir\n",
            "darüber, wie Deloitte Thought Leadership Content entwickelt und dafür haben wir uns einen super Gast geholt in unserem\n",
            "Podcast, und zwar den Michael Gramp. Du bist Chefökonom bei Deloitte in der Schweiz, Leiter des Research Teams und eben\n",
            "auch verantwortlich für diese Thought Leadership Publikation. Vielen Dank, dass du dir die Ze\n",
            "\n",
            "{'token_usage': {'prompt_tokens': 1644, 'completion_tokens': 228, 'total_tokens': 1872}, 'model_name': 'gpt-3.5-turbo', 'wordcount': {'input': 991, 'output': 122}}\n",
            "\n",
            "Processing step 2 of 7\n",
            " You are in the role of an assistant for an editor. Shorten the following text. Paraphrase the text, do not invent\n",
            "anything new and keep the original tone and style.  The output format is in Markdown syntax. Write in German language.\n",
            "``Also wir sind ganz klar Content-Driven, das heißt, Inhalt treibt alles andere bei unsUnd die Erstellung von Inhalt\n",
            "Thought Leadership Inhalt steht ganz am Anfang. Den produzieren wir und damit füttern wir Kommunikation, Marketing,\n",
            "Kundenbeziehungen etc. Und deswegen sollte auch ein Research Team, das diese Sachen arbeitet, nicht im Marketing sitzen.\n",
            "Jetzt kann man ein bisschen drüber streiten, rein von der Organisation, wenn das Team natürlich relativ unabhängig\n",
            "arbeiten kann und die Experten hat, kann das natürlich organisatorisch schon im Marketing sitze\n",
            "\n",
            "{'token_usage': {'prompt_tokens': 1611, 'completion_tokens': 388, 'total_tokens': 1999}, 'model_name': 'gpt-3.5-turbo', 'wordcount': {'input': 998, 'output': 218}}\n",
            "\n",
            "Processing step 3 of 7\n",
            " You are in the role of an assistant for an editor. Shorten the following text. Paraphrase the text, do not invent\n",
            "anything new and keep the original tone and style.  The output format is in Markdown syntax. Write in German language.\n",
            "``Also es ist ja sehr aufwendig, das zu machenDa sieht man auch, wie wichtig euch das dann ist. Und aber macht ihr denn\n",
            "auch dann, wie, ich meine, gut, dann hat man das jetzt auf der Seite, hat eine Microsite, aber wie tragt ihr das denn\n",
            "dann nach außen? Brecht ihr dann Sachen raus und streut die dann über eure Social-Media-Kanäle? Genau, richtig. Kannst\n",
            "du vielleicht einmal noch gerade erzählen, wie dann nachher das Seeding sozusagen weitergeht? Genau, weil das ist ja das\n",
            "Entscheidende immer. Was nützt es, den besten Content zu haben, aber nicht zu wissen,\n",
            "\n",
            "{'token_usage': {'prompt_tokens': 1656, 'completion_tokens': 645, 'total_tokens': 2301}, 'model_name': 'gpt-3.5-turbo', 'wordcount': {'input': 1000, 'output': 392}}\n",
            "\n",
            "Processing step 4 of 7\n",
            " You are in the role of an assistant for an editor. Shorten the following text. Paraphrase the text, do not invent\n",
            "anything new and keep the original tone and style.  The output format is in Markdown syntax. Write in German language.\n",
            "``Also das ist wahrscheinlich einer der wichtigsten Sachen, warum wir auch Content kreieren, Kundenbindung entweder\n",
            "aufzubauen oder zu verfestigen, weil wir bieten Externen eine Plattform, sich selbst zu präsentieren als Experte und das\n",
            "mag ja jederAlso ich habe jetzt schon gehört, aus Studien, Interviewserien, sozusagen Artikel, Fachartikel drumherum und\n",
            "das wiederum brecht dir ja sehr stark auch auf verschiedene Branchen runter. Ihr habt ja einen sehr starken auch\n",
            "Branchenansatz, das finde ich auch nochmal sehr spannend. Kannst du denn nochmal sagen, wer s\n",
            "\n",
            "{'token_usage': {'prompt_tokens': 1594, 'completion_tokens': 403, 'total_tokens': 1997}, 'model_name': 'gpt-3.5-turbo', 'wordcount': {'input': 983, 'output': 236}}\n",
            "\n",
            "Processing step 5 of 7\n",
            " You are in the role of an assistant for an editor. Shorten the following text. Paraphrase the text, do not invent\n",
            "anything new and keep the original tone and style.  The output format is in Markdown syntax. Write in German language.\n",
            "``Es gibt dann eben im zweiten Teil von der Studie gibt es in dem Teil Risikovermeidung, also wo ich dann zum Beispiel\n",
            "die Risiken, wir haben analysiert, was sind die Risiken, was müsste ich tun, um die Risiken zu vermeiden oder was gibt\n",
            "es sonst noch für Empfehlungen, was Unternehmen tun müssen, um dies oder jenes zu tunAber wir schreiben das nicht in dem\n",
            "Stil, wir wissen es und so weiter, weil nicht so direkt. Aber unterschwellig, wenn du natürlich jetzt einmal noch zwei,\n",
            "drei Seiten über diese Lösungsansätze schreibst, ist ja unterschwellig eine Aufforder\n",
            "\n",
            "{'token_usage': {'prompt_tokens': 1535, 'completion_tokens': 444, 'total_tokens': 1979}, 'model_name': 'gpt-3.5-turbo', 'wordcount': {'input': 981, 'output': 243}}\n",
            "\n",
            "Processing step 6 of 7\n",
            " You are in the role of an assistant for an editor. Shorten the following text. Paraphrase the text, do not invent\n",
            "anything new and keep the original tone and style.  The output format is in Markdown syntax. Write in German language.\n",
            "``Und das reicht halt nicht nur aufs Intranet zu stellen oder mal ein Newsletter, den keiner mehr liest, sondern da muss\n",
            "ich oft die Leute ein bisschen persönlich abholenIch glaube, wir haben noch nie mit jemanden fünf Minuten hier über\n",
            "seine KPIs oder zehn Minuten über die KPIs erzählen lassen. Das ist eindrucksvoll. Das finde ich sehr spannend und sehr\n",
            "interessant, wie ihr das aufgefächert habt. Das ist bestimmt für den einen oder anderen auch vielleicht eine\n",
            "Inspiration, das auch in die Richtung zu entwickeln. Ja, und gleichzeitig Und gleichzeitig kam auc\n",
            "\n",
            "{'token_usage': {'prompt_tokens': 1579, 'completion_tokens': 468, 'total_tokens': 2047}, 'model_name': 'gpt-3.5-turbo', 'wordcount': {'input': 986, 'output': 297}}\n",
            "\n",
            "Processing step 7 of 7\n",
            " You are in the role of an assistant for an editor. Shorten the following text. Paraphrase the text, do not invent\n",
            "anything new and keep the original tone and style.  The output format is in Markdown syntax. Write in German language.\n",
            "``Was aber wichtig ist, weil viele immer Angst haben, ersetzt mich das und so weiterAlso die Message ist ganz klar. Wer\n",
            "einen Job hat in diesen Bereichen, muss sich möglichst schnell mit dem Thema auseinandersetzen. Keiner wird durch Chat-\n",
            "GPT ersetzt, aber er wird definitiv ersetzt durch eine Person, die Chat-GPT anwenden kann. Definitiv. Also das kann ich\n",
            "so behaupten. Was aber auch wichtig ist, und daher habe ich keine Sorge jetzt für, sagen wir mal, Researcher etc.\n",
            "langfristig, weil auch das Tool, gibt es ja die alte Regel, Rubbish in, Rubbish out. Und da\n",
            "\n",
            "{'token_usage': {'prompt_tokens': 1174, 'completion_tokens': 264, 'total_tokens': 1438}, 'model_name': 'gpt-3.5-turbo', 'wordcount': {'input': 717, 'output': 143}}\n",
            "\n",
            "\n",
            "Ended at: 22:40:37\n",
            "\n",
            "Duration: 1.5 Minutes\n",
            "\n",
            "Statistics:\n",
            "\n",
            "\n",
            "\n",
            "***********************\n",
            "\n",
            "# Statistics: \n",
            "Wordcount ratio: 24.0%, Costs: $0.03\n",
            "\n",
            "{<br>  \"completion_tokens\": 2840,<br>  \"prompt_tokens\": 10793,<br>  \"prompt_tokens_price\": 0.03,<br>  \"total_tokens\": 13633,<br>  \"wordcount_input\": 6656,<br>  \"wordcount_output\": 1651,<br>  \"wordcount_ratio\": 0.24<br>}\n",
            "\n",
            "\n",
            "Model: gpt-3.5-turbo\n",
            "Started at: 22:40:43\n",
            "\n",
            "Processing step 1 of 2\n",
            " You are in the role of an assistant for an editor. Shorten the following text. Paraphrase the text, do not invent\n",
            "anything new and keep the original tone and style.  The output format is in Markdown syntax. Write in German language.\n",
            "``# Content-Performance-Podcast mit Fabian Deckert und Benjamin Odani  Herzlich willkommen zum Content-Performance-\n",
            "Podcast mit Fabian Deckert und Benjamin Odani, dem Online-Marketing-Podcast für Fortgeschrittene. Heute sprechen wir mit\n",
            "Michael Gramp, dem Chefökonomen bei Deloitte in der Schweiz, über die Entwicklung von Thought Leadership Content bei\n",
            "Deloitte. Thought Leadership hilft dabei, Unternehmen und Einzelpersonen als Vordenker und Experten zu positionieren und\n",
            "langfristige Kundenbeziehungen aufzubauen. Deloitte investiert strategisch in Thought Lead\n",
            "\n",
            "{'token_usage': {'prompt_tokens': 1765, 'completion_tokens': 1690, 'total_tokens': 3455}, 'model_name': 'gpt-3.5-turbo', 'wordcount': {'input': 990, 'output': 986}}\n",
            "\n",
            "Processing step 2 of 2\n",
            " You are in the role of an assistant for an editor. Shorten the following text. Paraphrase the text, do not invent\n",
            "anything new and keep the original tone and style.  The output format is in Markdown syntax. Write in German language.\n",
            "``Die Lösungsansätze werden nicht direkt genannt, sondern unterschwellig angedeutet, um Interesse zu weckenDas Ziel ist\n",
            "es, dass sich Leser bei uns melden und weiterführende Schritte unternehmen.   Um den Erfolg zu messen, verwenden wir\n",
            "verschiedene KPIs. Digitale KPIs sind am einfachsten zu messen und umfassen Website-Besuche, Scroll-Rate, Absprungrate,\n",
            "Verweildauer auf der Seite, Leads usw. Wir haben auch KPIs für organische und bezahlte Social-Media-Kampagnen, wie z.B.\n",
            "Impressionen, Klicks, Likes, Shares und Gesamtengagement.   Bei den Marketing-KPIs geht\n",
            "\n",
            "{'token_usage': {'prompt_tokens': 1196, 'completion_tokens': 655, 'total_tokens': 1851}, 'model_name': 'gpt-3.5-turbo', 'wordcount': {'input': 660, 'output': 354}}\n",
            "\n",
            "\n",
            "Ended at: 22:41:59\n",
            "\n",
            "Duration: 1.2 Minutes\n",
            "\n",
            "Statistics:\n",
            "\n",
            "\n",
            "\n",
            "***********************\n",
            "\n",
            "# Statistics: \n",
            "Wordcount ratio: 81.0%, Costs: $0.01\n",
            "\n",
            "{<br>  \"completion_tokens\": 2345,<br>  \"prompt_tokens\": 2961,<br>  \"prompt_tokens_price\": 0.01,<br>  \"total_tokens\": 5306,<br>  \"wordcount_input\": 1650,<br>  \"wordcount_output\": 1340,<br>  \"wordcount_ratio\": 0.81<br>}\n",
            "\n",
            "\n",
            "Model: gpt-3.5-turbo\n",
            "Started at: 22:42:00\n",
            "\n",
            "Processing step 1 of 2\n",
            " You are in the role of an assistant for an editor. Shorten the following text. Paraphrase the text, do not invent\n",
            "anything new and keep the original tone and style.  The output format is in Markdown syntax. Write in German language.\n",
            "``# Content-Performance-Podcast mit Fabian Deckert und Benjamin Odani  Willkommen zum Content-Performance-Podcast mit\n",
            "Fabian Deckert und Benjamin Odani. Heute sprechen wir mit Michael Gramp, dem Chefökonomen bei Deloitte in der Schweiz,\n",
            "über die Entwicklung von Thought Leadership Content bei Deloitte. Thought Leadership hilft Unternehmen und\n",
            "Einzelpersonen dabei, sich als Vordenker und Experten zu positionieren und langfristige Kundenbeziehungen aufzubauen.\n",
            "Deloitte investiert strategisch in Thought Leadership Content und hat dafür ein globales Team, regiona\n",
            "\n",
            "{'token_usage': {'prompt_tokens': 1727, 'completion_tokens': 1666, 'total_tokens': 3393}, 'model_name': 'gpt-3.5-turbo', 'wordcount': {'input': 973, 'output': 973}}\n",
            "\n",
            "Processing step 2 of 2\n",
            " You are in the role of an assistant for an editor. Shorten the following text. Paraphrase the text, do not invent\n",
            "anything new and keep the original tone and style.  The output format is in Markdown syntax. Write in German language.\n",
            "``Hier werden die Risiken analysiert und Empfehlungen gegeben, wie Unternehmen diese vermeiden können.```  Die\n",
            "Lösungsansätze werden indirekt angedeutet, um Interesse zu wecken und Leser zur Kontaktaufnahme zu motivierenZur Messung\n",
            "des Erfolgs werden verschiedene KPIs verwendet. Digitale KPIs wie Website-Besuche, Scroll-Rate, Absprungrate,\n",
            "Verweildauer auf der Seite und Leads sind leicht zu messen. Auch KPIs für organische und bezahlte Social-Media-Kampagnen\n",
            "wie Impressionen, Klicks, Likes, Shares und Gesamtengagement werden genutzt. Marketing-KPIs beziehen\n",
            "\n",
            "{'token_usage': {'prompt_tokens': 741, 'completion_tokens': 679, 'total_tokens': 1420}, 'model_name': 'gpt-3.5-turbo', 'wordcount': {'input': 366, 'output': 362}}\n",
            "\n",
            "\n",
            "Ended at: 22:43:22\n",
            "\n",
            "Duration: 1.3 Minutes\n",
            "\n",
            "Statistics:\n",
            "\n",
            "\n",
            "\n",
            "***********************\n",
            "\n",
            "# Statistics: \n",
            "Wordcount ratio: 99.0%, Costs: $0.01\n",
            "\n",
            "{<br>  \"completion_tokens\": 2345,<br>  \"prompt_tokens\": 2468,<br>  \"prompt_tokens_price\": 0.01,<br>  \"total_tokens\": 4813,<br>  \"wordcount_input\": 1339,<br>  \"wordcount_output\": 1335,<br>  \"wordcount_ratio\": 0.99<br>}\n",
            "\n",
            "\n",
            "Model: gpt-3.5-turbo\n",
            "Started at: 22:43:23\n",
            "\n",
            "Processing step 1 of 2\n",
            " You are in the role of an assistant for an editor. Shorten the following text. Paraphrase the text, do not invent\n",
            "anything new and keep the original tone and style.  The output format is in Markdown syntax. Write in German language.\n",
            "``# Content-Performance-Podcast mit Fabian Deckert und Benjamin Odani  Willkommen zum Content-Performance-Podcast mit\n",
            "Fabian Deckert und Benjamin Odani. Heute sprechen wir mit Michael Gramp, dem Chefökonomen bei Deloitte in der Schweiz,\n",
            "über die Entwicklung von Thought Leadership Content bei Deloitte. Thought Leadership hilft Unternehmen und\n",
            "Einzelpersonen dabei, sich als Vordenker und Experten zu positionieren und langfristige Kundenbeziehungen aufzubauen.\n",
            "Deloitte investiert strategisch in Thought Leadership Content und hat dafür ein globales Team, regiona\n",
            "\n",
            "{'token_usage': {'prompt_tokens': 1781, 'completion_tokens': 1721, 'total_tokens': 3502}, 'model_name': 'gpt-3.5-turbo', 'wordcount': {'input': 999, 'output': 999}}\n",
            "\n",
            "Processing step 2 of 2\n",
            " You are in the role of an assistant for an editor. Shorten the following text. Paraphrase the text, do not invent\n",
            "anything new and keep the original tone and style.  The output format is in Markdown syntax. Write in German language.\n",
            "``Zur Messung des Erfolgs werden verschiedene KPIs verwendet, wie z.BWebsite-Besuche, Scroll-Rate, Absprungrate,\n",
            "Verweildauer auf der Seite und Leads. Auch KPIs für organische und bezahlte Social-Media-Kampagnen wie Impressionen,\n",
            "Klicks, Likes, Shares und Gesamtengagement werden genutzt. Marketing-KPIs beziehen sich auf die Interaktion mit Kunden,\n",
            "einschließlich der Anzahl der Berührungspunkte durch die Studie. Auch Events und Mittagessen mit Kunden werden\n",
            "berücksichtigt. Es gibt auch KPIs für qualifizierte Leads, die jedoch schwer zu messen sind, da nicht a\n",
            "\n",
            "{'token_usage': {'prompt_tokens': 686, 'completion_tokens': 625, 'total_tokens': 1311}, 'model_name': 'gpt-3.5-turbo', 'wordcount': {'input': 335, 'output': 335}}\n",
            "\n",
            "\n",
            "Ended at: 22:44:40\n",
            "\n",
            "Duration: 1.2 Minutes\n",
            "\n",
            "Statistics:\n",
            "\n",
            "\n",
            "\n",
            "***********************\n",
            "\n",
            "# Statistics: \n",
            "Wordcount ratio: 100.0%, Costs: $0.01\n",
            "\n",
            "{<br>  \"completion_tokens\": 2346,<br>  \"prompt_tokens\": 2467,<br>  \"prompt_tokens_price\": 0.01,<br>  \"total_tokens\": 4813,<br>  \"wordcount_input\": 1334,<br>  \"wordcount_output\": 1334,<br>  \"wordcount_ratio\": 1.0<br>}\n",
            "\n",
            "\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyM4xN8xdD2zITOyQQgq+tV2",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "a829738f8c90455c9daa109b44abc55d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "VBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_5ce7f5e6c7c641c5ab943f3046372629",
              "IPY_MODEL_339f449797b2482c903685ad47b1d8b9",
              "IPY_MODEL_84933faa02c24ed9af73992c11446a93",
              "IPY_MODEL_aa9a5498f1c348f9ae285d81097bd30d",
              "IPY_MODEL_3be510e876924a128169ccf010dcbba3",
              "IPY_MODEL_408dbdc87d504ec2ac7d7f16ad96f474"
            ],
            "layout": "IPY_MODEL_9ba888272187427f9662cc2a42248882"
          }
        },
        "5ce7f5e6c7c641c5ab943f3046372629": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "BoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "BoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "BoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a2f5672325be44dfb09435f8a51918ad"
            ],
            "layout": "IPY_MODEL_76e86997daff4ca29e16a1228578947f"
          }
        },
        "339f449797b2482c903685ad47b1d8b9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "BoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "BoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "BoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_35d7d5bc127e448992b410494ac36e0d"
            ],
            "layout": "IPY_MODEL_76e86997daff4ca29e16a1228578947f"
          }
        },
        "84933faa02c24ed9af73992c11446a93": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "BoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "BoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "BoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_5efd3aa14e254b84b2f34d2b9aceeddf",
              "IPY_MODEL_52f97d7d3dbe45a08393f0bd97032947",
              "IPY_MODEL_55799e20bcbf4fddaddf39d5ab0e764b",
              "IPY_MODEL_93d11d613aeb4cf8a955ccc772f92073"
            ],
            "layout": "IPY_MODEL_76e86997daff4ca29e16a1228578947f"
          }
        },
        "aa9a5498f1c348f9ae285d81097bd30d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "BoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "BoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "BoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_2532a2f7705246249dbdd962f79ca2c0",
              "IPY_MODEL_215f495f18484612aa52e5e1141f06c7",
              "IPY_MODEL_8125bba543c544d29a489583b28afd58",
              "IPY_MODEL_b7fe0a1d139547d1a5204125278e19ea"
            ],
            "layout": "IPY_MODEL_76e86997daff4ca29e16a1228578947f"
          }
        },
        "3be510e876924a128169ccf010dcbba3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "BoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "BoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "BoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_1ce1ae8a53524cfc9d48432ba04c7754",
              "IPY_MODEL_0a20bb9cd93649c5a604b7e69e3e98fc",
              "IPY_MODEL_16289ab2dd1342f5a8ec46665c33c850",
              "IPY_MODEL_c99206c78a1d4280abfdd1febad36c16"
            ],
            "layout": "IPY_MODEL_76e86997daff4ca29e16a1228578947f"
          }
        },
        "408dbdc87d504ec2ac7d7f16ad96f474": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "BoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "BoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "BoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_96ef5680617e46938619961b02e3b16c"
            ],
            "layout": "IPY_MODEL_76e86997daff4ca29e16a1228578947f"
          }
        },
        "9ba888272187427f9662cc2a42248882": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a2f5672325be44dfb09435f8a51918ad": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d52e67f11d544f449f30727584ebad59",
            "placeholder": "​",
            "style": "IPY_MODEL_1b94f8a6cbba4e0281be9d1a92c7b6f7",
            "value": "<div style=\"background-color: red; text-align: center\"><b>Please wait for initial setup...</b></div>"
          }
        },
        "76e86997daff4ca29e16a1228578947f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": "stretch",
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": "flex",
            "flex": null,
            "flex_flow": "row",
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "90%"
          }
        },
        "35d7d5bc127e448992b410494ac36e0d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7e9ce601785847e6a5d69ddc7d536072",
            "placeholder": "​",
            "style": "IPY_MODEL_644c2a4d400447cd9d841138e051410e",
            "value": "<div style=\"background-color: #ccc; text-align: center\">Hello <b>World</b></div>"
          }
        },
        "5efd3aa14e254b84b2f34d2b9aceeddf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c1a2f88f233b46c7b1883722ed73caa3",
            "placeholder": "​",
            "style": "IPY_MODEL_5d022a971b554f91b3da02d701ba6a5c",
            "value": "Infotext"
          }
        },
        "52f97d7d3dbe45a08393f0bd97032947": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_46d7d9d2d40a4c539216f8a4df88296f",
            "placeholder": "​",
            "style": "IPY_MODEL_5436693acd5d4691b08aeab299c2c9f4",
            "value": "Infotext jdskl fjkdslf jsdklfjslf"
          }
        },
        "55799e20bcbf4fddaddf39d5ab0e764b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bd73248f5bbe443d850f2463c41b0599",
            "placeholder": "​",
            "style": "IPY_MODEL_6aecb9209d75414b8f0d967fcce41a27",
            "value": "Infotext jdskl fjkdslf jsdklfjslf"
          }
        },
        "93d11d613aeb4cf8a955ccc772f92073": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_47741962461f4b6aaba1aec0a706f3ee",
            "placeholder": "​",
            "style": "IPY_MODEL_ca5864e4fb5546c5924460031fe9ae67",
            "value": "Infotext jdskl fjkdslf jsdklfjslf"
          }
        },
        "2532a2f7705246249dbdd962f79ca2c0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "TextareaModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "TextareaModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "TextareaView",
            "continuous_update": true,
            "description": "",
            "description_tooltip": null,
            "disabled": false,
            "layout": "IPY_MODEL_67bdc1c7f2d44c92af7c744cd403e673",
            "placeholder": "Enter input text",
            "rows": null,
            "style": "IPY_MODEL_3e3fcf49787a402893df0b4883d1cb2e",
            "value": ""
          }
        },
        "215f495f18484612aa52e5e1141f06c7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "TextareaModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "TextareaModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "TextareaView",
            "continuous_update": true,
            "description": "",
            "description_tooltip": null,
            "disabled": false,
            "layout": "IPY_MODEL_1c8d9820ee374abd8d1b061ffaaa275c",
            "placeholder": "Enter input text",
            "rows": null,
            "style": "IPY_MODEL_eb1c8af3aea74ba7b66acb67ff5d61ad",
            "value": ""
          }
        },
        "8125bba543c544d29a489583b28afd58": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "TextareaModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "TextareaModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "TextareaView",
            "continuous_update": true,
            "description": "",
            "description_tooltip": null,
            "disabled": false,
            "layout": "IPY_MODEL_87c6ff2387514390b1e470e8b2a43eb3",
            "placeholder": "Enter input text",
            "rows": null,
            "style": "IPY_MODEL_b5b5828b9f7a4ce59ab5a8c8e1ebdb33",
            "value": ""
          }
        },
        "b7fe0a1d139547d1a5204125278e19ea": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "TextareaModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "TextareaModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "TextareaView",
            "continuous_update": true,
            "description": "",
            "description_tooltip": null,
            "disabled": false,
            "layout": "IPY_MODEL_ebdbc656822d478485da17fb8fe5705f",
            "placeholder": "Enter input text",
            "rows": null,
            "style": "IPY_MODEL_0ff7e796bf6942dcb5ccbcf3d6ed125e",
            "value": ""
          }
        },
        "1ce1ae8a53524cfc9d48432ba04c7754": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ButtonView",
            "button_style": "success",
            "description": "Summarize Articles",
            "disabled": false,
            "icon": "",
            "layout": "IPY_MODEL_8532fa5f72f54d3a98e37874d30960d2",
            "style": "IPY_MODEL_a56a81ea85644a0fbd56954319131712",
            "tooltip": ""
          }
        },
        "0a20bb9cd93649c5a604b7e69e3e98fc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ButtonView",
            "button_style": "success",
            "description": "Save Text",
            "disabled": false,
            "icon": "",
            "layout": "IPY_MODEL_ce1eb6ea7911436dbf4e639c720756e7",
            "style": "IPY_MODEL_b33c7a9ed3cd41f982d7427e6e2d112f",
            "tooltip": ""
          }
        },
        "16289ab2dd1342f5a8ec46665c33c850": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ButtonView",
            "button_style": "success",
            "description": "Split Text",
            "disabled": false,
            "icon": "",
            "layout": "IPY_MODEL_806b5ef1eac14e5e91c822911c8e2bd6",
            "style": "IPY_MODEL_3f7bda997b744f5fa85a1b81b60ab2ad",
            "tooltip": ""
          }
        },
        "c99206c78a1d4280abfdd1febad36c16": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ButtonView",
            "button_style": "success",
            "description": "Chat",
            "disabled": false,
            "icon": "",
            "layout": "IPY_MODEL_d1a87be6276f421d84a372d5645e79ba",
            "style": "IPY_MODEL_129afcfee9bc4da1b3b556e974a86269",
            "tooltip": ""
          }
        },
        "96ef5680617e46938619961b02e3b16c": {
          "model_module": "@jupyter-widgets/output",
          "model_name": "OutputModel",
          "model_module_version": "1.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/output",
            "_model_module_version": "1.0.0",
            "_model_name": "OutputModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/output",
            "_view_module_version": "1.0.0",
            "_view_name": "OutputView",
            "layout": "IPY_MODEL_fdd710a7c1924786a1a0d9d56f5b9424",
            "msg_id": "",
            "outputs": []
          }
        },
        "d52e67f11d544f449f30727584ebad59": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": "1 1 auto",
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": "hidden",
            "width": "auto"
          }
        },
        "1b94f8a6cbba4e0281be9d1a92c7b6f7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7e9ce601785847e6a5d69ddc7d536072": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": "1 1 auto",
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "auto"
          }
        },
        "644c2a4d400447cd9d841138e051410e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c1a2f88f233b46c7b1883722ed73caa3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": "1 1 auto",
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "25%"
          }
        },
        "5d022a971b554f91b3da02d701ba6a5c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "46d7d9d2d40a4c539216f8a4df88296f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": "1 1 auto",
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "25%"
          }
        },
        "5436693acd5d4691b08aeab299c2c9f4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "bd73248f5bbe443d850f2463c41b0599": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": "1 1 auto",
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "25%"
          }
        },
        "6aecb9209d75414b8f0d967fcce41a27": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "47741962461f4b6aaba1aec0a706f3ee": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": "1 1 auto",
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "25%"
          }
        },
        "ca5864e4fb5546c5924460031fe9ae67": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "67bdc1c7f2d44c92af7c744cd403e673": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": "1 1 auto",
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": "150px",
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "25%"
          }
        },
        "3e3fcf49787a402893df0b4883d1cb2e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1c8d9820ee374abd8d1b061ffaaa275c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": "1 1 auto",
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": "150px",
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "25%"
          }
        },
        "eb1c8af3aea74ba7b66acb67ff5d61ad": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "87c6ff2387514390b1e470e8b2a43eb3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": "1 1 auto",
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": "150px",
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "25%"
          }
        },
        "b5b5828b9f7a4ce59ab5a8c8e1ebdb33": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ebdbc656822d478485da17fb8fe5705f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": "1 1 auto",
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": "150px",
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "25%"
          }
        },
        "0ff7e796bf6942dcb5ccbcf3d6ed125e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8532fa5f72f54d3a98e37874d30960d2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": "1 1 0%",
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": "visible",
            "width": "auto"
          }
        },
        "a56a81ea85644a0fbd56954319131712": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "button_color": null,
            "font_weight": ""
          }
        },
        "ce1eb6ea7911436dbf4e639c720756e7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": "1 1 0%",
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": "visible",
            "width": "auto"
          }
        },
        "b33c7a9ed3cd41f982d7427e6e2d112f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "button_color": null,
            "font_weight": ""
          }
        },
        "806b5ef1eac14e5e91c822911c8e2bd6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": "1 1 0%",
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": "visible",
            "width": "auto"
          }
        },
        "3f7bda997b744f5fa85a1b81b60ab2ad": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "button_color": null,
            "font_weight": ""
          }
        },
        "d1a87be6276f421d84a372d5645e79ba": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": "1 1 0%",
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": "visible",
            "width": "auto"
          }
        },
        "129afcfee9bc4da1b3b556e974a86269": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "button_color": null,
            "font_weight": ""
          }
        },
        "fdd710a7c1924786a1a0d9d56f5b9424": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": "1 1 auto",
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "auto"
          }
        },
        "eef4ef83589741d48dfb57aa37a3bbd0": {
          "model_module": "@jupyter-widgets/output",
          "model_name": "OutputModel",
          "model_module_version": "1.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/output",
            "_model_module_version": "1.0.0",
            "_model_name": "OutputModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/output",
            "_view_module_version": "1.0.0",
            "_view_name": "OutputView",
            "layout": "IPY_MODEL_a0f24a372dd74f33b612ef857edbcb4a",
            "msg_id": "",
            "outputs": []
          }
        },
        "a0f24a372dd74f33b612ef857edbcb4a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "58d8f3bf3f464572aeda481d875b3589": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "TextareaModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "TextareaModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "TextareaView",
            "continuous_update": true,
            "description": "",
            "description_tooltip": null,
            "disabled": false,
            "layout": "IPY_MODEL_b867e32b455348398cb747079c41941f",
            "placeholder": "Enter input text",
            "rows": null,
            "style": "IPY_MODEL_8e740ccf763c4ea2acecca7c18d0efe4",
            "value": ""
          }
        },
        "b867e32b455348398cb747079c41941f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": "150px",
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "50%"
          }
        },
        "8e740ccf763c4ea2acecca7c18d0efe4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "16bb471b4b9f42e8a8d70ee6c83dc23d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ButtonView",
            "button_style": "",
            "description": "Summarize!",
            "disabled": false,
            "icon": "",
            "layout": "IPY_MODEL_4559a204277247cc8d8bd110f643688c",
            "style": "IPY_MODEL_04466e626ca841068fef16b239fc76ee",
            "tooltip": ""
          }
        },
        "4559a204277247cc8d8bd110f643688c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "04466e626ca841068fef16b239fc76ee": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "button_color": null,
            "font_weight": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}