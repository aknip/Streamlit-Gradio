{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aknip/Streamlit-Gradio/blob/main/myGPTlab.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# myGPTlab\n",
        "\n",
        "This app helps to process texts (longform content) with ChatGPT via API.\n",
        "\n",
        "## Start:\n",
        "**Run all cells - that's it.**\n",
        "- The notebooks checks automatically, if an initial setup (with PIP etc.) is necessary. The setup status is saved in the file 'installation.done'\n",
        "- You can force the setup by deleting this file or by going to Seciton \"Setup and Configuration\" and checking \"inital_setup_mode\". Afterwards uncheck \"Setup and Configuration\".\n",
        "\n",
        "## Working with myGPTlab\n",
        "Lorem ipsum...\n"
      ],
      "metadata": {
        "id": "Ht3Wkxk7Rpn_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Setup and Configuration"
      ],
      "metadata": {
        "id": "2goGpKmVRRUd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Settings\n",
        "\n",
        "# @markdown Default model\n",
        "default_model = 'GPT-3.5' # @param [\"GPT-3.5\", \"GPT-4\"]\n",
        "\n",
        "# @markdown Start Gradio webapp.\n",
        "start_gradio_webapp = False # @param {type:\"boolean\"}\n",
        "\n",
        "# @markdown Initial Setup Mode for pip install, fetch credentials etc.\n",
        "initial_setup_mode = False # @param {type:\"boolean\"}\n",
        "\n",
        "# @markdown Debug Mode for extensive logging.\n",
        "debug_mode = True # @param {type:\"boolean\"}\n",
        "\n",
        "# @markdown iOS Mode to develop helper functions, no Gradio.\n",
        "# @markdown Useful for development on iOS, eg. with Carnets App\n",
        "ios_mode = False # @param {type:\"boolean\"}"
      ],
      "metadata": {
        "cellView": "form",
        "id": "9NyekTkaGU3Z"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "folders = {\n",
        "    'audio': 'audio',\n",
        "    'audio-chunks': 'audio/chunks',\n",
        "    'transcript':'audio-transcript',\n",
        "    'transcript-chunks': 'audio-transcript/chunks',\n",
        "    'text-input': 'text-input',\n",
        "    'text-input-backup': 'text-input-backup'\n",
        "}"
      ],
      "metadata": {
        "id": "FBJns82oduIg"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from ipywidgets import widgets\n",
        "from IPython.display import Javascript, display, clear_output\n",
        "notify_output = widgets.Output()\n",
        "display(notify_output)\n",
        "@notify_output.capture()\n",
        "def popup(text):\n",
        "    clear_output()\n",
        "    display(Javascript(\"alert('{}')\".format(text)))\n",
        "#popup('Hello World!')"
      ],
      "metadata": {
        "id": "Z-9rgUetGeu0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17,
          "referenced_widgets": [
            "f5786a99eb56472294435950fb9da0d1",
            "61e0b62de19a474fa1b92b5508133b00"
          ]
        },
        "outputId": "22f5b3f1-ca09-4938-cb74-2dc127580e1f"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Output()"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f5786a99eb56472294435950fb9da0d1"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "if initial_setup_mode != True:\n",
        "  if os.path.exists('installation.done'):\n",
        "      initial_setup_mode = False\n",
        "      print('No initial setup - forced by existing file \"installation.done\"')\n",
        "  else:\n",
        "    initial_setup_mode = True\n",
        "    print('Starting automatic setup - forced by missing file \"installation.done\".\\n\\nEnter API Keys as JSON (in next notebook cell).')\n",
        "    popup('Starting automatic setup. Enter API Keys as JSON (in next notebook cell).')\n",
        "else:\n",
        "  print('Starting setup.\\n\\nEnter API Keys as JSON (in next notebook cell).')\n",
        "  popup('Starting setup. Enter API Keys as JSON (in next notebook cell).')"
      ],
      "metadata": {
        "id": "4cDDPr809eC4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "0dddb206-74db-41a7-cec5-5a9b07a9c9a8"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting automatic setup - forced by missing file \"installation.done\".\n",
            "\n",
            "Enter API Keys as JSON (in next notebook cell).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "if initial_setup_mode == True:\n",
        "  #popup('Enter API Keys as JSON:')\n",
        "  !wget -q bit.ly/aknip-colab-setup\n",
        "  %run aknip-colab-setup\n",
        "else:\n",
        "  print('No initial setup.')"
      ],
      "metadata": {
        "id": "eepWvnFN-yvj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2566a1f6-acd2-496b-f809-683d8b805b1f"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Secrets (JSON string): ··········\n",
            "Credentials stored in env 'CREDS'. Get values via: \n",
            "creds = json.loads(os.getenv('CREDS')) \n",
            "key = creds['OpenAI']['v1']['credential']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "creds = json.loads(os.getenv('CREDS'))\n",
        "# openAI_key = creds['OpenAI']['v2']['credential']\n",
        "# print(openAI_key)"
      ],
      "metadata": {
        "id": "iEwJ4-ShAt0v"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if ios_mode == False:\n",
        "  print('Mac')\n",
        "else:\n",
        "  print('iOS')"
      ],
      "metadata": {
        "id": "DRWVZHV1MOij",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "13a924d7-36df-4390-b55c-22be8dbe0681"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mac\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "Wtw0CARBQhTQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0b03a0bf-4f8b-4882-b09f-301fe1bda1fa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m72.0/72.0 kB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.0/3.0 MB\u001b[0m \u001b[31m9.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m16.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m232.6/232.6 kB\u001b[0m \u001b[31m15.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.1/14.1 MB\u001b[0m \u001b[31m37.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m193.6/193.6 kB\u001b[0m \u001b[31m16.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m50.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m129.9/129.9 kB\u001b[0m \u001b[31m12.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.7/2.7 MB\u001b[0m \u001b[31m53.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m90.0/90.0 kB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.4/49.4 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for pickle-mixin (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ],
      "source": [
        "if initial_setup_mode == True:\n",
        "  !pip install openai==0.27.7 yt-dlp==2023.7.6 librosa==0.10.0.post2 pickle-mixin==1.0.2 langchain==0.0.225 PyPDF2==3.0.1 PyMuPDF==1.22.5 -q\n",
        "else:\n",
        "  print('No initial setup.')\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "if (initial_setup_mode == True) and (ios_mode == False) :\n",
        "  !pip install gradio -q\n",
        "else:\n",
        "  print('No initial setup / iOS.')"
      ],
      "metadata": {
        "id": "-TpG9Zr0IUU0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "59ae39d1-9e44-47bf-ae25-011fc4520c50"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m19.9/19.9 MB\u001b[0m \u001b[31m32.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m65.7/65.7 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m294.2/294.2 kB\u001b[0m \u001b[31m17.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.4/75.4 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m268.8/268.8 kB\u001b[0m \u001b[31m16.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.5/50.5 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m140.3/140.3 kB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.7/45.7 kB\u001b[0m \u001b[31m1.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m59.5/59.5 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.4/50.4 kB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.5/46.5 kB\u001b[0m \u001b[31m396.3 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.7/43.7 kB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.0/41.0 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.0/41.0 kB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m87.5/87.5 kB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.5/84.5 kB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.0/67.0 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m74.5/74.5 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for ffmpy (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "if (initial_setup_mode == True) and (ios_mode == False) :\n",
        "  %load_ext gradio\n",
        "else:\n",
        "  print('No initial setup / iOS.')"
      ],
      "metadata": {
        "id": "EyhkzcJ_Ob45"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if initial_setup_mode == True:\n",
        "  f= open('installation.done','w+')\n",
        "  f.close()\n",
        "  print('Initial setup done. Application starting.')\n",
        "  popup('Initial setup done. Application starting.')\n",
        "else:\n",
        "  print('No initial setup.')"
      ],
      "metadata": {
        "id": "l0Lx1eHL9Nik",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "cf4a2943-aaca-4e80-9c6a-649a32a3f38b"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Initial setup done. Application starting.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Helper Functions\n",
        "\n",
        "- **create_file_directory**: Creates a new directory - if it not exists yet. The always_delete flag forces a deletion even if it exists."
      ],
      "metadata": {
        "id": "zO7UxoRjSWUy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# v2 - 06.08.2023\n",
        "import shutil\n",
        "import os\n",
        "\n",
        "def create_file_directory(directory, always_delete=False):\n",
        "  # Creates a new directory - if it not exists yet. The always_delete flag forces a deletion even if it exists.\n",
        "  # Examples:\n",
        "  # - create_file_directory('texts', False) => creates a new directory only if it not exists yet\n",
        "  # - create_file_directory('texts', True) => always deletes existing directory and creates a new one\n",
        "  if os.path.exists(directory):\n",
        "    if always_delete:\n",
        "      # delete the diectory recursively\n",
        "      shutil.rmtree(directory)\n",
        "  # create directory\n",
        "  if not os.path.exists(directory):\n",
        "    os.mkdir(directory)\n",
        "\n",
        "\n",
        "def find_files(path, extensions=[\".txt\"], recursive=False):\n",
        "    # Recursively (optional) find all files with extension in path\n",
        "    my_files = []\n",
        "    for root, dirs, files in os.walk(path):\n",
        "        for f in files:\n",
        "            if extensions == []:\n",
        "                my_files.append(os.path.join(root, f))\n",
        "            else:\n",
        "                for ext in extensions:\n",
        "                    if f.endswith(ext):\n",
        "                        my_files.append(os.path.join(root, f))\n",
        "        # no recursion / don't look inside any subdirectory\n",
        "        if recursive == False:\n",
        "            break\n",
        "    return my_files\n",
        "\n",
        "\n",
        "def merge_textfiles(path, extensions=[\".txt\"], recursive=False, new_filename='merged.txt'):\n",
        "    # Recursively (optional) find all files with extension in path\n",
        "    my_files = find_files(path, extensions, recursive)\n",
        "    merged_text = ''\n",
        "    for filename in my_files:\n",
        "      # print(filename)\n",
        "      f= open(filename,'r')\n",
        "      if f.mode == 'r':\n",
        "            contents =f.read()\n",
        "      f.close()\n",
        "      merged_text = merged_text + contents + '\\n\\n\\n'\n",
        "\n",
        "    f= open(new_filename,'w+')\n",
        "    f.write(merged_text)\n",
        "    f.close()"
      ],
      "metadata": {
        "id": "dydmkY6_SZeG"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# The App"
      ],
      "metadata": {
        "id": "A5nBZppW-bt3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if (ios_mode == False) and (start_gradio_webapp == True):\n",
        "  import gradio as gr\n",
        "\n",
        "  # Theming\n",
        "  theme = gr.themes.Default(\n",
        "      primary_hue=\"slate\" # , radius_size=gr.themes.Size(radius_sm=\"3px\", radius_xs=\"2px\", radius_xxs=\"1px\")\n",
        "  )\n",
        "  # Styling: Change max width\n",
        "  css = \"\"\"\n",
        "    .gradio-container {max-width: 700px!important}\n",
        "    .vspacer1 {margin-top: 50px}\n",
        "  \"\"\"\n",
        "\n",
        "  with gr.Blocks(theme=theme, css=css) as demo:\n",
        "\n",
        "      gr.Markdown(\"# ChatGPTLab 2.0\", elem_classes=\"vspacer1\")\n",
        "      gr.Markdown(\"### Optimizing your work with LLMs.\")\n",
        "\n",
        "      project_name = gr.Textbox(label=\"Project name\")\n",
        "\n",
        "      #\n",
        "      # 1. Input Text\n",
        "      #\n",
        "      with gr.Tab(\"Input Text \"):\n",
        "        gr.Markdown(\"Please enter text\")\n",
        "\n",
        "        # Input text via UI\n",
        "        gr.Markdown(\"### Input your text:\")\n",
        "        text_input = gr.Textbox(label=\"Enter text\", placeholder=\"Your text here...\", lines=10)\n",
        "        text_output = gr.Textbox(label=\"Result\")\n",
        "\n",
        "        def text_save(text, proj_name):\n",
        "          create_file_directory(proj_name, False)\n",
        "          create_file_directory(proj_name + '/' +  folders['text-input'], False)\n",
        "          f= open(proj_name + '/' +  folders['text-input'] + '/input_text.txt','w+')\n",
        "          f.write(text)\n",
        "          f.close()\n",
        "          log_text = \"Text saved.\"\n",
        "          return log_text\n",
        "        text_button = gr.Button(\"Save text\")\n",
        "        text_button.click(text_save, [text_input, project_name], text_output)\n",
        "\n",
        "        gr.Markdown(\"\")\n",
        "        gr.Markdown(\"\")\n",
        "\n",
        "        # Input text via upload\n",
        "        gr.Markdown(\"### Or upload your text:\")\n",
        "        upload_button = gr.UploadButton(\"Click to Upload a File\", file_types=[\".txt\",\".md\"], file_count=\"single\")\n",
        "        file_output = gr.Textbox(label=\"Result\")\n",
        "\n",
        "        def upload_file(my_file, proj_name):\n",
        "          create_file_directory(proj_name, False)\n",
        "          create_file_directory(proj_name + '/' +  folders['text-input'], False)\n",
        "          # copy to project directory\n",
        "          full_upload_path = my_file.name\n",
        "          just_the_filename = os.path.basename(full_upload_path)\n",
        "          full_text_path = \"./\" + proj_name + '/' + folders['text-input'] + '/' + just_the_filename\n",
        "          shutil.copyfile(full_upload_path, full_text_path)\n",
        "          # check if file is empty\n",
        "          f= open(full_text_path,'r')\n",
        "          if f.mode == 'r': contents =f.read()\n",
        "          f.close()\n",
        "          log_text = just_the_filename + \"\\n\"\n",
        "          if len(contents) == 0:\n",
        "            log_text = log_text + \"Error: Upload file lengt 0 bytes\"\n",
        "          else:\n",
        "            log_text = log_text + \"Upload successful\"\n",
        "          return log_text\n",
        "        upload_button.upload(upload_file, [upload_button, project_name], file_output)\n",
        "\n",
        "      #\n",
        "      # 2. Download full project\n",
        "      #\n",
        "      with gr.Tab(\"Download\"):\n",
        "        gr.Markdown(\"Download full project as ZIP file.\")\n",
        "        download_button = gr.Button(\"Download project\")\n",
        "        download_output = gr.File()\n",
        "\n",
        "        def download_do(proj_name):\n",
        "          full_text_path = \"./\" + proj_name\n",
        "          shutil.make_archive('archive', 'zip', full_text_path)\n",
        "          result = \"Downloading \" + full_text_path\n",
        "          return \"archive.zip\"\n",
        "        download_button.click(download_do, project_name, download_output)\n",
        "\n",
        "      #\n",
        "      # 3. xxx\n",
        "      #\n",
        "      with gr.Tab(\"Step 2\"):\n",
        "        gr.Markdown(\"Please select the optimization:\")\n",
        "        radio = gr.Radio(\n",
        "          [\"by headline\", \"by paragraph\", \"by §§§\"], label=\"Text split method\"\n",
        "        )\n",
        "        name = gr.Textbox(label=\"Name\", placeholder=\"Enter text...\")\n",
        "        output = gr.Textbox(label=\"Output Box\")\n",
        "        greet_btn = gr.Button(\"Start\", scale=0)\n",
        "        def greet(name):\n",
        "          result = \"HALLO \" + name + \"!!!\"\n",
        "          return result\n",
        "        greet_btn.click(fn=greet, inputs=name, outputs=output, api_name=\"greet\")\n",
        "\n",
        "  demo.launch(quiet=True, share=True, debug=debug_mode)\n",
        "\n",
        "else:\n",
        "  print('iOS Mode - Nothing to do.')"
      ],
      "metadata": {
        "id": "xK8-6hL0eIIE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "46fbdcd1-5feb-4175-fe23-8753824a68dc"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "iOS Mode - Nothing to do.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ChatGPT"
      ],
      "metadata": {
        "id": "lKcS3L5pXA06"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Promptlib\n",
        "# Todo: promptlib not as global,\n",
        "\n",
        "import pickle\n",
        "\n",
        "promptlib = {\n",
        "        'sum': {\n",
        "            'description': 'summarize prompt',\n",
        "            'category': 'summarize',\n",
        "            '1': {\n",
        "                'note': 'summarize prompt v1',\n",
        "                'prompt': 'hello, this is prompttext v1 {variable}'\n",
        "            },\n",
        "            '2': {\n",
        "                'note': 'summarize prompt v2',\n",
        "                'prompt': 'hello, this is prompttext v2 {variable}'\n",
        "            }\n",
        "        },\n",
        "        'para': {\n",
        "            'description': 'paraphrase prompt',\n",
        "            'category': 'paraphrase',\n",
        "            '1': {\n",
        "                'note': 'summarize prompt',\n",
        "                'prompt': 'hello, this is prompttext {variable}'\n",
        "            }\n",
        "        }\n",
        "    }\n",
        "\n",
        "def write_prompt_to_lib(prompt):\n",
        "    # adds or updates prompt to library\n",
        "    id = prompt['id']\n",
        "    version = prompt['version']\n",
        "    if id not in promptlib:\n",
        "        # new id\n",
        "        promptlib[id] = {}\n",
        "        promptlib[id][version] = {}\n",
        "    else:\n",
        "        # id already existing, checking for version\n",
        "        if version not in promptlib[id]:\n",
        "            promptlib[id][version] = {}\n",
        "    promptlib[id]['description'] = prompt['description']\n",
        "    promptlib[id]['category'] = prompt['category']\n",
        "    promptlib[id][version]['note'] = prompt['note']\n",
        "    promptlib[id][version]['prompt'] = prompt['prompt']\n",
        "\n",
        "\n",
        "def get_prompt_from_lib(id=None, version=None):\n",
        "    # searches for prompt with given id\n",
        "    # looks for highest available version, if no version is given\n",
        "    if id==None:\n",
        "        prompt_found = None\n",
        "    else:\n",
        "        prompt = promptlib[id]\n",
        "        if version != None:\n",
        "            # version given\n",
        "            version_highest = int(version)\n",
        "        else:\n",
        "            # look for highest available version\n",
        "            version_highest = 0\n",
        "            for key, val in prompt.items():\n",
        "                try:\n",
        "                    version = int(key)\n",
        "                except ValueError:\n",
        "                    version = 0\n",
        "                if version > version_highest:\n",
        "                    version_highest = version\n",
        "        prompt_version = prompt[str(version_highest)]\n",
        "        # return dict\n",
        "        prompt_found = {}\n",
        "        prompt_found['id'] = id\n",
        "        prompt_found['description'] = prompt['description']\n",
        "        prompt_found['category'] = prompt['category']\n",
        "        prompt_found['version'] = str(version_highest)\n",
        "        prompt_found['note'] = prompt_version['note']\n",
        "        prompt_found['prompt'] = prompt_version['prompt']\n",
        "    return prompt_found\n",
        "\n",
        "\n",
        "def save_promptlib(promptlib):\n",
        "  # saves promptlib to disk\n",
        "  with open('promptlib.dictionary', 'wb') as dict_file:\n",
        "      pickle.dump(promptlib, dict_file)\n",
        "\n",
        "def load_promptlib():\n",
        "  # load promptlib from disk\n",
        "  with open('promptlib.dictionary', 'rb') as dict_file:\n",
        "      promptlib = pickle.load(dict_file)\n",
        "  return promptlib"
      ],
      "metadata": {
        "id": "VD9mE55Zkl--"
      },
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# test promptlib and templates\n",
        "\n",
        "prompt_tmp = get_prompt_from_lib('sum')\n",
        "prompt_tmp = get_prompt_from_lib('sum', '1')\n",
        "#print(json.dumps(prompt_tmp, sort_keys=True, indent=2))\n",
        "\n",
        "def length_calc(my_text, maxWords):\n",
        "  # maxWords 0.0 - 1.0 (percentage)\n",
        "    return int(len(my_text) * maxWords)\n",
        "\n",
        "def build_prompt_from_template(input_txt, prompt_obj, lang, len_max=1):\n",
        "  prompt_text =  prompt_obj['prompt']\n",
        "  language_text = ''\n",
        "  if lang=='lang-de':\n",
        "    language_text = prompt_obj['lang-de']\n",
        "  if lang=='lang-en':\n",
        "    language_text = prompt_obj['lang-en']\n",
        "  if lang=='lang-same':\n",
        "    language_text = prompt_obj['lang-same']\n",
        "  # calculate max. output lengt dynamically\n",
        "  if len_max<1:\n",
        "    length_template = prompt_obj['length-max']\n",
        "    length_template2 = length_template.format(input_text = input_txt, max_len=len_max)\n",
        "    length_text = eval(f\"f'{length_template2}'\")\n",
        "  else:\n",
        "    length_text = ''\n",
        "  final_prompt = prompt_text.format(language_text=language_text, length_text=length_text, input_text=input_txt)\n",
        "  return final_prompt\n",
        "\n",
        "# test\n",
        "new_prompt = {\n",
        "        'id': 'xxx',\n",
        "        'version': '3',\n",
        "        'description': 'updated description',\n",
        "        'category': 'paraphrase',\n",
        "        'note': 'note summarize prompt v3',\n",
        "        'prompt': 'hello, this is prompttext 3. {language_text} {length_text} Text:```{input_text}```',\n",
        "        'lang-de': 'write evertyhing in DE.',\n",
        "        'lang-en': 'write everything in EN.',\n",
        "        'lang-same': 'write in language of original text.',\n",
        "        'length-max': 'max length is {{length_calc(\"{input_text}\", {max_len})}} words'\n",
        "    }\n",
        "\n",
        "\n",
        "input_text = 'This is the input text. Lorem ipsum.'\n",
        "\n",
        "the_prompt = build_prompt_from_template(input_text, new_prompt, 'lang-same', 0.5)\n",
        "print(the_prompt)\n",
        "\n",
        "#write_prompt_to_lib(new_prompt)\n",
        "\n",
        "#print(json.dumps(promptlib, sort_keys=True, indent=2))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OsYX9xQ2mjZd",
        "outputId": "f2b8e09f-05a4-4a14-bf0b-a777519d09ee"
      },
      "execution_count": 97,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "hello, this is prompttext 3. write in language of original text. max length is 18 words Text:```This is the input text. Lorem ipsum.```\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "my_text = 'Die Photosynthese ist ein physiologischer Prozess zur Erzeugung energiereicher Biomoleküle aus energieärmeren Stoffen mit Hilfe von Lichtenergie. Sie wird von Pflanzen, Algen und manchen Bakterien betrieben. Bei diesem biochemischen Vorgang wird Lichtenergie mit Hilfe von lichtabsorbierenden Farbstoffen wie Chlorophyll in chemische Energie umgewandelt. Diese wird dann genutzt, um aus energiearmen anorganischen Stoffen (vor allem Kohlenstoffdioxid (CO2) und Wasser (H2O)) energiereiche organische Verbindungen (vor allem Kohlenhydrate) aufzubauen. Der genutzte Anteil der eingestrahlten Energie, nämlich der zum Aufbau der Assimilate verwendete Anteil, wird photosynthetische Effizienz genannt. Soweit die energiereichen organischen Stoffe zu Bestandteilen des Lebewesens werden, bezeichnet man deren Synthese als Assimilation. Man unterscheidet zwischen oxygener und anoxygener Photosynthese. Bei der oxygenen Photosynthese wird molekularer Sauerstoff (O2) freigesetzt. Bei der anoxygenen Photosynthese, die nur von Bakterien betrieben wird, entstehen statt Sauerstoff andere anorganische Stoffe, beispielsweise elementarer Schwefel (S). Die Photosynthese ist der einzige biochemische Prozess, bei dem Lichtenergie, meistens Sonnenlicht, in chemisch gebundene Energie umgewandelt wird (Phototrophie). Indirekt sind auch fast alle heterotrophen (nicht zur Photosynthese fähigen) Lebewesen von ihr abhängig, da sie der Photosynthese letztlich ihre Nahrung und auch den zur Energiegewinnung mittels aerober Atmung benötigten Sauerstoff verdanken. Aus dem Sauerstoff entsteht außerdem die schützende Ozonschicht der Erdatmosphäre.'"
      ],
      "metadata": {
        "id": "ok-VAVRsVTR-"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create summary\n",
        "\n",
        "from datetime import datetime\n",
        "import langchain\n",
        "from langchain.chains import RetrievalQA\n",
        "from langchain.llms import OpenAI\n",
        "from langchain.chat_models import ChatOpenAI\n",
        "from langchain.schema import (AIMessage, HumanMessage, SystemMessage)\n",
        "from langchain.document_loaders import WebBaseLoader\n",
        "from langchain.embeddings import OpenAIEmbeddings\n",
        "from langchain.indexes import VectorstoreIndexCreator\n",
        "from langchain.prompts import PromptTemplate\n",
        "from langchain.vectorstores import Chroma\n",
        "from langchain.schema import HumanMessage\n",
        "from langchain.callbacks.base import BaseCallbackHandler\n",
        "\n",
        "# OpenAI Key\n",
        "openAI_key = creds['OpenAI']['v2']['credential']\n",
        "\n",
        "def create_summary_bullets (input_text):\n",
        "  llm = ChatOpenAI(model_name=\"gpt-3.5-turbo\", temperature=0.0, openai_api_key=openAI_key)\n",
        "  #llm = ChatOpenAI(model_name=\"gpt-4\", temperature=0.0, openai_api_key=openAI_key)\n",
        "  # model overveiew see https://gptforwork.com/guides/openai-gpt3-models\n",
        "\n",
        "  input_text_segments = input_text.split(\"§§§\")\n",
        "  output_text_segments = []\n",
        "  for index, input_text in enumerate(input_text_segments):\n",
        "\n",
        "      # 3\n",
        "      # model_name=\"gpt-3.5-turbo\", temperature=0.0\n",
        "      # input_text: Max word length: 1100 for EN, 900 for DE\n",
        "      # approx. 1 min processing time\n",
        "      # Example: Full book: 113 parts á 1000 words,  Started at: 22:55:43, Ended at: 23:10:32\n",
        "      myprompt = \"The given text is delimited by triple backticks. Summarize the current text to succint and clear bullet points of its contents. The length of the summary must be 200 words maximum.\"\n",
        "      myprompt = \"The given text is delimited by triple backticks. Summarize the current text to a maximum of 15 succint and clear bullet points of its contents.\"\n",
        "      # myprompt = myprompt + \"The maximum number of words should be 300 words in total. \"\n",
        "      myprompt = myprompt + \"Write everything in German language. \" # this is optional !\n",
        "      myprompt = myprompt + \"```\" + input_text + \"```\"\n",
        "\n",
        "      print('Processing step ' + str(index + 1) + ' of ' + str(len(input_text_segments)))\n",
        "      print('Started at: ' + datetime.now().strftime(\"%H:%M:%S\"))\n",
        "      gpt_response_obj = llm.generate([[HumanMessage(content=myprompt)]])\n",
        "      print('Ended at: ' + datetime.now().strftime(\"%H:%M:%S\"))\n",
        "      tmp_text = gpt_response_obj.generations[0][0].text\n",
        "      tmp_tokens = gpt_response_obj.llm_output\n",
        "      #st.write(tmp_text)\n",
        "      print(str(tmp_tokens) + '\\n')\n",
        "      output_text_segments.append(tmp_text)\n",
        "\n",
        "  full_output_text = '\\n\\n'.join(output_text_segments)\n",
        "  return full_output_text\n",
        "\n",
        "result_text = create_summary_bullets(my_text)\n",
        "print(result_text)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "owpR0O6MTAEz",
        "outputId": "ff9fd693-199a-48db-87e4-ad1afa3b1d4c"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing step 1 of 1\n",
            "Started at: 18:55:10\n",
            "Ended at: 18:55:19\n",
            "{'token_usage': {'prompt_tokens': 509, 'completion_tokens': 372, 'total_tokens': 881}, 'model_name': 'gpt-3.5-turbo'}\n",
            "\n",
            "- Photosynthese ist ein physiologischer Prozess zur Erzeugung energiereicher Biomoleküle aus energieärmeren Stoffen mit Hilfe von Lichtenergie.\n",
            "- Pflanzen, Algen und manche Bakterien betreiben die Photosynthese.\n",
            "- Lichtenergie wird mit Hilfe von lichtabsorbierenden Farbstoffen wie Chlorophyll in chemische Energie umgewandelt.\n",
            "- Energiearme anorganische Stoffe wie Kohlenstoffdioxid (CO2) und Wasser (H2O) werden in energiereiche organische Verbindungen (vor allem Kohlenhydrate) umgewandelt.\n",
            "- Der genutzte Anteil der eingestrahlten Energie wird photosynthetische Effizienz genannt.\n",
            "- Die Synthese energiereicher organischer Stoffe im Lebewesen wird als Assimilation bezeichnet.\n",
            "- Es gibt oxygene und anoxygene Photosynthese.\n",
            "- Bei der oxygenen Photosynthese wird molekularer Sauerstoff (O2) freigesetzt.\n",
            "- Bei der anoxygenen Photosynthese entstehen andere anorganische Stoffe wie elementarer Schwefel (S).\n",
            "- Die Photosynthese ist der einzige biochemische Prozess, bei dem Lichtenergie in chemisch gebundene Energie umgewandelt wird.\n",
            "- Fast alle heterotrophen Lebewesen sind indirekt von der Photosynthese abhängig, da sie ihre Nahrung und den für die Energiegewinnung benötigten Sauerstoff daraus beziehen.\n",
            "- Die Photosynthese trägt zur Bildung der schützenden Ozonschicht in der Erdatmosphäre bei.\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPXkPGM9CpNyRJiuIs0Bj/w",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "f5786a99eb56472294435950fb9da0d1": {
          "model_module": "@jupyter-widgets/output",
          "model_name": "OutputModel",
          "model_module_version": "1.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/output",
            "_model_module_version": "1.0.0",
            "_model_name": "OutputModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/output",
            "_view_module_version": "1.0.0",
            "_view_name": "OutputView",
            "layout": "IPY_MODEL_61e0b62de19a474fa1b92b5508133b00",
            "msg_id": "",
            "outputs": [
              {
                "output_type": "display_data",
                "data": {
                  "text/plain": "<IPython.core.display.Javascript object>",
                  "application/javascript": "alert('Initial setup done. Application starting.')"
                },
                "metadata": {}
              }
            ]
          }
        },
        "61e0b62de19a474fa1b92b5508133b00": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}