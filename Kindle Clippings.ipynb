{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aknip/Streamlit-Gradio/blob/main/Kindle%20Clippings.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Kindle Clippings\n",
        "\n",
        "xxx\n",
        "Sources:\n",
        "- https://github.com/dannberg/kindle-clippings-to-obsidian\n",
        "- https://github.com/stephenfmann/kindle-clippings/tree/master\n",
        "\n",
        "## First run:\n",
        "\n",
        "Go to \"Setup and Configuration\" and check \"inital_setup_mode\". Then run all cells. Afterwards uncheck \"Setup and Configuration\"."
      ],
      "metadata": {
        "id": "Ht3Wkxk7Rpn_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Setup and Configuration"
      ],
      "metadata": {
        "id": "2goGpKmVRRUd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Settings\n",
        "\n",
        "# @markdown Output only notes younger than x days\n",
        "max_days_old = 99 # @param {type:\"number\"}\n",
        "\n",
        "# @markdown Initial Setup Mode for pip install, fetch credentials etc.\n",
        "initial_setup_mode = False # @param {type:\"boolean\"}\n",
        "\n",
        "# @markdown Debug Mode for extensive logging.\n",
        "debug_mode = True # @param {type:\"boolean\"}\n",
        "\n",
        "# @markdown iOS Mode to develop helper functions, no Gradio.\n",
        "# @markdown Useful for development on iOS, eg. with Carnets App\n",
        "ios_mode = False # @param {type:\"boolean\"}"
      ],
      "metadata": {
        "cellView": "form",
        "id": "9NyekTkaGU3Z"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "folders = {\n",
        "    'clippings-input': 'in',\n",
        "    'clippings-output': 'out'\n",
        "}"
      ],
      "metadata": {
        "id": "FBJns82oduIg"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "Wtw0CARBQhTQ",
        "outputId": "eabb0344-b657-471e-edf5-72feeb99557d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: dateparser in /usr/local/lib/python3.10/dist-packages (1.1.8)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.10/dist-packages (from dateparser) (2.8.2)\n",
            "Requirement already satisfied: pytz in /usr/local/lib/python3.10/dist-packages (from dateparser) (2022.7.1)\n",
            "Requirement already satisfied: regex!=2019.02.19,!=2021.8.27 in /usr/local/lib/python3.10/dist-packages (from dateparser) (2022.10.31)\n",
            "Requirement already satisfied: tzlocal in /usr/local/lib/python3.10/dist-packages (from dateparser) (5.0.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil->dateparser) (1.16.0)\n"
          ]
        }
      ],
      "source": [
        "if initial_setup_mode == True:\n",
        "  !pip install dateparser\n",
        "else:\n",
        "  print('No initial setup.')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Helper Functions\n",
        "\n",
        "- **create_file_directory**: Creates a new directory - if it not exists yet. The always_delete flag forces a deletion even if it exists."
      ],
      "metadata": {
        "id": "zO7UxoRjSWUy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import shutil\n",
        "import os\n",
        "\n",
        "def create_file_directory(directory, always_delete=False):\n",
        "  # Creates a new directory - if it not exists yet. The always_delete flag forces a deletion even if it exists.\n",
        "  # Examples:\n",
        "  # - create_file_directory('texts', False) => creates a new directory only if it not exists yet\n",
        "  # - create_file_directory('texts', True) => always deletes existing directory and creates a new one\n",
        "  if os.path.exists(directory):\n",
        "    if always_delete:\n",
        "      # delete the diectory recursively\n",
        "      shutil.rmtree(directory)\n",
        "  # create directory\n",
        "  if not os.path.exists(directory):\n",
        "    os.mkdir(directory)\n",
        "\n",
        "\n",
        "def find_files(path, extensions=[\".txt\"], recursive=False):\n",
        "    # Recursively (optional) find all files with extension in path\n",
        "    my_files = []\n",
        "    for root, dirs, files in os.walk(path):\n",
        "        for f in files:\n",
        "            if extensions == []:\n",
        "                my_files.append(os.path.join(root, f))\n",
        "            else:\n",
        "                for ext in extensions:\n",
        "                    if f.endswith(ext):\n",
        "                        my_files.append(os.path.join(root, f))\n",
        "        # no recursion / don't look inside any subdirectory\n",
        "        if recursive == False:\n",
        "            break\n",
        "    return my_files\n",
        "\n",
        "\n",
        "def merge_textfiles(path, extensions=[\".txt\"], recursive=False, new_filename='merged.txt'):\n",
        "    # Recursively (optional) find all files with extension in path\n",
        "    my_files = find_files(path, extensions, recursive)\n",
        "    merged_text = ''\n",
        "    for filename in my_files:\n",
        "      # print(filename)\n",
        "      f= open(filename,'r')\n",
        "      if f.mode == 'r':\n",
        "            contents =f.read()\n",
        "      f.close()\n",
        "      merged_text = merged_text + contents + '\\n\\n\\n'\n",
        "\n",
        "    f= open(new_filename,'w+')\n",
        "    f.write(merged_text)\n",
        "    f.close()"
      ],
      "metadata": {
        "id": "dydmkY6_SZeG"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1. Create MD Files"
      ],
      "metadata": {
        "id": "A5nBZppW-bt3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if ios_mode == False:\n",
        "  import re\n",
        "  import hashlib\n",
        "  from dateutil.parser import parse\n",
        "  import os\n",
        "  from datetime import datetime, timedelta, timezone\n",
        "  import getpass\n",
        "  import sys\n",
        "  import dateparser\n",
        "  import json\n",
        "\n",
        "  infile = folders['clippings-input'] + '/My Clippings.txt'\n",
        "  infile_fixed = folders['clippings-input'] + '/My Clippings-fixed.txt'\n",
        "  outpath = folders['clippings-output'] + '/'\n",
        "\n",
        "  create_file_directory(folders['clippings-input'], False)\n",
        "  create_file_directory(folders['clippings-output'], True)\n",
        "\n",
        "  f= open(infile,'r')\n",
        "  if f.mode == 'r':\n",
        "        contents =f.read()\n",
        "  f.close()\n",
        "  contents2 = contents.replace(chr(65279), \"\")\n",
        "  f= open(infile_fixed,'w+')\n",
        "  f.write(contents2)\n",
        "  f.close()\n",
        "\n",
        "\n",
        "  def getvalidfilename(filename):\n",
        "      import unicodedata\n",
        "      clean = unicodedata.normalize('NFKD', filename)\n",
        "      cleaned_filename = re.sub('[()\\'\\?\\!:&]', '', clean) #^\\w\\s\n",
        "      return cleaned_filename\n",
        "\n",
        "\n",
        "  note_sep = '=========='\n",
        "\n",
        "  commentstr = '.. '  # RST (reStructuredText) comment\n",
        "\n",
        "  # EN Clipboard\n",
        "  #regex_title = re.compile('^(.*)\\((.*)\\)$')\n",
        "  #regex_info = re.compile(r'^- (\\S+) (.*)[\\s|]+Added on\\s+(.+)$')\n",
        "  #regex_loc = re.compile('Loc\\. ([\\d\\-]+)')\n",
        "  #regex_page = re.compile('Page ([\\d\\-]+)')\n",
        "  #regex_date = re.compile('Added on\\s+(.+)$')\n",
        "\n",
        "  # DE Clipboard\n",
        "  regex_title = re.compile('^(.*)\\((.*)\\)$')\n",
        "  regex_info = re.compile(r'^- (\\S+) (.*)[\\s|]+Hinzugefügt am\\s+(.+)$')\n",
        "  regex_loc = re.compile('bei Position ([\\d\\-]+)')\n",
        "  regex_page = re.compile('Seite ([\\d\\-]+)')\n",
        "  regex_date = re.compile('Hinzugefügt am\\s+(.+)$')\n",
        "\n",
        "  regex_hashline = re.compile('^\\.\\.\\s*([a-fA-F0-9]+)' + '\\s*')\n",
        "\n",
        "\n",
        "  pub_title = {}\n",
        "  pub_author = {}\n",
        "  pub_notes = {}\n",
        "  pub_hashes = {}\n",
        "\n",
        "  notes = {}\n",
        "  locations = {}\n",
        "  types = {}\n",
        "  dates = {}\n",
        "\n",
        "  existing_hashes = {}\n",
        "\n",
        "  print('Scanning output dir', outpath)\n",
        "  for directory, subdirlist, filelist in os.walk(outpath):\n",
        "      for fname in filelist:\n",
        "          ext = fname[-4:]\n",
        "          if ext == '.rst' or ext == '.RST':\n",
        "              print('Found RST file', fname, 'in directory', directory)\n",
        "              # open file, find commend lines, store hashes\n",
        "              rst = open(directory + '/' + fname, 'r')\n",
        "              line = rst.readline()\n",
        "              lines = 0\n",
        "              hashes = 0\n",
        "              while line:\n",
        "                  lines += 1\n",
        "                  findhash_result = regex_hashline.findall(line)\n",
        "                  if len(findhash_result):\n",
        "                      foundhash = findhash_result[0]\n",
        "                      existing_hashes[foundhash] = fname\n",
        "                      hashes += 1\n",
        "                  line = rst.readline()\n",
        "              rst.close()\n",
        "              print(hashes, 'hashes found in', lines, 'scanned lines')\n",
        "          else:\n",
        "              print('File', fname, 'does not seem to be RST, skipping', ext)\n",
        "\n",
        "  print('Found', len(existing_hashes), 'existing note hashes')\n",
        "  print('Processing clippings file', infile)\n",
        "\n",
        "  mc = open(infile_fixed, 'r')\n",
        "\n",
        "  mc.read(0)  # Was initially: mc.read(1) Skip first character - not necessary? Fixed with 0\n",
        "\n",
        "  line = mc.readline().strip()\n",
        "\n",
        "  all_notes = []\n",
        "\n",
        "  while line:\n",
        "\n",
        "      key = line.strip()\n",
        "      result_title = regex_title.findall(key)    # Extract title and author\n",
        "      line = mc.readline().strip()                # Read information line\n",
        "      note_type, location, date = regex_info.findall(line)[0]    # Extract note type, location and date\n",
        "      result_loc = regex_loc.findall(location)\n",
        "      result_page = regex_page.findall(location)\n",
        "      if len(result_title):\n",
        "          title, author = result_title[0]\n",
        "      else:\n",
        "          title = key\n",
        "          author = 'Unknown'\n",
        "\n",
        "      if len(result_loc):\n",
        "          note_loc = result_loc[0]\n",
        "      else:\n",
        "          note_loc = ''\n",
        "\n",
        "      if len(result_page):\n",
        "          note_page = result_page[0]\n",
        "      else:\n",
        "          note_page = ''\n",
        "\n",
        "      note_text = ''\n",
        "      line = mc.readline()                # Skip empty line\n",
        "      line = mc.readline().strip()\n",
        "\n",
        "      while line != note_sep:\n",
        "          note_text += line + '\\n'\n",
        "          line = mc.readline().strip()\n",
        "\n",
        "      note_hash = hashlib.sha256(note_text.strip().encode('utf8')).hexdigest()[:8]\n",
        "\n",
        "      if key not in pub_notes:\n",
        "          pub_notes[key] = []\n",
        "          pub_hashes[key] = []\n",
        "\n",
        "      pub_title[key] = title.strip()\n",
        "      pub_author[key] = author.strip()\n",
        "      pub_notes[key].append(note_text.strip())\n",
        "      pub_hashes[key].append(note_hash)\n",
        "\n",
        "      locstr = ''\n",
        "      if note_loc:\n",
        "          locstr = 'loc.' + note_loc\n",
        "      if note_page:\n",
        "          if note_loc:\n",
        "              locstr += ', '\n",
        "          locstr += 'p.' + note_page\n",
        "\n",
        "      try:\n",
        "          #datestr = str(parse(date)) # works only for US dates\n",
        "          datestr = str(dateparser.parse(date)) # , languages=['de']\n",
        "      except:\n",
        "          datestr = date\n",
        "          print(\"Date parsing exception: \" + date)\n",
        "\n",
        "      notes[note_hash] = note_text.strip()\n",
        "      locations[note_hash] = locstr\n",
        "      types[note_hash] = note_type\n",
        "      dates[note_hash] = datestr\n",
        "\n",
        "      line = mc.readline().strip()\n",
        "\n",
        "      data = {}\n",
        "      data['hash'] = note_hash\n",
        "      data['title'] = title.strip()\n",
        "      data['author'] = author.strip()\n",
        "      data['date'] = datestr\n",
        "      data['note_text'] = note_text.strip()\n",
        "      all_notes.append(data)\n",
        "\n",
        "  mc.close()\n",
        "\n",
        "  for key in pub_title.keys():\n",
        "      nr_notes = len(pub_notes[key])\n",
        "      author = pub_author[key]\n",
        "      title = pub_title[key]\n",
        "      short_title = title.split('|')[0]\n",
        "      short_title = short_title.split(' - ')[0]\n",
        "      short_title = short_title.split('. ')[0]\n",
        "      # shorten title for filename\n",
        "      if len(short_title) > 25:\n",
        "          short_title = short_title[:24]\n",
        "\n",
        "      fname = author + ' - ' + short_title.strip() + '.rst'\n",
        "      short = 0\n",
        "      #if (nr_notes > 2):\n",
        "      #    fname = author + ' - ' + short_title.strip() + '.rst'\n",
        "      #    short = 0\n",
        "      #else:\n",
        "      #    fname = 'short_notes.rst'\n",
        "      #    short = 1\n",
        "\n",
        "      new_hashes = 0\n",
        "      for note_hash in pub_hashes[key]:\n",
        "          note_date = dateparser.parse(dates[note_hash])\n",
        "          days_old = (datetime.now() - note_date).days\n",
        "          #print(str(note_date) + \"/\" + str(days_old))\n",
        "          if (note_hash not in existing_hashes) and (days_old < max_days_old):\n",
        "              new_hashes += 1\n",
        "\n",
        "      if new_hashes > 0:\n",
        "          print(new_hashes, 'new notes found for', title)\n",
        "      else:\n",
        "          continue            # Skip to next title if there are no new hashes\n",
        "\n",
        "      outfile = os.path.join(outpath, getvalidfilename(fname))\n",
        "\n",
        "      newfile = os.path.isfile(outfile)\n",
        "\n",
        "      out = open(outfile, 'a')\n",
        "\n",
        "      if short:\n",
        "          # Short note, output a small header and append to short note file\n",
        "          if author != 'Unknown':\n",
        "              titlestr = author + ' - ' + title\n",
        "          else:\n",
        "              titlestr = title\n",
        "          out.write(titlestr + '\\n')\n",
        "          out.write(('-' * len(titlestr)) + '\\n\\n')\n",
        "      elif not newfile:\n",
        "          # Many notes, output with header and metadata in a separate file\n",
        "          titlestr = title # 'Highlights from ' +\n",
        "          out.write(titlestr + '\\n')\n",
        "          out.write(('=' * len(titlestr)) + '\\n\\n')\n",
        "          if author != 'Unknown':\n",
        "              out.write(author + '\\n\\n') # 'Authors: ' +\n",
        "          #out.write('Recommended By:: \\nTags:: [[Books]]\\n\\n# ' + title + '\\n\\n### Highlights\\n')\n",
        "          # out.write('## ' + title + '\\n\\n')\n",
        "          out.write('## Highlights\\n')\n",
        "\n",
        "      last_date = datetime.now()\n",
        "\n",
        "      for note_hash in pub_hashes[key]:\n",
        "          note = notes[note_hash]\n",
        "          note_type = types[note_hash]\n",
        "          note_date = dates[note_hash]\n",
        "          note_loc = locations[note_hash]\n",
        "          if note_hash in existing_hashes:\n",
        "              print('Note', note_hash, 'is already in', existing_hashes[note_hash])\n",
        "          else:\n",
        "              print('Adding new note to', outfile + ':', note_hash, note_type, note_loc, note_date)\n",
        "\n",
        "              comment = str(commentstr + note_hash + ' ; ' + note_type + ' ; ' + note_loc + ' ; ' + note_date)\n",
        "\n",
        "              if short:\n",
        "                  comment += ' ; ' + author + ' ; ' + title\n",
        "\n",
        "              # this adds metadata before each note.\n",
        "              # out.write(comment + '\\n\\n')\n",
        "              out.write('- ' + note + '\\n')\n",
        "          try:\n",
        "              #last_date = parse(note_date) # works only for US dates\n",
        "              last_date = dateparser.parse(note_date)\n",
        "          except:\n",
        "              pass\n",
        "\n",
        "      out.close()\n",
        "\n",
        "      # Update file modification time to time of last note\n",
        "\n",
        "      if last_date.tzinfo is None or last_date.tzinfo.utcoffset(last_date) is None:\n",
        "          epoch = datetime(1970, 1, 1)\n",
        "      else:\n",
        "          epoch = datetime(1970, 1, 1, tzinfo=timezone.utc)\n",
        "      note_timestamp = (last_date - epoch) / timedelta(seconds=1)\n",
        "      os.utime(outfile, (note_timestamp, note_timestamp))\n",
        "\n",
        "      # Write all_notes.md\n",
        "      merge_textfiles(folders['clippings-output'], ['.rst'], False, folders['clippings-output'] + '/all_notes.md')\n",
        "\n",
        "      # Write all_notes.json\n",
        "      all_notes_json = json.dumps(all_notes, sort_keys=False, indent=2)\n",
        "      f= open(folders['clippings-output'] + '/all_notes.json','w+')\n",
        "      f.write(all_notes_json)\n",
        "      f.close()\n",
        "\n",
        "      shutil.make_archive(outpath + 'archive', 'zip', outpath)\n",
        "\n",
        "else:\n",
        "  print('iOS Mode - Nothing to do.')"
      ],
      "metadata": {
        "id": "xK8-6hL0eIIE",
        "outputId": "3778a663-0a91-4939-9069-a585827e6376",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Scanning output dir out/\n",
            "Found 0 existing note hashes\n",
            "Processing clippings file in/My Clippings.txt\n",
            "4 new notes found for ChatGPT for Better Business Communication: How to Use ChatGPT to Increase Productivity and Communicate More Effectively at Work (ChatGPT prompts, tips, and examples that help you in the workplace)\n",
            "Adding new note to out/Osman, Hassan - ChatGPT for Better Busin.rst: 207abae3 Deine loc.198-206, p.13 2023-07-10 08:42:25\n",
            "Adding new note to out/Osman, Hassan - ChatGPT for Better Busin.rst: 6a6bd197 Deine loc.264-267, p.18 2023-07-12 08:42:41\n",
            "Adding new note to out/Osman, Hassan - ChatGPT for Better Busin.rst: 36b510f9 Deine loc.319-323, p.22 2023-07-14 08:43:08\n",
            "Adding new note to out/Osman, Hassan - ChatGPT for Better Busin.rst: dd754ee1 Deine loc.380-383, p.25 2023-07-24 08:45:30\n",
            "3 new notes found for Don't Reply All: 18 Email Tactics That Help You Write Better Emails and Improve Communication with Your Team\n",
            "Adding new note to out/Osman, Hassan - Dont Reply All 18 Emai.rst: ce686d39 Deine loc.163-168, p.14 2023-07-16 08:43:32\n",
            "Adding new note to out/Osman, Hassan - Dont Reply All 18 Emai.rst: fc46f1da Deine loc.241-248, p.21 2023-07-18 08:43:47\n",
            "Adding new note to out/Osman, Hassan - Dont Reply All 18 Emai.rst: dcd5739e Deine loc.258-262, p.22 2023-07-20 08:44:17\n",
            "1 new notes found for DIE WELT\n",
            "Adding new note to out/WELT GRUPPE - DIE WELT.rst: ba66ffc1 Deine loc.463-467 2023-07-06 08:45:06\n",
            "1 new notes found for O'Loughlin & Ruiz 02 - Amnesie - Michael Robotham\n",
            "Adding new note to out/Robotham, Michael - OLoughlin  Ruiz 02.rst: 35bafbe3 Deine loc.4727-4730 2023-07-26 17:37:42\n",
            "1 new notes found for Write Your Book on the Side: How to Write and Publish Your First Nonfiction Kindle Book While Working a Full-Time Job (Even if You Don’t Have a Lot of Time and Don’t Know Where to Start)\n",
            "Adding new note to out/Osman, Hassan - Write Your Book on the S.rst: cc0900da Deine loc.188-191, p.16 2023-07-28 18:14:43\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Test array / JSON\n",
        "\n",
        "query_title = 'DIE WELT'\n",
        "query_title = 'ChatGPT for Better Business Communication: How to Use ChatGPT to Increase Productivity and Communicate More Effectively at Work (ChatGPT prompts, tips, and examples that help you in the workplace)'\n",
        "\n",
        "search_result = [element for element in all_notes if element['title'] == query_title]\n",
        "# search_result = list(filter(lambda mynote: mynote['title'] == query_title, all_notes))\n",
        "print(json.dumps(search_result , sort_keys=False, indent=2))\n",
        "json_data = json.dumps(all_notes)\n",
        "#print(json_data)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BkVpIsQHjGIn",
        "outputId": "06bd89c6-90c5-4caf-c0a4-04f3ac504c7d"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[\n",
            "  {\n",
            "    \"hash\": \"207abae3\",\n",
            "    \"title\": \"ChatGPT for Better Business Communication: How to Use ChatGPT to Increase Productivity and Communicate More Effectively at Work (ChatGPT prompts, tips, and examples that help you in the workplace)\",\n",
            "    \"author\": \"Osman, Hassan\",\n",
            "    \"date\": \"2023-07-10 08:42:25\",\n",
            "    \"note_text\": \"How ChatGPT works ChatGPT is a type of language model, which means that it is trained to predict the next word or phrase in a given context. To do this, ChatGPT is fed a large dataset of human-generated text, which it uses to learn the patterns and structures of natural language. Once it has been trained, ChatGPT can then generate text that is coherent and engaging and is often difficult to distinguish from text written by a human. One of the main capabilities of ChatGPT is its ability to generate text on a wide range of topics. This makes it a useful tool for working professionals, as it can assist with brainstorming and idea generation, as well as generating text and revising content. ChatGPT can also help with drafting agendas, summarizing meetings, and writing better emails.\"\n",
            "  },\n",
            "  {\n",
            "    \"hash\": \"6a6bd197\",\n",
            "    \"title\": \"ChatGPT for Better Business Communication: How to Use ChatGPT to Increase Productivity and Communicate More Effectively at Work (ChatGPT prompts, tips, and examples that help you in the workplace)\",\n",
            "    \"author\": \"Osman, Hassan\",\n",
            "    \"date\": \"2023-07-12 08:42:41\",\n",
            "    \"note_text\": \"Example 1: Modify the tone Prompt: Change the tone of this paragraph so that it sounds more friendly: \\\"Your request for an extension on the project deadline was received. It is important to note that we have strict policies regarding deadlines, and we expect them to be met. Failure to do so can result in serious consequences.\\\"\"\n",
            "  },\n",
            "  {\n",
            "    \"hash\": \"36b510f9\",\n",
            "    \"title\": \"ChatGPT for Better Business Communication: How to Use ChatGPT to Increase Productivity and Communicate More Effectively at Work (ChatGPT prompts, tips, and examples that help you in the workplace)\",\n",
            "    \"author\": \"Osman, Hassan\",\n",
            "    \"date\": \"2023-07-14 08:43:08\",\n",
            "    \"note_text\": \"ChatGPT can help you come up with some ideas for writing clear and concise meeting agendas. Here are a few examples that show you how powerful this is and how it can save you some time. Example 1: Create a sample agenda Prompt: Draft a short agenda to give a project status update to a team. The duration of the meeting is 30 minutes.\"\n",
            "  },\n",
            "  {\n",
            "    \"hash\": \"dd754ee1\",\n",
            "    \"title\": \"ChatGPT for Better Business Communication: How to Use ChatGPT to Increase Productivity and Communicate More Effectively at Work (ChatGPT prompts, tips, and examples that help you in the workplace)\",\n",
            "    \"author\": \"Osman, Hassan\",\n",
            "    \"date\": \"2023-07-24 08:45:30\",\n",
            "    \"note_text\": \"Example 3: Write an email follow-up regarding the agenda Prompt:\\u00a0Write a short email to the team summarizing the objective of the meeting and include a shorter version of the agenda. Stress that everyone should come prepared to the meeting.\"\n",
            "  }\n",
            "]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2. Create JSON File"
      ],
      "metadata": {
        "id": "joDRxBiIgZWM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re, json, sys, io, argparse\n",
        "from time import strptime\n",
        "from datetime import datetime\n",
        "from dateutil.tz import tzlocal\n",
        "\n",
        "\n",
        "DUMMY_AUTHOR = \"zznoauthor\" # Lower case to ensure it goes at the end.\n",
        "\n",
        "config_infile = folders['clippings-input'] + '/My Clippings.txt'\n",
        "DEFAULT_IN = \"in/My Clippings.txt\"      # clippings file\n",
        "DEFAULT_OUT = \"out/clippings.json\"      # output file\n",
        "DEFAULT_SUB = \"in/subs.json\"            # substitute authors/titles\n",
        "DEFAULT_COMBINE = \"in/combine.json\"     # existing quotes to combine with output\n",
        "DEFAULT_TIMEZONE = tzlocal()            # timezone for quote timestamps: note this assumes the system timezone because the kindle doesn't store this information\n",
        "\n",
        "PROG_USAGE = 'python clippings.py '+\\\n",
        "        '[-i <input.txt>] '+\\\n",
        "        '[-o <output.json>] '+\\\n",
        "        '[-s [<substitute_file.json>]] '+\\\n",
        "        '[-c [<combine_file.json>]] ' +\\\n",
        "        '[-z]'\n",
        "\n",
        "def do_clippings():\n",
        "    \"\"\"\n",
        "        Wrapper\n",
        "    \"\"\"\n",
        "\n",
        "    ## 1. Get user input\n",
        "    # f_in,f_out,f_substitute,f_combine, f_timezone = parse_arguments()\n",
        "    f_in = open(DEFAULT_IN,\"r\",encoding='utf-8')\n",
        "    f_out = io.open(DEFAULT_OUT,\"w\",encoding='utf-8')\n",
        "    f_substitute = open(DEFAULT_SUB,\"r\",encoding='utf-8')\n",
        "    f_combine = DEFAULT_COMBINE\n",
        "    f_timezone = DEFAULT_TIMEZONE\n",
        "\n",
        "    ## 2. Log\n",
        "    print(\"Extracting clippings from \"+f_in.name)\n",
        "\n",
        "    ## 3. Get raw clippings\n",
        "    #with open(f_in,\"r\",encoding='utf-8') as f:\n",
        "    #    raw = f.read()\n",
        "    raw = f_in.read()\n",
        "    f_in.close()\n",
        "\n",
        "    ## 4. Parse into dictionary\n",
        "    dict_all = parse_raw(raw)\n",
        "\n",
        "    ## 5. Organise the dictionary\n",
        "    dict_all = organise(dict_all,f_timezone)\n",
        "\n",
        "    ## 6. Make substitutions if necessary\n",
        "    if f_substitute:\n",
        "        dict_all = substitute(dict_all,f_substitute)\n",
        "\n",
        "    ## 7. Combine if necessary\n",
        "    if f_combine:\n",
        "        dict_all = combine(dict_all,f_combine)\n",
        "\n",
        "    ## 8. Output the dictionary\n",
        "    output(dict_all,f_out)\n",
        "\n",
        "def parse_arguments():\n",
        "    \"\"\"\n",
        "        Controls how the script deals with command-line arguments.\n",
        "    \"\"\"\n",
        "\n",
        "    parser = argparse.ArgumentParser( # See https://docs.python.org/3.7/library/argparse.html\n",
        "                description='Convert Kindle clippings to JSON format.',\n",
        "                usage=PROG_USAGE)\n",
        "\n",
        "    ## Is there an input filepath specified manually?\n",
        "    parser.add_argument(\n",
        "            '-i',\n",
        "            nargs='?', # expects one argument after -i\n",
        "            const=DEFAULT_IN, # default if -i is provided but no file specified\n",
        "            default=DEFAULT_IN, # default if -i is not provided\n",
        "            help='TXT file of Kindle clippings. See README.md.',\n",
        "            type=argparse.FileType('r',encoding=\"utf-8\") # expect a filename\n",
        "            )\n",
        "\n",
        "    ## Is there an output filepath specified manually?\n",
        "    parser.add_argument(\n",
        "            '-o',\n",
        "            nargs='?', # expects one argument after -o\n",
        "            const=DEFAULT_OUT, # default if -o is provided but no file specified\n",
        "            default=DEFAULT_OUT, # default if -o is not provided\n",
        "            help='JSON file for output. See README.md for format.',\n",
        "            type=argparse.FileType('w',encoding=\"utf-8\") # expect a filename\n",
        "            )\n",
        "\n",
        "    ## Are we substituting author/book titles?\n",
        "    parser.add_argument(\n",
        "            '-s',\n",
        "            nargs='?', # expects one argument after -s\n",
        "            const=DEFAULT_SUB, # default if -s is provided but no file specified\n",
        "            default=None, # default if -s is not provided\n",
        "            help='JSON file specifying author/title substitutions. See README.md for correct format.',\n",
        "            type=argparse.FileType('r',encoding=\"utf-8\") # expect a filename\n",
        "            )\n",
        "\n",
        "    ## Are we combining quotes from an external file?\n",
        "    parser.add_argument(\n",
        "            '-c',\n",
        "            nargs='?', # expects one argument after -c\n",
        "            const=DEFAULT_COMBINE, # default if -c is provided but no file specified\n",
        "            default=None, # default if -c is not provided\n",
        "            help='JSON file specifying existing quotations to combine. See README.md for correct format.',\n",
        "            type=argparse.FileType('r',encoding=\"utf-8\") # expect a filename\n",
        "            )\n",
        "\n",
        "    ## Are we assigning the user's local timezone to timestamps?\n",
        "    parser.add_argument('-z', action='store_true',help=\"Flag: if set, the user's current timezone will be added to all timestamps.\")\n",
        "\n",
        "    args = parser.parse_args()\n",
        "\n",
        "    if args.z: args.z = DEFAULT_TIMEZONE # if the flag was set, switch to timezone\n",
        "\n",
        "    return args.i, args.o, args.s, args.c, args.z\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "    Primary functions:\n",
        "        parse_raw, organise, output\n",
        "\"\"\"\n",
        "def parse_raw(raw):\n",
        "    \"\"\"\n",
        "        Convert Kindle clippings text file to JSON and print to JSON file\n",
        "    \"\"\"\n",
        "\n",
        "    ## 1. Preprocessing e.g. byte order mark\n",
        "    raw = preprocess(raw)\n",
        "\n",
        "    ## 2. Get regular expressions\n",
        "    regex_author_str, regex_noauthor_str = build_regexes()\n",
        "\n",
        "    ## 3. Perform the regex for entries with an author\n",
        "    regex_author = re.compile(regex_author_str)\n",
        "    progress(\"Regex complete \",0,2)\n",
        "    dict_author = {\"notes_author\":regex_author.findall(raw)}\n",
        "\n",
        "    ## 4. Perform the regex for entries without an author\n",
        "    regex_noauthor = re.compile(regex_noauthor_str)\n",
        "    progress(\"Regex complete \",1,2)\n",
        "    dict_noauthor = {\"notes_noauthor\":regex_noauthor.findall(raw)}\n",
        "\n",
        "    ## 5. Create the dictionary\n",
        "    dict_all = dict_author\n",
        "    dict_all.update(dict_noauthor)\n",
        "\n",
        "    return dict_all\n",
        "\n",
        "\n",
        "def organise(dict,f_timezone=None):\n",
        "    \"\"\"\n",
        "        How do you want your JSON output organised?\n",
        "        The input looks like this:\n",
        "            {\n",
        "                notes_noauthor:     [\n",
        "                    [   <title>,\n",
        "                        Loc.|on Page,\n",
        "                        <loc or page>,\n",
        "                        <??>,\n",
        "                        <??>,\n",
        "                        <day name>,\n",
        "                        <month name>,\n",
        "                        <day number>,\n",
        "                        <year>,\n",
        "                        <hour>,\n",
        "                        <minute>,\n",
        "                        AM/PM,\n",
        "                        <quote>\n",
        "                    ],\n",
        "                    [...],[...]\n",
        "                ],\n",
        "                notes_author:       [\n",
        "                    [   <title>,\n",
        "                        <author>,\n",
        "                        Loc.|on Page,\n",
        "                        <loc or page>,\n",
        "                        <??>,\n",
        "                        <??>,\n",
        "                        <day name>,\n",
        "                        <month name>,\n",
        "                        <day number>,\n",
        "                        <year>,\n",
        "                        <hour>,\n",
        "                        <minute>,\n",
        "                        AM/PM,\n",
        "                        <quote>\n",
        "                    ],\n",
        "                    [...],[...]\n",
        "                ]\n",
        "            }\n",
        "        I want something like this:\n",
        "            {\n",
        "                \"Kate Chopin\": {\n",
        "                    \"The Awakening and Selected Short Stories\": {\n",
        "                        \"l1197\": [\n",
        "                            {\n",
        "                                \"date\": \"20180405-1257\",\n",
        "                                \"quote\": \"She had reached a stage when she seemed to be no longer feeling her way, working, when in the humor, with sureness and ease. And being devoid of ambition, and striving not toward accomplishment, she drew satisfaction from the work in itself.\"\n",
        "                            }\n",
        "                        ]\n",
        "                    }\n",
        "                }\n",
        "            }\n",
        "    \"\"\"\n",
        "\n",
        "    dict_new = {}\n",
        "\n",
        "    ## 1. Quotes with an author\n",
        "    i=0\n",
        "    total = len(dict[\"notes_author\"]) + len(dict[\"notes_noauthor\"])\n",
        "    for line in dict[\"notes_author\"]:\n",
        "\n",
        "        dict_line = build_dict_line(line,f_timezone)\n",
        "\n",
        "        dict_new = add_line_to_dict_deep(dict_new,dict_line)\n",
        "\n",
        "        progress(\"Author complete: \",i,total)\n",
        "        i+=1\n",
        "\n",
        "    ## 2. Quotes with no author\n",
        "    for line in dict[\"notes_noauthor\"]:\n",
        "        line2 = (line[0],DUMMY_AUTHOR)+line[1:]\n",
        "        dict_line = build_dict_line(line2,f_timezone)\n",
        "\n",
        "        dict_new = add_line_to_dict_deep(dict_new,dict_line)\n",
        "\n",
        "        progress(\"No author complete: \",i,total)\n",
        "        i+=1\n",
        "\n",
        "    ## 3. Pad location keys.\n",
        "    ##     See function comment text for explanation.\n",
        "    dict_new = pad_location_keys(dict_new)\n",
        "\n",
        "    return dict_new\n",
        "\n",
        "def substitute(dict_all, f_substitute):\n",
        "    \"\"\"\n",
        "        Substitute errant authors/titles with the correct ones.\n",
        "        Subs file should be a list of objects with form:\n",
        "            {\n",
        "                \"old\":  {\n",
        "                    \"author\":   \"Batchie\",\n",
        "                    \"title\":    \"Jose_Saramago_Seeing__\"\n",
        "                \"new\":  {\n",
        "                    \"author_new\":   \"José Saramago\",\n",
        "                    \"title_new\":    \"Seeing\"\n",
        "                }\n",
        "            }\n",
        "    \"\"\"\n",
        "\n",
        "    print(\"Substituting features from \"+f_substitute.name)\n",
        "\n",
        "    dict_subs = json.loads(f_substitute.read())\n",
        "    f_substitute.close()\n",
        "\n",
        "    for entry in dict_subs:\n",
        "        author = entry[\"old\"][\"author\"]\n",
        "        title = entry[\"old\"][\"title\"]\n",
        "        author_new = entry[\"new\"][\"author\"]\n",
        "        title_new = entry[\"new\"][\"title\"]\n",
        "\n",
        "        ## Create new entry\n",
        "        line={author_new:{title_new:dict_all[author][title]}}\n",
        "        add_line_to_dict_deep(dict_all,line)\n",
        "\n",
        "        ## Delete old entry\n",
        "        del dict_all[author][title]\n",
        "\n",
        "        ## Delete old author if empty\n",
        "        if len(dict_all[author]) < 1:\n",
        "            del dict_all[author]\n",
        "\n",
        "    return dict_all\n",
        "\n",
        "def combine(dict_all, f_combine):\n",
        "    \"\"\"\n",
        "        Combine quotes from file f_combine into dict_all.\n",
        "    \"\"\"\n",
        "\n",
        "    ## TODO\n",
        "    pass\n",
        "\n",
        "    return dict_all\n",
        "\n",
        "def output(dict_all,f_out=None):\n",
        "    \"\"\"\n",
        "        Print or file write\n",
        "    \"\"\"\n",
        "\n",
        "    if f_out:\n",
        "        #with io.open(f_out,\"w\",encoding='utf-8') as f:\n",
        "        #    f.write(\n",
        "        f_out.write(\n",
        "                json.dumps(     # convert dictionary to string and output\n",
        "                    dict_all,\n",
        "                    indent=4,\n",
        "                    sort_keys=True,\n",
        "                    ensure_ascii=False  # unicode characters\n",
        "                )\n",
        "            )\n",
        "\n",
        "        print(\"Output JSON to \"+f_out.name)\n",
        "        return\n",
        "\n",
        "    ## Else, output to STDOUT\n",
        "    print(json.dumps(dict_all))\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "    Helper functions\n",
        "\"\"\"\n",
        "\n",
        "def preprocess(raw):\n",
        "    \"\"\"\n",
        "        Basic text formatting e.g. BOM at start of file\n",
        "    \"\"\"\n",
        "\n",
        "\n",
        "    ## 1. Remove byte order marks if necessary\n",
        "\n",
        "    if raw[0]=='\\ufeff':\n",
        "        raw = raw[1:]\n",
        "\n",
        "    # if raw[0] == '\\xef':\n",
        "        # raw = raw[1:]\n",
        "\n",
        "    # if raw[0] == '\\xbb':\n",
        "        # raw = raw[1:]\n",
        "\n",
        "    # if raw[0] == '\\xbf':\n",
        "        # raw = raw[1:]\n",
        "\n",
        "    return raw\n",
        "\n",
        "\n",
        "def build_regexes():\n",
        "    \"\"\"\n",
        "        Create regular expressions to extract quote data.\n",
        "    \"\"\"\n",
        "\n",
        "\n",
        "    ## 1. Regex parts\n",
        "    title_regex = \"(.+)\"\n",
        "    title_author_regex = \"(.+) \\((.+)\\)\"\n",
        "\n",
        "    ## 2. Regex locations\n",
        "    loc_all_regex = \"(Loc.|on Page) ([0-9]+)( |-([0-9]+)  )\"\n",
        "\n",
        "    ## 3. Regex date and time\n",
        "    date_regex = \"([a-zA-Z]+), ([a-zA-Z]+) ([0-9]+), ([0-9]+)\"  # Date\n",
        "    time_regex = \"([0-9]+):([0-9]+) (AM|PM)\"  # Time\n",
        "\n",
        "    ## 4. Regex quote\n",
        "    content_regex = \"(.*)\"\n",
        "    footer_regex = \"=+\"\n",
        "\n",
        "    ## 5. Regex newline\n",
        "    nl_re = \"\\n*\"\n",
        "\n",
        "    ## 6. Regex quotes with an author\n",
        "    regex_author_str =\\\n",
        "    title_author_regex + nl_re +\\\n",
        "    \"- Highlight \" + loc_all_regex + \"\\| Added on \" +\\\n",
        "    date_regex + \", \" + time_regex + nl_re +\\\n",
        "    content_regex + nl_re +\\\n",
        "    footer_regex\n",
        "\n",
        "    ## 7. Regex quotes with no author\n",
        "    regex_noauthor_str =\\\n",
        "    title_regex + nl_re +\\\n",
        "    \"- Highlight \" + loc_all_regex + \"\\| Added on \" +\\\n",
        "    date_regex + \", \" + time_regex + nl_re +\\\n",
        "    content_regex + nl_re +\\\n",
        "    footer_regex\n",
        "\n",
        "    return regex_author_str,regex_noauthor_str\n",
        "\n",
        "\n",
        "def build_dict_line(line,f_timezone=None):\n",
        "    \"\"\"\n",
        "        Convert the line to the new format.\n",
        "        The current order is:\n",
        "            0 <title>,\n",
        "            1 <author>,\n",
        "            2 \"Loc.\" or \"on Page\",\n",
        "            3 <loc> or <page>,\n",
        "            4 <??>,\n",
        "            5 <??>,\n",
        "            6 <day>,\n",
        "            7 <month>,\n",
        "            8 <date>,\n",
        "            9 <year>,\n",
        "            10 <hour>,\n",
        "            11 <minute>,\n",
        "            12 \"AM\" or \"PM\",\n",
        "            13 <quote>\n",
        "        New format:\n",
        "            {\n",
        "                \"Ursula K. Le Guin\":  {\n",
        "                    \"Tales from Earthsea\":   {\n",
        "                        \"l1321\": [\n",
        "                            {\n",
        "                                \"date\": \"20170618-1726\",\n",
        "                                \"quote\": \"The wizard kept the name Roke in his memory, and when he heard it again, and in the same connection, he knew Hound had been on a true track again.\"\n",
        "                            }\n",
        "                        ],\n",
        "                    }\n",
        "                }\n",
        "            }\n",
        "    \"\"\"\n",
        "\n",
        "    ## 1. Quote\n",
        "    ##  Add formatting here if necessary.\n",
        "    quote = line[13]\n",
        "\n",
        "    ## 2. Timestamp\n",
        "    # # line[9]\n",
        "    # # line[7]\n",
        "    # # line[8]\n",
        "    # # line[10]\n",
        "    # # line[11] # minute\n",
        "    # # line[12] # AM/PM\n",
        "    year = int(line[9])                             # year\n",
        "    month = int(strptime(line[7][:3],'%b').tm_mon)  # month (in words)\n",
        "    day = int(line[8])                              # day\n",
        "    hour = int(line[10])                            # hour\n",
        "    if line[12] == \"PM\":                            # fix for 24 hour clock\n",
        "        hour = (hour + 12) % 24\n",
        "    minute = int(line[11])                          # minute\n",
        "\n",
        "    ## Quote object is quote with timestamp.\n",
        "    ## Timestamp might have a timezone assigned, or might be naive.\n",
        "    if f_timezone:\n",
        "        date = datetime(year,month,day,hour,minute,tzinfo=f_timezone)     # full date, with timezone\n",
        "    else:\n",
        "        date = datetime(year,month,day,hour,minute)     # full date, naive\n",
        "\n",
        "    ## 3. Page/location format\n",
        "    if line[2] == \"on Page\":\n",
        "        loc = \"p\"\n",
        "    elif line[2] == \"Loc.\":\n",
        "        loc = \"l\"\n",
        "    else:\n",
        "        loc = \"\"\n",
        "\n",
        "    loc = loc + str(line[3]) # combine location prefix with location.\n",
        "\n",
        "    ## 4. Author format\n",
        "    author = line[1]\n",
        "    author = author.replace('\\\\','') # Remove backslashes\n",
        "\n",
        "    ## 5. Build line.\n",
        "    ## Timestamp will ignore the \"%z\" part of the format declaration\n",
        "    ##  if no timezone has been assigned.\n",
        "    dict_line = {\n",
        "        author:{\n",
        "            line[0]:{ # title\n",
        "                loc:[\n",
        "                    {\"quote\":quote,\"date\":date.strftime(\"%Y-%m-%dT%H:%M%z\")}\n",
        "                ]\n",
        "            }\n",
        "        }\n",
        "    }\n",
        "\n",
        "    return dict_line\n",
        "\n",
        "\n",
        "def add_line_to_dict_deep(d,line):\n",
        "    \"\"\"\n",
        "        The dict looks like:\n",
        "            {\n",
        "                \"John Updike\": {\n",
        "                    \"Rabbit, Run\": {\n",
        "                        \"l4467\": [{\n",
        "                                \"date\": \"20171011-2249\",\n",
        "                                \"quote\": \"Two thoughts comfort him, let a little light through the dense pack of impossible alternatives. Ruth has parents, and she will let his baby live: two thoughts that are perhaps the same thought, the vertical order of parenthood, a kind of thin tube upright in time in which our solitude is somewhat diluted.\"\n",
        "                            }\n",
        "                        ]\n",
        "                    }\n",
        "                },\n",
        "            ...\n",
        "            }\n",
        "        So we need to check the title and location to make sure it's not overwritten.\n",
        "    \"\"\"\n",
        "\n",
        "    ## 1. Initialise\n",
        "    author      = list(line.keys())[0]\n",
        "    title       = list(line[author].keys())[0]\n",
        "    location    = list(line[author][title].keys())[0]\n",
        "\n",
        "\n",
        "    if author not in d:\n",
        "        ## 2. Author not yet added.\n",
        "        d.update(line)\n",
        "        return d\n",
        "\n",
        "    if title not in d[author]:\n",
        "        ## 3. Title not yet added.\n",
        "        d[author].update(line[author])\n",
        "        return d\n",
        "\n",
        "    if location not in d[author][title]:\n",
        "        ## 4. Location not yet added.\n",
        "        d[author][title].update(line[author][title])\n",
        "        return d\n",
        "\n",
        "    ## 5. The location is already there (should be impossible for Locs, rare for Pages)\n",
        "    ## Just need to add the entry\n",
        "    d[author][title][location] += line[author][title][location]\n",
        "    return d\n",
        "\n",
        "\n",
        "def pad_location_keys(dict_new):\n",
        "    \"\"\"\n",
        "        Multiple locations for the same book may have different lengths,\n",
        "         which affects the correct ordering of quotes.\n",
        "        For example, \"l163\" should be earlier than \"l1466\", but JSON puts the latter first.\n",
        "        To fix this, we need to get the max length of location keys for each publication,\n",
        "         and pad all of that publication's location keys that are shorter\n",
        "         with leading zeros after the initial letter.\n",
        "    \"\"\"\n",
        "\n",
        "    for books in dict_new.values():\n",
        "        for key,book in books.items():\n",
        "            loc_length = longest_loc_length(book)\n",
        "            book_new = pad_locs(book,loc_length)\n",
        "            books[key] = book_new # can I do this within a loop??\n",
        "    return dict_new\n",
        "\n",
        "\n",
        "def longest_loc_length(book):\n",
        "    \"\"\"\n",
        "        Return the length of the longest location key string.\n",
        "    \"\"\"\n",
        "\n",
        "    loc_length = 0\n",
        "    for loc_string in book.keys():\n",
        "        if len(loc_string) > loc_length: loc_length = len(loc_string)\n",
        "\n",
        "    return loc_length\n",
        "\n",
        "\n",
        "def pad_locs(book,loc_length):\n",
        "    \"\"\"\n",
        "        Pad location keys as necessary\n",
        "    \"\"\"\n",
        "\n",
        "    book_new = {}\n",
        "    for key,value in book.items():\n",
        "        pad = loc_length - len(key) # how much we need to pad\n",
        "        newkey=key\n",
        "        while pad > 0:\n",
        "            newkey = newkey[0] + \"0\" + newkey[1:]\n",
        "            pad-=1\n",
        "        book_new[newkey] = value\n",
        "\n",
        "    return book_new\n",
        "\n",
        "\n",
        "def progress(message,step,total):\n",
        "    \"\"\"\n",
        "        Print progress.\n",
        "    \"\"\"\n",
        "\n",
        "    print(message+str(int(step*100/total))+\"%\", end=\"\\r\")\n",
        "\n",
        "\n",
        "do_clippings()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UJkb6y8VsHCK",
        "outputId": "e0f4cdd1-7c18-4553-cb1d-5041ee5254b9"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting clippings from in/My Clippings.txt\n",
            "Regex complete 0%\rRegex complete 50%\rSubstituting features from in/subs.json\n",
            "Output JSON to out/clippings.json\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPJDG8LZxtH/Y+ntLrjfEdB",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}