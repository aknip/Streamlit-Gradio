{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aknip/Streamlit-Gradio/blob/main/Kindle%20Clippings.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Kindle Clippings\n",
        "\n",
        "xxx\n",
        "\n",
        "## First run:\n",
        "\n",
        "Go to \"Setup and Configuration\" and check \"inital_setup_mode\". Then run all cells. Afterwards uncheck \"Setup and Configuration\"."
      ],
      "metadata": {
        "id": "Ht3Wkxk7Rpn_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Setup and Configuration"
      ],
      "metadata": {
        "id": "2goGpKmVRRUd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Settings\n",
        "\n",
        "# @markdown Default model\n",
        "default_model = 'GPT-3.5' # @param [\"GPT-3.5\", \"GPT-4\"]\n",
        "\n",
        "# @markdown Initial Setup Mode for pip install, fetch credentials etc.\n",
        "initial_setup_mode = False # @param {type:\"boolean\"}\n",
        "\n",
        "# @markdown Debug Mode for extensive logging.\n",
        "debug_mode = True # @param {type:\"boolean\"}\n",
        "\n",
        "# @markdown iOS Mode to develop helper functions, no Gradio.\n",
        "# @markdown Useful for development on iOS, eg. with Carnets App\n",
        "ios_mode = False # @param {type:\"boolean\"}"
      ],
      "metadata": {
        "id": "9NyekTkaGU3Z"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "folders = {\n",
        "    'audio': 'audio',\n",
        "    'audio-chunks': 'audio/chunks',\n",
        "    'transcript':'audio-transcript',\n",
        "    'transcript-chunks': 'audio-transcript/chunks',\n",
        "    'text-input': 'text-input',\n",
        "    'text-input-backup': 'text-input-backup'\n",
        "}"
      ],
      "metadata": {
        "id": "FBJns82oduIg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if ios_mode == False:\n",
        "  print('Mac')\n",
        "else:\n",
        "  print('iOS')"
      ],
      "metadata": {
        "id": "DRWVZHV1MOij",
        "outputId": "86935302-7bc2-43b0-9a1f-f35e8c5598dd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mac\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Wtw0CARBQhTQ",
        "outputId": "2741824e-6d1a-4c11-a244-a9b32f9d2c35",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No initial setup.\n"
          ]
        }
      ],
      "source": [
        "if initial_setup_mode == True:\n",
        "  !pip install openai==0.27.7 yt-dlp==2023.7.6 librosa==0.10.0.post2 pickle-mixin==1.0.2 langchain==0.0.225 PyPDF2==3.0.1 PyMuPDF==1.22.5 -q\n",
        "else:\n",
        "  print('No initial setup.')\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "if (initial_setup_mode == True) and (ios_mode == False) :\n",
        "  !pip install gradio -q\n",
        "else:\n",
        "  print('No initial setup / iOS.')"
      ],
      "metadata": {
        "id": "-TpG9Zr0IUU0",
        "outputId": "64051c1a-cb33-457a-ff37-5e3df1bc2343",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No initial setup / iOS.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "if (initial_setup_mode == True) and (ios_mode == False) :\n",
        "  %load_ext gradio\n",
        "else:\n",
        "  print('No initial setup / iOS.')"
      ],
      "metadata": {
        "id": "EyhkzcJ_Ob45",
        "outputId": "58812211-f831-4cef-df08-3859e11b3467",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No initial setup / iOS.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "if initial_setup_mode == True:\n",
        "  !wget -q bit.ly/aknip-colab-setup\n",
        "  %run aknip-colab-setup\n",
        "else:\n",
        "  print('No initial setup.')"
      ],
      "metadata": {
        "id": "eepWvnFN-yvj",
        "outputId": "3aff8ed6-84f3-4ea9-f085-362bb9d9ca64",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No initial setup.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "creds = json.loads(os.getenv('CREDS'))\n",
        "key = creds['OpenAI']['v2']['credential']\n",
        "# print(key)"
      ],
      "metadata": {
        "id": "iEwJ4-ShAt0v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Helper Functions\n",
        "\n",
        "- **create_file_directory**: Creates a new directory - if it not exists yet. The always_delete flag forces a deletion even if it exists."
      ],
      "metadata": {
        "id": "zO7UxoRjSWUy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import shutil\n",
        "import os\n",
        "\n",
        "def create_file_directory(directory, always_delete=False):\n",
        "  # Creates a new directory - if it not exists yet. The always_delete flag forces a deletion even if it exists.\n",
        "  # Examples:\n",
        "  # - create_file_directory('texts', False) => creates a new directory only if it not exists yet\n",
        "  # - create_file_directory('texts', True) => always deletes existing directory and creates a new one\n",
        "  if os.path.exists(directory):\n",
        "    if always_delete:\n",
        "      # delete the diectory recursively\n",
        "      shutil.rmtree(directory)\n",
        "  # create directory\n",
        "  if not os.path.exists(directory):\n",
        "    os.mkdir(directory)\n",
        "\n"
      ],
      "metadata": {
        "id": "dydmkY6_SZeG"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# The App"
      ],
      "metadata": {
        "id": "A5nBZppW-bt3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if ios_mode == False:\n",
        "  import re\n",
        "  import hashlib\n",
        "  from dateutil.parser import parse\n",
        "  import os\n",
        "  from datetime import datetime, timedelta, timezone\n",
        "  import getpass\n",
        "  import sys\n",
        "\n",
        "  infile = 'My Clippings.txt'\n",
        "  infile_fixed = 'My Clippings-fixed.txt'\n",
        "  outpath = 'clippings/'\n",
        "\n",
        "  f= open(infile,'r')\n",
        "  if f.mode == 'r':\n",
        "        contents =f.read()\n",
        "  f.close()\n",
        "  contents2 = contents.replace(chr(65279), \"\")\n",
        "  f= open(infile_fixed,'w+')\n",
        "  f.write(contents2)\n",
        "  f.close()\n",
        "\n",
        "  create_file_directory('clippings', True)\n",
        "\n",
        "  def getvalidfilename(filename):\n",
        "      import unicodedata\n",
        "      clean = unicodedata.normalize('NFKD', filename)\n",
        "      return re.sub('[^\\w\\s()\\'.?!:-]', '', clean)\n",
        "\n",
        "\n",
        "  note_sep = '=========='\n",
        "\n",
        "  commentstr = '.. '  # RST (reStructuredText) comment\n",
        "\n",
        "  #regex_title = re.compile('^(.*)\\((.*)\\)$')\n",
        "  #regex_info = re.compile(r'^- (\\S+) (.*)[\\s|]+Added on\\s+(.+)$')\n",
        "  #regex_loc = re.compile('Loc\\. ([\\d\\-]+)')\n",
        "  #regex_page = re.compile('Page ([\\d\\-]+)')\n",
        "  #regex_date = re.compile('Added on\\s+(.+)$')\n",
        "\n",
        "  regex_title = re.compile('^(.*)\\((.*)\\)$')\n",
        "  regex_info = re.compile(r'^- (\\S+) (.*)[\\s|]+Hinzugefügt am\\s+(.+)$')\n",
        "  regex_loc = re.compile('bei Position ([\\d\\-]+)')\n",
        "  regex_page = re.compile('Seite ([\\d\\-]+)')\n",
        "  regex_date = re.compile('Hinzugefügt am\\s+(.+)$')\n",
        "\n",
        "  regex_hashline = re.compile('^\\.\\.\\s*([a-fA-F0-9]+)' + '\\s*')\n",
        "\n",
        "\n",
        "  pub_title = {}\n",
        "  pub_author = {}\n",
        "  pub_notes = {}\n",
        "  pub_hashes = {}\n",
        "\n",
        "  notes = {}\n",
        "  locations = {}\n",
        "  types = {}\n",
        "  dates = {}\n",
        "\n",
        "  existing_hashes = {}\n",
        "\n",
        "  print('Scanning output dir', outpath)\n",
        "  for directory, subdirlist, filelist in os.walk(outpath):\n",
        "      for fname in filelist:\n",
        "          ext = fname[-4:]\n",
        "          if ext == '.rst' or ext == '.RST':\n",
        "              print('Found RST file', fname, 'in directory', directory)\n",
        "              # open file, find commend lines, store hashes\n",
        "              rst = open(directory + '/' + fname, 'r')\n",
        "              line = rst.readline()\n",
        "              lines = 0\n",
        "              hashes = 0\n",
        "              while line:\n",
        "                  lines += 1\n",
        "                  findhash_result = regex_hashline.findall(line)\n",
        "                  if len(findhash_result):\n",
        "                      foundhash = findhash_result[0]\n",
        "                      existing_hashes[foundhash] = fname\n",
        "                      hashes += 1\n",
        "                  line = rst.readline()\n",
        "              rst.close()\n",
        "              print(hashes, 'hashes found in', lines, 'scanned lines')\n",
        "          else:\n",
        "              print('File', fname, 'does not seem to be RST, skipping', ext)\n",
        "\n",
        "  print('Found', len(existing_hashes), 'existing note hashes')\n",
        "  print('Processing clippings file', infile)\n",
        "\n",
        "  mc = open(infile_fixed, 'r')\n",
        "\n",
        "  mc.read(0)  # Was initially: mc.read(1) Skip first character - not necessary? Fixed with 0\n",
        "\n",
        "  line = mc.readline().strip()\n",
        "\n",
        "  while line:\n",
        "\n",
        "      key = line.strip()\n",
        "      result_title = regex_title.findall(key)    # Extract title and author\n",
        "      line = mc.readline().strip()                # Read information line\n",
        "      note_type, location, date = regex_info.findall(line)[0]    # Extract note type, location and date\n",
        "      result_loc = regex_loc.findall(location)\n",
        "      result_page = regex_page.findall(location)\n",
        "      if len(result_title):\n",
        "          title, author = result_title[0]\n",
        "      else:\n",
        "          title = key\n",
        "          author = 'Unknown'\n",
        "\n",
        "      if len(result_loc):\n",
        "          note_loc = result_loc[0]\n",
        "      else:\n",
        "          note_loc = ''\n",
        "\n",
        "      if len(result_page):\n",
        "          note_page = result_page[0]\n",
        "      else:\n",
        "          note_page = ''\n",
        "\n",
        "      note_text = ''\n",
        "      line = mc.readline()                # Skip empty line\n",
        "      line = mc.readline().strip()\n",
        "\n",
        "      while line != note_sep:\n",
        "          note_text += line + '\\n'\n",
        "          line = mc.readline().strip()\n",
        "\n",
        "      note_hash = hashlib.sha256(note_text.strip().encode('utf8')).hexdigest()[:8]\n",
        "\n",
        "      if key not in pub_notes:\n",
        "          pub_notes[key] = []\n",
        "          pub_hashes[key] = []\n",
        "\n",
        "      pub_title[key] = title.strip()\n",
        "      pub_author[key] = author.strip()\n",
        "      pub_notes[key].append(note_text.strip())\n",
        "      pub_hashes[key].append(note_hash)\n",
        "\n",
        "      locstr = ''\n",
        "      if note_loc:\n",
        "          locstr = 'loc.' + note_loc\n",
        "      if note_page:\n",
        "          if note_loc:\n",
        "              locstr += ', '\n",
        "          locstr += 'p.' + note_page\n",
        "\n",
        "      try:\n",
        "          datestr = str(parse(date))\n",
        "      except:\n",
        "          datestr = date\n",
        "\n",
        "      notes[note_hash] = note_text.strip()\n",
        "      locations[note_hash] = locstr\n",
        "      types[note_hash] = note_type\n",
        "      dates[note_hash] = datestr\n",
        "\n",
        "      line = mc.readline().strip()\n",
        "\n",
        "  mc.close()\n",
        "\n",
        "  for key in pub_title.keys():\n",
        "      nr_notes = len(pub_notes[key])\n",
        "      author = pub_author[key]\n",
        "      title = pub_title[key]\n",
        "      short_title = title.split('|')[0]\n",
        "      short_title = short_title.split(' - ')[0]\n",
        "      short_title = short_title.split('. ')[0]\n",
        "      if len(short_title) > 128:\n",
        "          short_title = short_title[:127]\n",
        "\n",
        "      fname = author + ' - ' + short_title.strip() + '.rst'\n",
        "      short = 0\n",
        "      #if (nr_notes > 2):\n",
        "      #    fname = author + ' - ' + short_title.strip() + '.rst'\n",
        "      #    short = 0\n",
        "      #else:\n",
        "      #    fname = 'short_notes.rst'\n",
        "      #    short = 1\n",
        "\n",
        "      new_hashes = 0\n",
        "      for note_hash in pub_hashes[key]:\n",
        "          if note_hash not in existing_hashes:\n",
        "              new_hashes += 1\n",
        "\n",
        "      if new_hashes > 0:\n",
        "          print(new_hashes, 'new notes found for', title)\n",
        "      else:\n",
        "          continue            # Skip to next title if there are no new hashes\n",
        "\n",
        "      outfile = os.path.join(outpath, getvalidfilename(fname))\n",
        "\n",
        "      newfile = os.path.isfile(outfile)\n",
        "\n",
        "      out = open(outfile, 'a')\n",
        "\n",
        "      if short:\n",
        "          # Short note, output a small header and append to short note file\n",
        "          if author != 'Unknown':\n",
        "              titlestr = author + ' - ' + title\n",
        "          else:\n",
        "              titlestr = title\n",
        "          out.write(titlestr + '\\n')\n",
        "          out.write(('-' * len(titlestr)) + '\\n\\n')\n",
        "      elif not newfile:\n",
        "          # Many notes, output with header and metadata in a separate file\n",
        "          titlestr = 'Highlights from ' + title\n",
        "          out.write(titlestr + '\\n')\n",
        "          out.write(('=' * len(titlestr)) + '\\n\\n')\n",
        "          if author != 'Unknown':\n",
        "              out.write('Authors:: [[' + author + ']]' + '\\n')\n",
        "          out.write('Recommended By:: \\nTags:: [[Books]]\\n\\n# ' + title + '\\n\\n### Highlights\\n')\n",
        "\n",
        "      last_date = datetime.now()\n",
        "\n",
        "      for note_hash in pub_hashes[key]:\n",
        "          note = notes[note_hash]\n",
        "          note_type = types[note_hash]\n",
        "          note_date = dates[note_hash]\n",
        "          note_loc = locations[note_hash]\n",
        "          if note_hash in existing_hashes:\n",
        "              print('Note', note_hash, 'is already in', existing_hashes[note_hash])\n",
        "          else:\n",
        "              print('Adding new note to', outfile + ':', note_hash, note_type, note_loc, note_date)\n",
        "\n",
        "              comment = str(commentstr + note_hash + ' ; ' + note_type + ' ; ' + note_loc + ' ; ' + note_date)\n",
        "\n",
        "              if short:\n",
        "                  comment += ' ; ' + author + ' ; ' + title\n",
        "\n",
        "              # this adds metadata before each note.\n",
        "              # out.write(comment + '\\n\\n')\n",
        "              out.write('- ' + note + '\\n')\n",
        "          try:\n",
        "              last_date = parse(note_date)\n",
        "          except:\n",
        "              pass\n",
        "\n",
        "      out.close()\n",
        "\n",
        "      # Update file modification time to time of last note\n",
        "\n",
        "      if last_date.tzinfo is None or last_date.tzinfo.utcoffset(last_date) is None:\n",
        "          epoch = datetime(1970, 1, 1)\n",
        "      else:\n",
        "          epoch = datetime(1970, 1, 1, tzinfo=timezone.utc)\n",
        "      note_timestamp = (last_date - epoch) / timedelta(seconds=1)\n",
        "      os.utime(outfile, (note_timestamp, note_timestamp))\n",
        "\n",
        "      shutil.make_archive('archive', 'zip', outpath)\n",
        "\n",
        "else:\n",
        "  print('iOS Mode - Nothing to do.')"
      ],
      "metadata": {
        "id": "xK8-6hL0eIIE",
        "outputId": "dffbf692-e71f-4496-c649-58fde32430e5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Scanning output dir clippings/\n",
            "Found 0 existing note hashes\n",
            "Processing clippings file My Clippings.txt\n",
            "4 new notes found for ChatGPT for Better Business Communication: How to Use ChatGPT to Increase Productivity and Communicate More Effectively at Work (ChatGPT prompts, tips, and examples that help you in the workplace)\n",
            "Adding new note to clippings/Osman Hassan - ChatGPT for Better Business Communication: How to Use ChatGPT to Increase Productivity and Communicate More Effectively at Work.rst: 207abae3 Deine loc.198-206, p.13 Mittwoch, 2. August 2023 08:42:25\n",
            "Adding new note to clippings/Osman Hassan - ChatGPT for Better Business Communication: How to Use ChatGPT to Increase Productivity and Communicate More Effectively at Work.rst: 6a6bd197 Deine loc.264-267, p.18 Mittwoch, 2. August 2023 08:42:41\n",
            "Adding new note to clippings/Osman Hassan - ChatGPT for Better Business Communication: How to Use ChatGPT to Increase Productivity and Communicate More Effectively at Work.rst: 36b510f9 Deine loc.319-323, p.22 Mittwoch, 2. August 2023 08:43:08\n",
            "Adding new note to clippings/Osman Hassan - ChatGPT for Better Business Communication: How to Use ChatGPT to Increase Productivity and Communicate More Effectively at Work.rst: dd754ee1 Deine loc.380-383, p.25 Mittwoch, 2. August 2023 08:45:30\n",
            "3 new notes found for Don't Reply All: 18 Email Tactics That Help You Write Better Emails and Improve Communication with Your Team\n",
            "Adding new note to clippings/Osman Hassan - Don't Reply All: 18 Email Tactics That Help You Write Better Emails and Improve Communication with Your Team.rst: ce686d39 Deine loc.163-168, p.14 Mittwoch, 2. August 2023 08:43:32\n",
            "Adding new note to clippings/Osman Hassan - Don't Reply All: 18 Email Tactics That Help You Write Better Emails and Improve Communication with Your Team.rst: fc46f1da Deine loc.241-248, p.21 Mittwoch, 2. August 2023 08:43:47\n",
            "Adding new note to clippings/Osman Hassan - Don't Reply All: 18 Email Tactics That Help You Write Better Emails and Improve Communication with Your Team.rst: dcd5739e Deine loc.258-262, p.22 Mittwoch, 2. August 2023 08:44:17\n",
            "1 new notes found for DIE WELT\n",
            "Adding new note to clippings/WELT GRUPPE - DIE WELT.rst: ba66ffc1 Deine loc.463-467 Mittwoch, 2. August 2023 08:45:06\n",
            "1 new notes found for O'Loughlin & Ruiz 02 - Amnesie - Michael Robotham\n",
            "Adding new note to clippings/Robotham Michael - O'Loughlin  Ruiz 02.rst: 35bafbe3 Deine loc.4727-4730 Mittwoch, 2. August 2023 17:37:42\n",
            "1 new notes found for Write Your Book on the Side: How to Write and Publish Your First Nonfiction Kindle Book While Working a Full-Time Job (Even if You Don’t Have a Lot of Time and Don’t Know Where to Start)\n",
            "Adding new note to clippings/Osman Hassan - Write Your Book on the Side: How to Write and Publish Your First Nonfiction Kindle Book While Working a Full-Time Job (Even if.rst: cc0900da Deine loc.188-191, p.16 Mittwoch, 2. August 2023 18:14:43\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "f= open('My Clippings.txt','r')\n",
        "if f.mode == 'r':\n",
        "      contents =f.read()\n",
        "f.close()\n",
        "\n",
        "print(contents)\n",
        "print(len(contents))\n",
        "print(contents[2])\n",
        "print(ord(contents[2]))\n",
        "print(contents[1])\n",
        "print(ord(contents[1]))\n",
        "print(chr(65279))\n",
        "\n",
        "contents2 = contents.replace(chr(65279), \"\")\n",
        "print(contents2)\n",
        "print(len(contents2))\n",
        "\n",
        "f= open('My Clippings2.txt','w+')\n",
        "f.write(contents2)\n",
        "f.close()\n"
      ],
      "metadata": {
        "id": "Qu1Slzrmg4iJ"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNURo37hEG2Upd5a4BdNvB4",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}