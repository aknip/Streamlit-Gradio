{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNL8OlECDcZ5HSuSyz80Ffh",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aknip/Streamlit-Gradio/blob/main/helper_lib.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# helper_lib"
      ],
      "metadata": {
        "id": "2oVPxUEFVZzt"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "nYJvtG74VWwJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "501f4704-e7e7-4f31-e5c7-ac7b8836b8d7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pypandoc==1.11\n",
            "  Downloading pypandoc-1.11-py3-none-any.whl (20 kB)\n",
            "Installing collected packages: pypandoc\n",
            "Successfully installed pypandoc-1.11\n"
          ]
        }
      ],
      "source": [
        "!pip install pypandoc==1.11"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pypandoc\n",
        "\n",
        "def test_pypandoc():\n",
        "  output = pypandoc.convert_text('# some title', 'rst', format='md')\n",
        "  return output\n",
        "\n",
        "#print(test_pypandoc())"
      ],
      "metadata": {
        "id": "Y6YtIID7jGy6"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# v4 - 13.08.2023\n",
        "import shutil\n",
        "import os\n",
        "import textwrap\n",
        "import re\n",
        "import time\n",
        "from datetime import datetime\n",
        "import pypandoc\n",
        "import os\n",
        "import zipfile\n",
        "import random\n",
        "import requests\n",
        "\n",
        "def import_prompt_lib():\n",
        "  fname = 'prompt_lib.ipynb'\n",
        "  url = 'https://raw.githubusercontent.com/aknip/Streamlit-Gradio/main/' + fname\n",
        "  r = requests.get(url)\n",
        "  open(fname, 'wb').write(r.content)\n",
        "  %run prompt_lib.ipynb\n",
        "\n",
        "def import_helper_lib():\n",
        "  fname = 'helper_lib.ipynb'\n",
        "  url = 'https://raw.githubusercontent.com/aknip/Streamlit-Gradio/main/' + fname\n",
        "  r = requests.get(url)\n",
        "  open(fname, 'wb').write(r.content)\n",
        "  %run helper_lib.ipynb\n",
        "\n",
        "def create_file_directory(directory, always_delete=False):\n",
        "  # Creates a new directory - if it not exists yet. The always_delete flag forces a deletion even if it exists.\n",
        "  # Examples:\n",
        "  # - create_file_directory('texts', False) => creates a new directory only if it not exists yet\n",
        "  # - create_file_directory('texts', True) => always deletes existing directory and creates a new one\n",
        "  if os.path.exists(directory):\n",
        "    if always_delete:\n",
        "      # delete the diectory recursively\n",
        "      shutil.rmtree(directory)\n",
        "  # create directory\n",
        "  if not os.path.exists(directory):\n",
        "    os.mkdir(directory)\n",
        "\n",
        "\n",
        "def find_files(path, extensions=[\".txt\"], recursive=False):\n",
        "    # Recursively (optional) find all files with extension in path\n",
        "    my_files = []\n",
        "    for root, dirs, files in os.walk(path):\n",
        "        for f in files:\n",
        "            if extensions == []:\n",
        "                my_files.append(os.path.join(root, f))\n",
        "            else:\n",
        "                for ext in extensions:\n",
        "                    if f.endswith(ext):\n",
        "                        my_files.append(os.path.join(root, f))\n",
        "        # no recursion / don't look inside any subdirectory\n",
        "        if recursive == False:\n",
        "            break\n",
        "    return my_files\n",
        "\n",
        "\n",
        "def merge_textfiles(path, extensions=[\".txt\"], recursive=False, new_filename='merged.txt'):\n",
        "    # Recursively (optional) find all files with extension in path\n",
        "    my_files = find_files(path, extensions, recursive)\n",
        "    merged_text = ''\n",
        "    for filename in my_files:\n",
        "      # print(filename)\n",
        "      f= open(filename,'r')\n",
        "      if f.mode == 'r':\n",
        "            contents =f.read()\n",
        "      f.close()\n",
        "      merged_text = merged_text + contents + '\\n\\n\\n'\n",
        "\n",
        "    f= open(new_filename,'w+')\n",
        "    f.write(merged_text)\n",
        "    f.close()\n",
        "\n",
        "\n",
        "def save_and_backup(filepath, filename, content, convert_to_docx=False):\n",
        "  dot_pos = filename.rfind('.')\n",
        "  docx_filename = filename[:dot_pos] + '.docx'\n",
        "  if os.path.exists(filepath + '/' + filename):\n",
        "    # file exists, do backup\n",
        "    current_date_time = datetime.now().strftime(\"%Y-%m-%d %H-%M-%S\")\n",
        "    backuppath = filepath + '/backup ' + current_date_time\n",
        "    os.mkdir(backuppath)\n",
        "    shutil.copyfile(filepath + '/' + filename, backuppath + '/' + filename)\n",
        "    # copy corresponding .docx if necessary\n",
        "    if (convert_to_docx == True) and (os.path.exists(filepath + '/' + docx_filename)):\n",
        "      shutil.copyfile(filepath + '/' + docx_filename, backuppath + '/' + docx_filename)\n",
        "  # save\n",
        "  f= open(filepath + '/' + filename,'w+')\n",
        "  f.write(content)\n",
        "  f.close()\n",
        "  if convert_to_docx == True:\n",
        "    docx_file = pypandoc.convert_file(\n",
        "    filepath + '/' + filename,\n",
        "    'docx',\n",
        "    outputfile=filepath + '/' + docx_filename)\n",
        "\n",
        "\n",
        "def zip_full_archive():\n",
        "  # zips all project folders (except \"sample_data\" and config files)\n",
        "  #os.remove('zipfile.zip')\n",
        "  directory = \"./\"\n",
        "  with zipfile.ZipFile(\"zipfile.zip\", \"w\") as zip:\n",
        "      for subdir, dirs, files in os.walk(directory):\n",
        "          for file in files:\n",
        "              srcpath = os.path.join(subdir, file)\n",
        "              if (subdir != './') and (subdir.startswith('./.config') == False) and (subdir != './sample_data'):\n",
        "                #print(subdir)\n",
        "                dstpath_in_zip = os.path.relpath(srcpath, start=directory)\n",
        "                with open(srcpath, 'rb') as infile:\n",
        "                    print(srcpath)\n",
        "                    zip.writestr(dstpath_in_zip, infile.read())\n",
        "\n",
        "def unzip_full_archive():\n",
        "  with zipfile.ZipFile('zipfile.zip', 'r') as zip:\n",
        "      zip.printdir()\n",
        "      zip.extractall('./')\n",
        "\n",
        "\n",
        "def remove_all_double_whitespace (input_text):\n",
        "    # replaces ALL whitespace to a single SPACE, no paragraphs left\n",
        "    clean_text = \" \".join(re.split(\"[\\s ]+\", input_text, flags=re.UNICODE))\n",
        "    # clean_text = input_text.translate(str.maketrans('', '', ' \\n\\t\\r'))\n",
        "    return clean_text.strip()\n",
        "\n",
        "def remove_double_spaces_keep_paragraphs (input_text):\n",
        "    # removes double spaces and double paragraphs, keeps paragraph structure\n",
        "    clean_text = \"\"\n",
        "    for line in input_text.split('\\n'):\n",
        "        line_trimmed = line.strip()\n",
        "        if line_trimmed != '':\n",
        "            clean_text = clean_text + (re.sub('[\\t ]+',' ', line_trimmed)) + '\\n'\n",
        "    return clean_text[:-1] # remove last \\n\n",
        "\n",
        "\n",
        "def remove_special_chars(input_text, strength_level):\n",
        "  # removes\n",
        "  cleaned_text = input_text.replace('»', '\"')\n",
        "  cleaned_text = cleaned_text.replace('«', '\"')\n",
        "  cleaned_text = cleaned_text.replace('„', '\"')\n",
        "  cleaned_text = cleaned_text.replace('“', '\"')\n",
        "  cleaned_text = re.sub('(?sm)[\\\\\\/\"\\'`´\\^\\*{}\\[\\]<>\\+\\&]', '', cleaned_text)\n",
        "  return cleaned_text\n",
        "\n",
        "\n",
        "def text_stats(input_text):\n",
        "    nr_paragraphs = len(input_text.split(\"\\n\"))\n",
        "    nr_words = wordcount(input_text)\n",
        "    array_segments = input_text.split(\"§§§\")\n",
        "    nr_segments = len(array_segments)\n",
        "    stat_txt = f'Number of words / paragraphs / §§§ segements: {nr_words} / {nr_paragraphs} / {nr_segments}'\n",
        "    if nr_segments > 1:\n",
        "        seg_stats = []\n",
        "        seg_stats_text = ''\n",
        "        for seg in array_segments:\n",
        "            seg_stats.append(wordcount(seg))\n",
        "            seg_stats_text = seg_stats_text + str(wordcount(seg)) + ' / '\n",
        "        stat_txt = stat_txt + '\\n\\nMax words in §§§ segment: ' + str(max(seg_stats)) + ' (' + seg_stats_text[:-3] + ')'\n",
        "    return stat_txt\n",
        "\n",
        "\n",
        "\n",
        "def calculate_stats(my_stats):\n",
        "  model = my_stats[0]['model_name']\n",
        "  wordcount_input = 0\n",
        "  wordcount_output = 0\n",
        "  completion_tokens = 0\n",
        "  prompt_tokens = 0\n",
        "  total_tokens = 0\n",
        "  for i in my_stats:\n",
        "    wordcount_input = wordcount_input + i['wordcount']['input']\n",
        "    wordcount_output = wordcount_output + i['wordcount']['output']\n",
        "    prompt_tokens = prompt_tokens + i['token_usage']['prompt_tokens']\n",
        "    completion_tokens = completion_tokens + i['token_usage']['completion_tokens']\n",
        "    total_tokens = total_tokens + i['token_usage']['total_tokens']\n",
        "\n",
        "  token_prices = {\n",
        "    \"gpt-3.5-turbo\": {\n",
        "        \"prompt_tokens\": 0.002,\n",
        "        \"completion_tokens\": 0.002,\n",
        "    },\n",
        "    \"gpt-4\": {\n",
        "        \"prompt_tokens\": 0.03,\n",
        "        \"completion_tokens\": 0.06\n",
        "    }\n",
        "  }\n",
        "\n",
        "  prompt_tokens_price = int((prompt_tokens / 1000 * token_prices[model][\"prompt_tokens\"] + completion_tokens / 1000 * token_prices[model][\"completion_tokens\"])*100+0.5)/100\n",
        "  wordcount_ratio = int(wordcount_output/wordcount_input*100)/100\n",
        "\n",
        "  stats_obj = {\n",
        "    'wordcount_input': wordcount_input,\n",
        "    'wordcount_output': wordcount_output,\n",
        "    'wordcount_ratio': wordcount_ratio,\n",
        "    'prompt_tokens': prompt_tokens,\n",
        "    'completion_tokens': completion_tokens,\n",
        "    'total_tokens': total_tokens,\n",
        "    'prompt_tokens_price': prompt_tokens_price\n",
        "  }\n",
        "\n",
        "  return stats_obj\n",
        "\n",
        "\n",
        "def wordcount(input_text):\n",
        "    # returns number of words of given input_text\n",
        "    return len(input_text.split())\n",
        "\n",
        "\n",
        "def split_text_by_separator (text, separator, joiner, fixer, min_words=1000, max_words=0):\n",
        "    # Split text into an array of texts with a maximum word count\n",
        "    # optionally use random word counts between min_words and max_words (if max_words is set)\n",
        "    # example 1: Split by paragraphs\n",
        "    #   split_text_by_separator(input_text, '\\n', '\\n', 'fix-nothing', 2000)\n",
        "    # example 2: Split by sentences '. ' and fix\n",
        "    #   split_text_by_separator(input_text, '. ', ' ', 'fix-end', 2000)\n",
        "    # example 3: Split by markdown headlines '\\n#' and fix\n",
        "    #   split_text_by_separator(input_text, '\\n#', '\\n\\n', 'fix-start', 2000)\n",
        "    paragraphs = []\n",
        "    sections = []\n",
        "    section = ''\n",
        "    if max_words == 0:\n",
        "      max_words = min_words\n",
        "    # Split text, separated by separator\n",
        "    paragraphs_stripped = text.split(separator)\n",
        "    # fix paragraphs (if wanted) by re-adding the separator at end or start\n",
        "    if fixer == 'fix-nothing':\n",
        "        paragraphs = paragraphs_stripped\n",
        "    if fixer == 'fix-end':\n",
        "        for index, paragraph in enumerate(paragraphs_stripped):\n",
        "            if (index+1) == len(paragraphs_stripped):\n",
        "                paragraphs.append(paragraph)\n",
        "            else:\n",
        "                paragraphs.append(paragraph + separator)\n",
        "    if fixer == 'fix-start':\n",
        "        for index, paragraph in enumerate(paragraphs_stripped):\n",
        "            if index == 0:\n",
        "                paragraphs.append(paragraph)\n",
        "            else:\n",
        "                paragraphs.append(separator + paragraph)\n",
        "    # Loop through paragraphs and aggregate up to maximum word count\n",
        "    for index, paragraph in enumerate(paragraphs):\n",
        "        if min_words == max_words:\n",
        "            max_random = min_words\n",
        "        else:\n",
        "            max_random = random.randrange(min_words, max_words)\n",
        "        test_section = section + paragraph + joiner\n",
        "        if wordcount(test_section) > max_random:\n",
        "            sections.append(section.strip())\n",
        "            section = paragraph\n",
        "            if min_words == max_words:\n",
        "                max_random = min_words\n",
        "            else:\n",
        "                max_random = random.randrange(min_words, max_words)\n",
        "        else:\n",
        "            section = section + paragraph + joiner\n",
        "            # if last paragraph, append to array\n",
        "            if (index+1) == len(paragraphs):\n",
        "              sections.append(section)\n",
        "    return sections\n"
      ],
      "metadata": {
        "id": "niXO7GfdjIfy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import pickle\n",
        "\n",
        "\n",
        "\n",
        "def write_prompt_to_lib(promptlib, prompt):\n",
        "    # adds or updates prompt to library\n",
        "    #\n",
        "    # TODO: Add model sections \"gpt-4\", ... etc.\n",
        "    #\n",
        "    id = prompt['id']\n",
        "    version = prompt['version']\n",
        "    if id not in promptlib:\n",
        "        # new id\n",
        "        promptlib[id] = {}\n",
        "        promptlib[id][version] = {}\n",
        "    else:\n",
        "        # id already existing, checking for version\n",
        "        if version not in promptlib[id]:\n",
        "            promptlib[id][version] = {}\n",
        "    promptlib[id]['description'] = prompt['description']\n",
        "    promptlib[id]['category'] = prompt['category']\n",
        "    promptlib[id][version]['note'] = prompt['note']\n",
        "    promptlib[id][version]['prompt'] = prompt['prompt']\n",
        "\n",
        "\n",
        "def get_prompt_from_lib(promptlib, id, model='default-model', version=None ):\n",
        "    # searches for prompt with given id\n",
        "    # looks for highest available version, if no version is given\n",
        "    if id==None:\n",
        "        prompt_found = None\n",
        "    else:\n",
        "        prompt = promptlib[id]\n",
        "        if version != None:\n",
        "            # version given\n",
        "            version_highest = int(version)\n",
        "        else:\n",
        "            # look for highest available version\n",
        "            version_highest = 0\n",
        "            for key, val in prompt.items():\n",
        "                try:\n",
        "                    version = int(key)\n",
        "                except ValueError:\n",
        "                    version = 0\n",
        "                if version > version_highest:\n",
        "                    version_highest = version\n",
        "        prompt_version = prompt[str(version_highest)]\n",
        "        # return dict\n",
        "        prompt_found = {}\n",
        "        prompt_found['id'] = id\n",
        "        prompt_found['description'] = prompt['description']\n",
        "        prompt_found['category'] = prompt['category']\n",
        "        prompt_found['version'] = str(version_highest)\n",
        "        prompt_found['note'] = prompt_version['note']\n",
        "        prompt_found['prompt'] = prompt_version['prompt']\n",
        "        prompt_found['lang-de'] = prompt_version['lang-de']\n",
        "        prompt_found['lang-en'] = prompt_version['lang-en']\n",
        "        prompt_found['lang-same'] = prompt_version['lang-same']\n",
        "        if model in prompt_version:\n",
        "          prompt_found['input-text-max'] = prompt_version[model]['input-text-max']\n",
        "          prompt_found['length-max-fix'] = prompt_version[model]['length-max-fix']\n",
        "          prompt_found['length-max-dyn'] = prompt_version[model]['length-max-dyn']\n",
        "        else:\n",
        "          prompt_found['input-text-max'] = prompt_version['default-model']['input-text-max']\n",
        "          prompt_found['length-max-fix'] = prompt_version['default-model']['length-max-fix']\n",
        "          prompt_found['length-max-dyn'] = prompt_version['default-model']['length-max-dyn']\n",
        "    return prompt_found\n",
        "\n",
        "def build_prompt_from_template(input_txt, prompt_obj, lang, length_type, length_max, toc_text):\n",
        "  prompt_text =  prompt_obj['prompt']\n",
        "  language_text = prompt_obj[lang]\n",
        "  # calculate max. output lengt dynamically\n",
        "  if length_type != '':\n",
        "    length_template = prompt_obj[length_type]\n",
        "    input_txt2 = re.sub('(?sm)[\\\\\\/\"\\'„“]', '', input_txt)\n",
        "    input_txt2 = re.sub('(?sm)[\\n]', ' ', input_txt2)\n",
        "    length_template2 = length_template.format(input_text = input_txt2, max_len=length_max)\n",
        "    length_text = eval(f\"f'{length_template2}'\")\n",
        "  else:\n",
        "    length_text = ''\n",
        "  # Create the final prompt, fill the variables\n",
        "  # Example: \"Summarize the following text. {language_text} {length_text} Text:```{input_text}``` TOC:```{toc_text}```\"\n",
        "  final_prompt = prompt_text.format(language_text=language_text, length_text=length_text, input_text=input_txt, toc_text=toc_text)\n",
        "  return final_prompt\n",
        "\n",
        "def length_calc(my_text, maxWords):\n",
        "  # maxWords 0.0 - 1.0 (percentage)\n",
        "    return int(wordcount(my_text) * maxWords)\n",
        "\n",
        "def save_promptlib(promptlib):\n",
        "  # saves promptlib to disk\n",
        "  with open('promptlib.dictionary', 'wb') as dict_file:\n",
        "      pickle.dump(promptlib, dict_file)\n",
        "\n",
        "def load_promptlib():\n",
        "  # load promptlib from disk\n",
        "  with open('promptlib.dictionary', 'rb') as dict_file:\n",
        "      promptlib = pickle.load(dict_file)\n",
        "  return promptlib\n",
        "\n"
      ],
      "metadata": {
        "id": "lVfTksM0jNPb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Talk to model\n",
        "\n",
        "from datetime import datetime\n",
        "import langchain\n",
        "from langchain.chains import RetrievalQA\n",
        "from langchain.llms import OpenAI\n",
        "from langchain.chat_models import ChatOpenAI\n",
        "from langchain.schema import (AIMessage, HumanMessage, SystemMessage)\n",
        "from langchain.document_loaders import WebBaseLoader\n",
        "from langchain.embeddings import OpenAIEmbeddings\n",
        "from langchain.indexes import VectorstoreIndexCreator\n",
        "from langchain.prompts import PromptTemplate\n",
        "from langchain.vectorstores import Chroma\n",
        "from langchain.schema import HumanMessage\n",
        "from langchain.callbacks.base import BaseCallbackHandler\n",
        "import pypandoc\n",
        "\n",
        "# OpenAI Key\n",
        "openAI_key = creds['OpenAI']['v2']['credential']\n",
        "\n",
        "def create_test_project(proj_name, proj_text):\n",
        "  create_file_directory(proj_name, False)\n",
        "  create_file_directory(proj_name + '/' +  folders['text-input'], False)\n",
        "  create_file_directory(proj_name + '/' +  folders['text-output'], False)\n",
        "  create_file_directory(proj_name + '/' +  folders['text-output-logs'], False)\n",
        "  if proj_text != '':\n",
        "    f= open(proj_name + '/' +  folders['text-input'] + '/testfile.txt','w+')\n",
        "    f.write(proj_text)\n",
        "    f.close()\n",
        "\n",
        "\n",
        "def execute_prompt (exec_params):\n",
        "  #    'model':'no',\n",
        "  #    'prompt-name': prompt_name,\n",
        "  #    'prompt-version': prompt_version,\n",
        "  #    'prompt-comment': prompt_comment,\n",
        "  #    'loglevel':0,\n",
        "  #    'stop-after-step':5,\n",
        "  #    'proj-name': proj_name,\n",
        "  #    'input-filepath': '',\n",
        "  #    'input-filename': '',\n",
        "  #    'folders': folders,\n",
        "  #    'prompt-obj': prompt_obj,\n",
        "  #    'language': 'lang-de',\n",
        "  #    'length-type': 'length-max-dyn',\n",
        "  #    'length-max': 0.5,\n",
        "  #    'toc-text': 'some toc-text',\n",
        "  #    'result-filename': 'paraphrased.txt'\n",
        "\n",
        "  # Read file from disk\n",
        "  if exec_params['input-filename'] != '':\n",
        "    input_file_path = exec_params['proj-name'] + '/' + exec_params['input-filepath'] + '/' + exec_params['input-filename']\n",
        "  else:\n",
        "    input_file_path = find_files(exec_params['proj-name'] + '/' + exec_params['folders']['text-input'], ['.txt','.md'], False)[0]\n",
        "  f= open(input_file_path,'r')\n",
        "  if f.mode == 'r': input_text =f.read()\n",
        "  f.close()\n",
        "  # if input text is output from a prevoius step, strip out Logs\n",
        "  input_text = input_text.split('=== LOGS: ===')[0]\n",
        "\n",
        "  # remove special characters\n",
        "  # input_text = remove_special_chars(input_text, 1) # level 1\n",
        "\n",
        "  # email.[^[\\[1\\]]{.underline}^](\\l)\n",
        "\n",
        "  if exec_params['loglevel'] >= 1:\n",
        "    print(json.dumps(exec_params['prompt-obj'], sort_keys=False, indent=2) + '\\n')\n",
        "    #print(textwrap.fill(input_text, 120) + '\\n')\n",
        "\n",
        "  llm = ChatOpenAI(model_name=exec_params['model'], temperature=0.0, openai_api_key=openAI_key)\n",
        "  # model overview see https://gptforwork.com/guides/openai-gpt3-models\n",
        "\n",
        "  #input_text_segments = input_text.split(\"§§§\")\n",
        "  input_text_segments = split_text_by_separator(input_text, '\\n', '\\n', 'fix-nothing', exec_params['prompt-obj']['input-text-max'])\n",
        "  output_text_segments = []\n",
        "\n",
        "  log_detail_model = 'Model: ' + exec_params['model']\n",
        "  print(log_detail_model)\n",
        "  log_time_start = 'Started at: ' + datetime.now().strftime(\"%H:%M:%S\") + '\\n'\n",
        "  print(log_time_start)\n",
        "  timer_start = time.time()\n",
        "\n",
        "  log_stats = []\n",
        "  log_prompt = '\\n\\n\\n***********************\\n\\n# Promptname: ' + exec_params['prompt-name'] + ', Version: ' + str(exec_params['prompt-version'])  + '\\n'\n",
        "  log_prompt = '\\n' + log_prompt + exec_params['prompt-comment'] + '\\n\\n\\n'\n",
        "  prompt_obj_for_log = json.dumps(exec_params['prompt-obj'], sort_keys=False, indent=2).replace('\\n', '<br>')\n",
        "  prompt_obj_for_log = prompt_obj_for_log.replace(' ', '&nbsp;')\n",
        "  prompt_obj_for_log = prompt_obj_for_log.replace('`', '\\`')\n",
        "  log_prompt = log_prompt +  prompt_obj_for_log\n",
        "  log_input_output_compare = '\\n\\n\\n***********************\\n\\n# Compare input and output texts (' + log_detail_model + ')\\n'\n",
        "  log_input_SHORT = '\\n\\n\\n***********************\\n\\n# Prompts (Input Text shortened)\\n'\n",
        "  log_input = '\\n\\n\\n***********************\\n\\n# Prompts (Full length)\\n'\n",
        "  log_input_output = '\\n\\n\\n***********************\\n\\n# Prompts and anwers (Full length)\\n'\n",
        "\n",
        "  for index, input_text in enumerate(input_text_segments):\n",
        "\n",
        "      log_detail = 'Processing step ' + str(index + 1) + ' of ' + str(len(input_text_segments))\n",
        "      print(log_detail)\n",
        "\n",
        "      #print('TEXT FROM ARRAY:')\n",
        "      #print(textwrap.fill(input_text, 120) + '\\n')\n",
        "\n",
        "      prompt_txt_final = remove_all_double_whitespace(\n",
        "          build_prompt_from_template(input_text, exec_params['prompt-obj'], exec_params['language'], exec_params['length-type'], exec_params['length-max'], exec_params['toc-text'])\n",
        "          )\n",
        "      # Shorten input text for logging purposes\n",
        "      #input_txt_short = re.findall('(?sm)```(.+)```', prompt_txt_final)[0][:30]\n",
        "      #prompt_txt_final_SHORT = re.sub('(```)(.+)(```)', r'\\1' + input_txt_short + '...' + r'\\3' , prompt_txt_final)\n",
        "      prompt_txt_final_SHORT = prompt_txt_final[:800]\n",
        "      if exec_params['loglevel'] <= 1:\n",
        "        print(textwrap.fill(prompt_txt_final_SHORT, 120) + '\\n')\n",
        "      if exec_params['loglevel'] == 2:\n",
        "        print(textwrap.fill(prompt_txt_final, 120) + '\\n')\n",
        "\n",
        "      if exec_params['model'] != 'no':\n",
        "        gpt_response_obj = llm.generate([[HumanMessage(content=prompt_txt_final)]])\n",
        "        tmp_text = gpt_response_obj.generations[0][0].text\n",
        "        tmp_tokens = gpt_response_obj.llm_output\n",
        "        # log statistics (tokens, words)\n",
        "        tmp_tokens['wordcount'] = {}\n",
        "        tmp_tokens['wordcount']['input'] = wordcount(input_text)\n",
        "        tmp_tokens['wordcount']['output'] = wordcount(tmp_text)\n",
        "        log_stats.append(tmp_tokens)\n",
        "\n",
        "        if exec_params['loglevel'] >= 1:\n",
        "          print('*** Resonse: ***')\n",
        "          print(textwrap.fill(tmp_text, 120) + '\\n')\n",
        "        print(str(tmp_tokens) + '\\n')\n",
        "        output_text_segments.append(tmp_text)\n",
        "      else:\n",
        "        tmp_text = '... Response from model ...'\n",
        "\n",
        "      # Log prompts\n",
        "      log_input = log_input + log_detail + '\\n' + prompt_txt_final + '\\n\\n'\n",
        "      log_input_SHORT = log_input_SHORT + log_detail + '\\n' + prompt_txt_final_SHORT + '\\n\\n'\n",
        "      log_input_output = log_input_output + log_detail + '\\n' + prompt_txt_final + '\\n\\n' + tmp_text + '\\n\\n\\n'\n",
        "\n",
        "      # Log input / output comparison\n",
        "      log_text = ''\n",
        "      log_text = log_text + '| Step | ' + str(index + 1) + ' of ' + str(len(input_text_segments)) + ' |\\n'\n",
        "      log_text = log_text + '| -------- | ------- |\\n'\n",
        "      log_text = log_text + '| ' + str(wordcount(input_text)) + ' | ' + str(wordcount(tmp_text)) + ' |\\n'\n",
        "      log_text = log_text + '| ' + input_text.replace('\\n','<br />') + ' | ' + tmp_text.replace('\\n','<br />') + ' |\\n'\n",
        "      log_text = log_text + '\\n'\n",
        "\n",
        "      log_input_output_compare = log_input_output_compare + log_text\n",
        "\n",
        "      # check if not all text segments/steps should be processed (eg. for debugging)\n",
        "      if (index+1) == exec_params['stop-after-step']:\n",
        "        break\n",
        "\n",
        "  timer_end = time.time()\n",
        "  timer_duration_secs = int(timer_end - timer_start)\n",
        "  timer_duration_mins = int(timer_duration_secs/60*10)/10\n",
        "\n",
        "  log_time_end = '\\nEnded at: ' + datetime.now().strftime(\"%H:%M:%S\") + '\\n\\nDuration: ' + str(timer_duration_mins) + ' Minutes\\n'\n",
        "  print(log_time_end)\n",
        "  log_time = '\\n\\n\\n***********************\\n\\n# Duration\\n' + str(timer_duration_secs) + ' Seconds\\n' + str(timer_duration_mins) + ' Minutes\\n' + log_time_start + '\\n' + log_time_end\n",
        "\n",
        "  full_output_text = '\\n\\n'.join(output_text_segments)\n",
        "\n",
        "  dot_pos = exec_params['result-filename'].rfind('.')\n",
        "  input_text_filename_only1 = exec_params['result-filename'][:dot_pos]\n",
        "  input_text_filename_only2 = exec_params['result-filename'][dot_pos:]\n",
        "  output_filename_with_model = input_text_filename_only1 + '_' + exec_params['model'][:5] + input_text_filename_only2\n",
        "\n",
        "  stats_aggregated = calculate_stats(log_stats)\n",
        "  stats_text = '\\n\\n\\n***********************\\n\\n# Statistics: \\n'\n",
        "  stats_text = stats_text + 'Wordcount ratio: ' + str(stats_aggregated['wordcount_ratio']) + '%, Costs: $' + str(stats_aggregated['prompt_tokens_price']) + '\\n'\n",
        "  stats_text = stats_text + '\\n' + json.dumps(stats_aggregated, sort_keys=True, indent=2).replace('\\n', '<br>') + '\\n\\n'\n",
        "  #stats_text = stats_text + json.dumps(log_stats, sort_keys=True, indent=2) + '\\n\\n'\n",
        "  print('Statistics:')\n",
        "  print(stats_text)\n",
        "\n",
        "  # save prompt log to disk\n",
        "  save_and_backup(\n",
        "      exec_params['proj-name'] + '/' + exec_params['folders']['text-output-logs'],\n",
        "      output_filename_with_model + '.log.md',\n",
        "      log_prompt + log_time + stats_text + log_input_output_compare + log_input_SHORT + log_input + log_input_output,\n",
        "      True) # create .docx\n",
        "\n",
        "  # save output only to disk (in log folder)\n",
        "  save_and_backup(\n",
        "      exec_params['proj-name'] + '/' + exec_params['folders']['text-output-logs'],\n",
        "      output_filename_with_model + '.pure.md',\n",
        "      full_output_text,\n",
        "      False) # create .docx\n",
        "\n",
        "  # save full output to disk\n",
        "  save_and_backup(\n",
        "      exec_params['proj-name'] + '/' + exec_params['folders']['text-output'],\n",
        "      output_filename_with_model,\n",
        "      full_output_text + '\\n\\n=== LOGS: ===\\n\\n\\n\\n' + log_prompt + log_time + stats_text + log_input_output_compare + log_input_SHORT + log_input + log_input_output,\n",
        "      True) # create .docx\n",
        "\n",
        "  # Always create .zip archive in root directory (for download)\n",
        "  shutil.make_archive(exec_params['proj-name'], 'zip', exec_params['proj-name'])\n",
        "\n",
        "  # return output path and filename (tuple)\n",
        "  return exec_params['proj-name'] + '/' + exec_params['folders']['text-output'], output_filename_with_model\n",
        "\n",
        "\n",
        "\n",
        "def execute_project(proj_name, model, prompt_lib, prompt_id, prompt_version, length_max_dyn, toc_text, stop_after_step, delete_output_dirs, folders, input_text_string, prompt_comment):\n",
        "  create_test_project(proj_name, '')\n",
        "  if delete_output_dirs == True:\n",
        "    create_file_directory(proj_name + '/' + folders['text-output'], True)\n",
        "    create_file_directory(proj_name + '/' + folders['text-output-logs'], True)\n",
        "  # if input_text is contains '<File: >' do not create text file\n",
        "  filename_regex = re.findall('(?sm)<File:>', input_text_string)\n",
        "  if not filename_regex:\n",
        "    # Save text to input dir\n",
        "    f= open(proj_name + '/' + folders['text-input'] + '/input.txt','w+')\n",
        "    f.write(input_text_string)\n",
        "    f.close()\n",
        "  else:\n",
        "    # Check, if docx file is in input dir\n",
        "    print('chechking for docx.')\n",
        "    input_files_all = find_files(proj_name + '/' + folders['text-input'], [''], False)\n",
        "    input_files_docx = find_files(proj_name + '/' + folders['text-input'], ['.docx'], False)\n",
        "    if (len(input_files_all) == 1) and (len(input_files_docx) == 1):\n",
        "      #convert docx to md\n",
        "      dot_pos = input_files_docx[0].rfind('.')\n",
        "      output_filename = input_files_docx[0][:dot_pos] + '.md'\n",
        "      md_file = pypandoc.convert_file(input_files_docx[0], 'md', outputfile=output_filename)\n",
        "\n",
        "  prompt_obj = get_prompt_from_lib(prompt_lib, prompt_id, model, prompt_version)\n",
        "  #print(json.dumps(prompt_obj, sort_keys=False, indent=2))\n",
        "  result_text = execute_prompt({\n",
        "      'model': model,\n",
        "      'prompt-name': prompt_id,\n",
        "      'prompt-version': prompt_version,\n",
        "      'prompt-comment': prompt_comment,\n",
        "      'loglevel': 0,\n",
        "      'stop-after-step': stop_after_step,\n",
        "      'proj-name': proj_name,\n",
        "      'input-filepath': '',\n",
        "      'input-filename': '',\n",
        "      'folders': folders,\n",
        "      'prompt-obj': prompt_obj,\n",
        "      'language': 'lang-same',\n",
        "      'length-type': length_max_dyn,\n",
        "      'length-max': 0.5,\n",
        "      'toc-text': toc_text,\n",
        "      'result-filename': 'response.md'\n",
        "  })\n",
        "  return result_text"
      ],
      "metadata": {
        "id": "ZLP9xc-4jXDa"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}